{"aid": "40159756", "title": "An overlooked game-changing use case of LLMs for software developers", "url": "https://www.promptotype.io/blog/posts/llm-structured-tasks", "domain": "promptotype.io", "votes": 5, "user": "ramn7", "posted_at": "2024-04-25 16:40:55", "comments": 0, "source_title": "Promptotype - The platform for structured prompt engineering", "source_text": "Promptotype - The platform for structured prompt engineering\n\n# An overlooked game-changing use case of LLMs for software developers\n\n## Introduction\n\nOpenAI's revolution has transformed the landscape of natural language\nprocessing, marking a significant leap in the capabilities of conversational\nAI. ChatGPT has demonstrated an unprecedented understanding of context,\nfinding applications across a wide range of fields. This innovation signifies\na pivotal moment in the evolution of AI, showcasing the potential for advanced\nlanguage models to enhance communication and problem-solving in diverse\ncontexts.\n\nLLMs have countless use cases, literally! To demonstrate one of them, the\nabove introduction was written by an LLM (only to make a point, not that it\u2019s\nneeded). Some of these use cases are very relevant to us- software developers.\n\nContext-specific chatbots, writing code for us, and assisting in planning,\ntesting, and design are some of the software-related use cases that are being\ndiscussed a lot. However, there\u2019s one very strong use case that imho isn\u2019t\ndiscussed as much as it should, and is very relevant to many software\ndevelopers, especially to those who don\u2019t have a lot of experience with AI/ML\ntechnologies- LLM Structured Tasks.\n\n## What are LLM Structured Tasks?\n\nI have to admit I think I might have made up that name, but it\u2019s a real thing\nI promise. On a very high level, it\u2019s a task done by an LLM that can be\nintegrated into our program\u2019s flow- basically, a function that\u2019s written in (a\nsomewhat) natural language instead of code. The task is implemented by\ninstructing the LLM to do some work on some input.\n\nA basic example would be entity extraction: we can instruct the model to\nextract all names of < countries/people/companies/else > from the provided\ntext input. This is already useful but we can even add follow-up \u201cwork\u201d too:\nreturn all continents of the mentioned countries, return stock symbols of the\ncompanies, return the sentiment of the text as one of 5 values: ..., and\nanything else you can think of.\n\nThe task work is often deterministic, having one correct output for every\ninput. It is also potentially complex enough to return multiple values,\ntherefore the output needs to be structured (as a JSON for example), so our\nprogram will be able to work with it. The \u2018structured\u2019 part is not trivial for\nthe LLM that\u2019s usually generally built to output text.\n\nLLM function calling can also be considered a structured task- having the LLM\ndeciding whether and how to call the functions, and outputting the arguments\nstructure.\n\n## What's so game-changing about it?\n\nImagine what it would be like to try and implement any of the examples\nmentioned above without highly accessible LLMs: the simplest example (entity\nextraction) would require setting up complex ML dedicated systems, and the\nmore complicated ones a whole array of pipelines of them- each requiring many,\nmany hours of work in design, development, and testing.\n\nNow, with the high accessibility (and continually reduced price!), these kinds\nof tasks can be easily developed and tested to a reasonable quality, sometimes\nin as little as a few hours- try it yourself!\n\n## The challenges in engineering LLM structured tasks\n\n### Semantic Ambiguity\n\nLLMs don\u2019t always respond exactly the way we expect them to. A prompt\ninstruction can seem very clear to a human but have unexpected output from the\nmodel, and sometimes even worse- a total hallucination. This is often due to\nthe model's \"creativity\", which helps a lot in some use cases of LLMs (in\nother words- some of it is by design) but can have a detrimental effect here\nwhen the result has a concrete applicative goal.\n\n### Structure Fragility\n\nLLMs\u2019 creativity can have big effects on even simpler things, such as JSON\nvalidity (OpenAI doesn\u2019t guarantee a valid JSON even when using the dedicated\nJSON mode). Responding with the correct attributes we requested is even harder\nfor it. Needless to say, such errors can make it impossible for a program to\nwork properly.\n\n### Development Iteration Fragility\n\nOur prompt usually keeps evolving- we sometimes find queries it doesn\u2019t work\nwell with and want to fix it, or maybe want to support new \u201cfeatures\u201d by\nextending it.\n\nThe problem is, that even small adjustments to the prompt can sometimes have\nunexpected effects. We can often find ourselves adding a few words to\ncorrectly support a failed query, and find out that other unrelated queries\n(possibly even much simpler ones) break as a result of the change.\n\n### Model Stability\n\nWhen using LLM\u2019s public APIs, some of the underlying models (or at least parts\nof their stack) occasionally change under the hood, often without notice. This\ncan potentially have detrimental effects on the tasks we\u2019re performing by\nbreaking it.\n\n## The good news\n\nLLMs are strong tools, and the structured tasks use-case can be very powerful\nand stable with the correct development process and habits. The even better\nnews is that this process and habits are practically the same as the ones\nrequired for software engineering anyway: careful development, thorough\ntesting on a diverse set of samples, and reasonable monitoring to make sure it\nworks as we expect it to.\n\nAmbiguity and fragility challenges can all be addressed with careful\ndevelopment and basic testing, on a small set of query samples with expected\noutput- similar to unit tests.\n\nStability challenges can be addressed by testing on a broader set of use\ncases, along with periodic scheduled testing- similar to system tests.\n\n## Promptotype- The platform for { structured } prompt engineering\n\nPromptotype is a prompt development platform focusing on this specific use\ncase of LLM structured tasks.\n\nIt provides you with an extended playground- letting you define templated\nprompts, function calling (if relevant), and model configuration.\n\nWhile developing in the playground, you can test your prompts on query inputs\n(the values for the templated prompt\u2019s variables), by comparing the response\nwith a defined expected response: JSON value or schema, or function calling\nvalue. Initially creating the expected response can even be done semi-\nautomatically by running your query through the model, and then simply\nadjusting the incoming response.\n\nThe more important feature is the ability to define whole collections of\nqueries and run them at once with every adjustment iteration. You can also\ndefine scheduled periodic runs of these collections, to ensure everything\nkeeps performing as expected.\n\nThis set of features helps overcome all of the four challenges mentioned\nbefore.\n\nYou\u2019re more than welcome to sign up and check out Promptotype for free right\nnow! https://www.promptotype.io\n\n## Coming Soon\n\nWe\u2019re planning to write a few follow-up blog posts, a few major ones that come\nto mind are development challenges with a demo product example, considerations\nof when and how to test your prompts (spoiler: it doesn\u2019t fit perfectly to\nexisting CI/CD testing methodologies), and techniques for using AI to improve\nyour prompts or models.\n\nSigned-up Promptotype users get an email with news so you\u2019re more than welcome\nto sign up, even just to follow (it\u2019s free).\n\nUntil next time- happy prompting! Ram from Promptotype\n\n", "frontpage": false}
