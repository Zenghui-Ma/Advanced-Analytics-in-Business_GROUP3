{"aid": "40145103", "title": "My Experience with Large Language Models", "url": "https://amycatgirl.nekoweb.org/blog/my-experience-with-ai/", "domain": "nekoweb.org", "votes": 1, "user": "mdwalters", "posted_at": "2024-04-24 14:54:38", "comments": 0, "source_title": "My experience with Large Language Models", "source_text": "My experience with Large Language Models\n\nSkip to main content\n\n## My experience with Large Language Models\n\nPublished on 24 April 2024\n\n#ib #external-assessment #artificial-intelligence #school-project #large-\nlanguage-models #llm #ai #personal #gemini #google #openai\n\nArtificial intelligence has changed the world as we know it. Many companies\nare dropping of their previous metaverse frenzy to get their hands on some of\nthe potential profit that AI products offer. At this point, you might be\nfamiliar with the concept of what an AI model is, or at least, a rudimentary\nimage of what the concept entails.\n\nBut what if I told you that we are not quite on the AI era? Or that AI will\nnot \"render out jobs as X useless\"?\n\nWell, we might not be there just yet, and it might seem that it's progressing\nat a rather alarming rate, but in reality, we are really far from the concept\nof a fully automated, accurate and efficient AI.\n\nWith this article, I want to talk a little bit about LLMs (or Large Language\nModels), My experience with them, as a Student and frontend developer, and\ntheir impact that they have on our world.\n\n## What is an AI? link\n\nAn AI model, at it's core, is a big neural network, trained using hundreds,\nthousands, heck even millions of tokens. From what I understand, tokens are\nbasically words; Whenever you see a model with a number and a letter as it's\nsuffix, it usually means the amount of \"tokens\" that they've been trained on.\nThese models are trained using rewards, like we use treats to tell our dogs\nwhat's good or bad. What I mean by this is that, these models \"try\" to predict\nwhich response out of a given prompt gives out the most results (aka. the best\nresult). This process is called re-enforcement training and it's the most\nwidely used training method used in AI models.\n\nNow that you probably have, at the very least, a better grasp of what I am\ntalking about, and how it works, I'll talk about my overall experience with\nGemini/Bard, Google's \"magnum opus\" on the current AI arms race.\n\n## My experience with Gemini link\n\nIf I could summarise my experience with Gemini in a singular word, it would be\n\"clueless\".\n\nWhy clueless? You may ask.\n\nI say clueless because, most of the time, you have to use it's double check\nfeature to make sure it doesn't hallucinate, other times, it would tell you\nthat it doesn't know the answer to the question.\n\nYou might say that the questions that I've asked the model were \"Too complex\"\nor \"Too recent\". But nope, they weren't either complex, nor recent. In fact, I\nasked about Nicolas the Ovando's life, which was a governor on la Hispaniola\n(which if you didn't know, is the name of our island), and the model replied\nwith:\n\n> \"I don't know the answer to the question yet\"\n>\n>   * Gemini\n>\n\nAfterwards, I was able to look up the answer to the question I've had in like,\nno time at all.\n\nAnother example would be generating code, more specifically, Kotlin code. I\nasked about Kotlin naming schemes, as I didn't understand how to name files.\nIt took me about 3 to 4 separate prompts to get an answer I could understand\nand apply to my code.\n\n## General thoughts link\n\nWhilst I do understand that AI models are in continuous development, and that\nthey will get better as time goes on, I think it's wrong to advertise them as\nsuch. As artificial intelligence, I mean.\n\nThis might seem like I am downplaying the efforts of countless bright minds\nbehind this amazingly complex invention, but I personally thing that they are\nnothing but fancy and expensive prediction machines. Mostly because they are\nreally good at recognising patterns and predicting what should go next, after\nall, that's how they choose responses.\n\n## Ethical issues link\n\nTo conclude, let's talk about ethical issues with AI.\n\nAs you probably know, I am an artist. I draw furries and I publish my art on\nPixelfed and Mastodon under CC-BY 4.0 I licence my artwork under a creative\ncommons license to avoid art theft, I don't want other people to steal my art\nwithout my explicit permission because I take a lot of time to get motivation\nto draw, and actually finish the artwork.\n\nIt turns out that AI models like Google's Gemini, OpenAI and Microsoft Copilot\ntake all sorts of copyrighted material, from licensed code without\nattribution, to artwork from artists that have a watermark to avoid the\npreviously mention art theft. And those companies are perfectly fine with such\npractices, in fact, let me mention a quote from Sam Altman on an interview\nconducted with him:\n\n> \"AI wouldn't be possible without copyrighted material\"\n>\n>   * Sam Altman\n>\n\nThat, of course, is completely unethical, but that's the sad reality we are\nliving in. Currently, there are no regulations that prevent this kind of\nactivities from being performed by companies, it's a legal gray area.\n\nI feel like when that gets sorted out, then more people will start using AI.\nOh, and let's not forget the fact that a bunch of companies are shoving AI\nusage to your face every time. Not sure if that's even ethical, it probably is\nbut it might as well not be.\n\nIt's a mess.\n\nPrevious Post: Github Actions automatic publishing test\n\n", "frontpage": false}
