{"aid": "40046357", "title": "A $3M Dropdown (2023)", "url": "https://sentry.engineering/blog/3m-dollar-dropdown", "domain": "sentry.engineering", "votes": 1, "user": "mooreds", "posted_at": "2024-04-15 22:21:02", "comments": 0, "source_title": "A $3,000,000 Dropdown", "source_text": "A $3,000,000 Dropdown\n\nSentry Engineering\n\nWebInfrastructureBuilding SentryTagsOpen Source\n\nPublished on\n\n    Wednesday, November 15, 2023\n\n# A $3,000,000 Dropdown\n\nAuthors\n\n    \n\n  * Name\n    Mike Ihbe\nTwitter\n\n    @mikeihbe\n\n### TLDR; Shameless Plug\n\nSentry is excited to offer EU Data Residency (from Frankfurt, Germany) to our\ncustomers on **all** plan tiers and at no extra cost. Fill out our form for\nearly access or wait for the GA planned in December.\n\nOn to the technical goodies...\n\n# The Project\n\nAlmost 2 years ago, Sentry embarked on a project to bring true data residency\nto our customers. We decided to do it the hard way.\n\nWe\u2019ve been fully compliant with GDPR through data processor contracts, but we\nwanted to side-step the lawyers and enable customers to truly host their data\nin the EU. Many Sentry users, big and small, have been self-hosting Sentry\nbecause we were unable to provide in-jurisdiction data storage for them.\n\nSuperficially, supporting the EU is as simple as adding a dropdown to our\norganization creation flow. We did in fact do that, but there is a mountain of\nwork that happened behind the scenes that we want to share!\n\nThis is the $3M dropdown in the Sentry organization creation flow that sets\nwhere your customer data is stored:\n\n> \ud83d\udcb0 ~15 people working part or full time over >18 months in San Francisco and\n> Toronto easily tops $3M.\n\n# Optimizing for User Experience\n\nOne of the primary goals of this project was to deliver a great user\nexperience for our customers. This drove most of our decision-making.\n\nA simple implementation would've involved deploying a completely disjointed\ninstance of Sentry in the EU. Unfortunately, this would\u2019ve been a terrible\nuser experience for many customers.\n\nYou\u2019ve probably experienced the bad UX I\u2019m talking about with other products.\nEvery time you want to log in, you have to tell them your email address or the\nname of your organization, then they send you a link to the right URL where\nyou can actually log in.\n\nWe wanted to avoid that rigamarole \u2013 for several reasons. About half of\nSentry\u2019s users are in multiple Sentry organizations, and those organizations\ncan now be in different data centers. Imagine having to wait for an email link\nevery time you wanted to switch organizations?\n\nWe wanted to do better. We wanted to maintain your ability to seamlessly\ntoggle between Sentry organizations anywhere in the world.\n\nWe also have 1000s of organizations that share the same 3rd party integration\ntarget with multiple Sentry organizations. Sometimes several teams within a\ncompany will create their own Sentry orgniazations but share a single GitHub\naccount or Slack workspace. Or a parent company can have many subsidiaries\n(each with their own Sentry organization) that all share a Jira instance. We\ndidn\u2019t want to break any of these customer workflows just because customers\nopt to have organizations in multiple locales.\n\nWe worked hard to design a solution that maintained these optimal experiences,\nand that was as backward compatibile and as fault-tolerant as possible.\n\n# An architecture that optimizes for UX\n\n## First, some context\n\nSentry is a monolithic Python Django application deployed in several form\nfactors (web servers, Kafka consumers, Celery workers, etc). The application\nis backed by several PostgreSQL and Redis clusters, Google Cloud Storage,\nSnuba and Clickhouse clusters, and a bunch of other services like Relay and\nSymbolicator that are associated with our processing pipeline.\n\n> \ud83e\ude9a Our job was to take this monolithic hydra of an application and surgically\n> divide all the pieces that need to be centralized from all the customer data\n> that needs to be localized all while the application is running and 100ish\n> other engineers are working on the project.\n\nSome stats to illustrate the scope of the sentry monolith:\n\n## Our approach\n\nThe most important thing we did was to articulate a clear difference between\nSentry user data (its users) and Sentry\u2019s customers\u2019 data (event data).\nCustomer event data must never leave the region it was sent to, but Sentry\nuser data has to be reachable everywhere.\n\n## Splitting the data model\n\nGiven those constraints, we began by introducing the concept of \u201csilos\u201d. A\nsingle \u201ccontrol silo\u201d contains globally unique data and many \u201cregion silos\u201d\ncontain Sentry\u2019s customer\u2019s data.\n\nThe control silo holds globally unique information like organization data,\nuser accounts, slugs, and integration configuration. The region silos contain\nall of an organization\u2019s events, projects, and other customer-specific\ninformation.\n\nWe then assigned each model to a silo and went about breaking all foreign keys\nbetween models located in different silos. This required roughly 80 migrations\nas well as refactoring all queries that joined data across silo boundaries to\neither fundamentally change how they work or replace them with RPC calls.\n\n## Cross silo interaction\n\nCustomer data cannot be fetched from region silos, which is the key principle\nof the design, but there are lots of cases where region silos need user\ninformation to check permissions or fetch notification settings to properly\nsend an alert. To handle these cases, we ended up building two primary\nmechanisms: RPCs and a transactionally written event queue (aka an \u201coutbox\u201d)\nthat we use to ensure eventual consistency.\n\n### Remote Procedure Calls\n\nWe ended up building a fairly standard RPC implementation that allows us to\ndefine a pure python interface that accepts simple dataclasses as arguments,\nthen we provide a single concrete implementation of the interface. We have\nsome decorators and helper methods that wrap up the interface and autogenerate\nan HTTP client implementation that handles arguemnt serialization, etc and\nconnects to our RPC endpoint that re-marshals the data and handles dispatching\nto the concrete implementation.\n\n\u2014> Go see some code \u2014>\n\n#### Why not GRPC?\n\nWe strongly considered it, but adopting a code gen tool for this was a bit\ncontroversial internally, and this wasn\u2019t that hard to implement, so we just\nbuilt it \ud83e\udd37.\n\n### RPC Versioning\n\nBreaking API changes can be a big problem. Particularly when we have to run\ndifferent versions of Sentry all over the world in a backward compatible way.\nThat's why we are building a tool that publishes the OpenAPI spec for our RPC\ninterfaces and can detect incompatible version drift (like removing arguments\nor adding arguments without a default). In practice, so far at least, these\nAPIs don\u2019t change much, so we\u2019ve been prioritizing shipping this to customers,\nbut we\u2019ll be circling back to ship this to ensure that all of our cross-silo\ncommunication remains stable.\n\n### Cross Region Replication\n\nWe had some hearty debate about how to handle data replication where we needed\nit. We wanted to strike the right balance between network efficiency,\nexplicitness, and ease of correct use. We didn\u2019t want to require intervention\nfrom our ops team to replicate a new table, but we also didn\u2019t want it to be\ntoo easy for developers to move data around that they shouldn\u2019t be moving.\nExplicitness was key to the implementation so we could confirm correctness.\n\n#### Why not Change Data Capture (CDC)?\n\nSentry has a lot of wildly varying deployment modes that we need to handle:\nself-hosted, development environments, test suites, single tenants, and\nproduction SaaS. Our replication needs also occasionally involve business\nlogic that needs to be tested. Between the operational complexity and our need\nfor custom business logic, we opted to fully define our replication\nimplementation within the application logic so that it would just work\neverywhere and be easy to test.\n\n### Cross silo synchronization\n\n#### Webhook Proxying\n\nSentry receives webhooks from many third parties, ranging from repository\nproviders like GitHub to payment processors like Stripe. Many of these\nintegrations only allow for a single webhook destination. This created a\nsignificant challenge for our multi-region architecture: where should webhooks\ngo? We chose a design that receives all integration webhooks in the Control\nSilo. Once received, webhook payloads are stored as outbox messages which are\ndelivered to the relevant region as if it came from the integrating service\ndirectly. This design allowed us to avoid rewriting complex webhook handling\nlogic and focus our efforts on extracting routing information from webhooks\nand proxying hooks to the relevant region in an eventually consistent way.\n\n#### 3rd Party Integrations\n\nSentry allows third party integrations to be shared across organizations. This\nwas no problem when all requests to the third party originated from the same\nplace, but now these organizations can be in different regions. This causes a\nproblem: any of the requests to a third party from any region could trigger an\nOAuth token refresh that other silos need to be immediately aware of. Eventual\nconsistency driven by our outbox system is insufficient for meeting this\nrequirement.\n\nIn order to provide this synchronization, we built an OAuth aware 3rd party\nproxy that handles token refreshes and allows us to maintain a single source\nof truth for OAuth tokens. The trade off for correctness here is that all 3rd\nparty API traffic has to go through this proxy that lives in the control silo.\n\n## Learnings & Challenges\n\nThis post was only able to scratch the surface of the many interesting\nchallenges we encountered in this project. We\u2019ll be covering many of these\ntopic in more detail in an upcoming blog series after we go live.\n\nCustomer Domains| Deploy Pipelines  \n---|---  \nUpgrading Columns to BigInt| Audit Logs & User IP Records  \nDistributed ID Generation| Admin UX Changes  \nCross Region Replication| Move Marketo Domain  \nControl Silo Webhook Forwarding| Update ETL for Control Silo  \nEndpoint Allocation & Enforcement| Update ETL for Region Silos  \nModel Allocation & Enforcement| Dangerous Migrations in Multi-Region  \nAPI Gateway| Relay in Each Region  \nInfra Provisioning for Regions| Datadog Observability Consolidation  \nInfra Provisioning for Control| RPC Implementation  \nRegion Selection UX| CI with Logically Split DBs  \nNew APIs for Non-Organization Resources| CI with Actually Split DBs  \nFeature Flagging Across Regions  \n  \nIf there's anything specific you'd like to hear more about, hit us up on\nDiscord or Twitter!\n\n# How do I get it?\n\nWe\u2019re currently in the process of launching the new EU region. If you\u2019re\ninterested in early access, you can sign up here\nhttps://sentry.io/trust/privacy/#data-residency-form.\n\nWe also have new tooling coming soon to support relocating organizations from\nself-hosted to EU/US region as well as between the EU/US regions. We\u2019ll update\nhere as soon as it\u2019s available.\n\nDiscuss on Twitter \u2022 View on GitHub\n\n## Tags\n\nbuilding-sentry\n\n## Share\n\ntwitterhackernews\n\n## Previous Article\n\nScaling Cron Monitoring\n\n## Next Article\n\nImproving Node.js loader performance\n\n\u2190 Back to the blog\n\ngithubyoutubelinkedintwitter\n\n\u00a9 2024\n\n\u2022\n\nSentry Engineering\n\n\u2022\n\nRSS\n\n\u2022\n\nChangelog\n\n", "frontpage": false}
