{"aid": "40098480", "title": "Data Engineering Challenges and How Airbyte Solves Them", "url": "https://airbyte.com/blog/data-engineering-challenges-how-airbyte-solves-them", "domain": "airbyte.com", "votes": 1, "user": "makaimc", "posted_at": "2024-04-20 16:23:05", "comments": 0, "source_title": "The Top 3 Data Engineering Challenges & How Airbyte Solves Them | Airbyte", "source_text": "The Top 3 Data Engineering Challenges & How Airbyte Solves Them | Airbyte\n\nOpens in a new window Opens an external website Opens an external website in a\nnew window\n\nThis website utilizes technologies such as cookies to enable essential site\nfunctionality, as well as for analytics, personalization, and targeted\nadvertising purposes. You may change your settings at any time or accept the\ndefault settings. You may close this banner to continue with only essential\ncookies. Privacy Policy\n\nComplete the State of Data & AI Survey for a chance to win a Steam Deck!\n\nView Press Kit\n\nData Insights\n\nArticle\n\n# The Top 3 Data Engineering Challenges & How Airbyte Solves Them\n\nPierre Carpentier\n\n\u2022\n\n\u2022\n\nApril 19, 2024\n\n\u2022\n\n10 min read\n\nWhy would you have to make data engineering so complicated?\n\nAt one point-in-time, large organizations needed another type of CEO \u2013 the\nChief Electricity Officer. This was a time before there was an accessible and\nreliable grid to plug into. Organizations that required complex electricity\nsetups employed a CEO. They became extinct over 100 years ago due to the\nstandardization of the consumption layer, and increased availability and\nreliability of electricity from the main grid.\n\nEnter the role of the Chief Digital Officer (CDO), sometimes now called the\nChief Digital and Artificial Intelligence Officer (CDAIO). Similar to the CEO\nin my example, this role exists to create accessible and reliable technology\nsolutions.\n\nWe\u2019re at a turning point in human history where multiple life changing\ntechnologies are coming of age all at once, the most prevalent such as\nGenerative AI becoming mainstream only recently. The dirty little secret of\nGenerative AI, and broader AI applications is that the outcome is heavily\ninfluenced by the quality and understanding of the context from the model\nbeing used, and the underlying data.\n\nIn my experience, this is also true in something as simple as producing a\ndashboard. In the end, technology, no matter how complex it is under the hood,\nbreaks down when there is a misunderstanding as to the meaning of the outcome.\n\nHaving been a frustrated business executive, looking at numbers on dashboards\nthat don\u2019t make sense, and having also helped customers build data analytics\nstacks from scratch, I can say that the gap comes from a chasm between\nknowledge about the business, and semantic details of how the information gets\nprocessed.\n\nIn large corporate environments, a notion as simple as a \"customer\" can\nliterally have 3 different meanings depending on who you talk to, and come\nfrom 6 different systems all with different naming conventions that need to be\ntransformed. This is because the goal of software systems and the engineers\nthat make them is to create a working, and usable transactional system that\nsolves a unique need for the department or business (an HR system like\nWorkday, an ERP like SAP, etc.). Connecting information in a meaningful way\nacross these systems is where the challenges lie.\n\nWith that in mind, here are 3 top challenges for achieving data engineering\ntraction and justifying ROI, followed by strategies to overcome them.\n\n# Top 3 Most Common Data Engineering Challenges\n\n### Challenge 1: Resource Efficiency in Data Management\n\nYour most expensive resources still spend a significant amount of time simply\nmoving data around and managing it. While it is necessary to achieve the end\nresult, it is a non-value added task that can and should be streamlined as\nmuch as possible by the many available tools in the modern data stack. One of\nthe major reasons the E (Extract) in ETL/ELT is due to source variety, and\nsource complexity. As you can see in the graph below, the most expensive\nresources spend well over 45% of their time loading and cleaning data. In my\nexperience, these resources perform the Extract piece manually in a way that\nis not reusable.\n\nHow data scientists spend their time. Image courtesy: Anaconda \u201c2020 State of\nData Science: Moving From Hype toward Maturity\".\n\n### Challenge 2: The Complexity of Data Engineering Tooling\n\nThe big data engineering tooling vendors that large corporate entities\ntypically favor are not incentivized to help you solve your data engineering\nissues. Though the tools offered by large vendors and hyperscalers solve parts\nof the data engineering problem, the bigger vendors are incentivized by having\nyou and your company utilize their solution at scale. What this means is that\nthere is not only cost pressures from an expensive resources perspective, but\ncost pressures from different SaaS vendors at play.\n\nSome vendor decisions are also not reversible, meaning, if you favor open\nsource or other tools down the line, the switching cost is extremely high. A\ncomplement to this challenge is that your team needs to be trained on the\nspecific toolset, and, oftentimes there is no active general community to help\nsolve issues you may have with the tooling, you need to rely on the vendor who\noften charges for these services.\n\nBCG, A New Architecture to Manage Data Costs and Complexity\n\n### Challenge 3: Infrastructure and Cost Management\n\nThe third most common challenge is related to infrastructure setup and\nmaintenance. Depending on the architecture of your data stack, and the\ncapabilities of your internal team to manage infrastructure, you may end up\nfavoring a mix of SaaS solutions instead of setting up OSS solutions in your\nown infrastructure.\n\nManaging infrastructure is also a non-value added activity but a necessary one\ngiven the complexities of the toolset available in data engineering today.\nWhat this means is that oftentimes, the total cost of ownership of the entire\ndata engineering stack is unknown to the business from a CAPEX vs. OPEX\nperspective and the costs creep up over time. When data engineering related\nprojects reach a certain scale, it will end up requiring even a fully\nfunctional data engineering team to justify their ROI and usage to the\nbusiness users funding the activities.\n\nIn fact, a recent industry study performed by Dremio concluded that 56% of\ncompanies dealing with big data expect that they can achieve an overall\nsavings of over 50% on their total cost of ownership if they rethought their\ndata stack!\n\nBCG, A New Architecture to Manage Data Costs and Complexity\n\n## Strategies to Overcome Data Engineering Challenges\n\nGiven all these complexities, and gaps between technology and business\nstakeholders, how can one successfully tackle the common challenges in data\nengineering and become a major value driver for the organization? Here are 3\ngeneral categories that can help frame a solution.\n\n### Strategy 1: Optimizing Resource Allocation\n\nFind out where your most expensive resources are spending most of their time.\nYou can do this by performing a simple time study of daily activities. If\nyou\u2019re worried about a \"big-brother\" vibe with your best technical resources,\nexplain to them that the reason for the study is to find ways to remove\nbarriers and use their time for value-added work.\n\nMost technical people I\u2019ve met welcome ways for work to be easier and more\nenjoyable. If it turns out the source variety is causing a lot of time to be\ndevoted to simply extract (the E in ETL/ELT), consider open-source and readily\navailable tools like Airbyte that is built to make Extraction very easy and\nquick to set up and maintain. With this burden reduced, the ROI on your entire\ndata team will go up as the people will spend more time on delivering value to\nthe business.\n\n### Strategy 2: Simplifying the Data Stack\n\nAnalyze all the various tools being used in your data stack both from a fit\nand purpose perspective. In almost all cases that I\u2019ve been personally\ninvolved in, the data stack was too complex, built over years of various pet\nprojects and systems being implemented.\n\nPro-tip: you don\u2019t need to map out the entire enterprise data model to get\nstarted. Simply take the top 5 most used or highest value data pipelines, and\nfollow the data from source all the way to consumption. Map out all the\nvarious tools, transformations, and manual efforts required to get data moving\nacross the stack. Think of it in terms of ETL/ELT.\n\nIf it turns out you have multiple tools and methods for extraction, multiple\ntools for transformations, and multiple tools for loading and storing, you may\nneed to consolidate and find a way to simplify your tech stack down to the\nindustry leading toolset.\n\nFor extraction, Airbyte provides the largest pre-built connector set in the\nindustry and should cover most if not all your use cases.\n\n### Strategy 3: Calculating Total Cost of Ownership\n\nCalculate the Total Cost of Ownership of your current data stack. This\nincludes all the tools, equipment, resources, etc. Thinking of it from a\nbusiness perspective, you are trying to weigh the benefits and value of having\na data engineering team versus the cost for building and maintaining the team.\n\nIf you are a technical manager or leader, this is important because this is\nhow the executive branch and the people funding your initiatives think about\nthe business. The tricky part here is defining the benefits of running a\nproper data engineering team. Oftentimes, with proper analytics setup,\ncompanies can offer new products or services, avoid costly mistakes, etc. Do\nyour best to try and find value or past use cases where having the data team\nproved to be beneficial.\n\nThe cost piece of the equation should be more straightforward though sometimes\ndifficult to drill across what is CAPEX vs OPEX. If your own internal ROI\ncalculation doesn\u2019t look positive, this is a sign that you need to adopt new\nstrategies and focus your results on the highest impact initiatives.\n\nAll data engineering work starts with Extraction, and ends with a curated\ndataset that is used for various reasons. Moving towards industry leading\narchitectures like the lakehouse or medallion architecture help to separate\nconcerns and cost between compute and storage, and really leverage the\nscalability of the cloud.\n\nTools like Airbyte plug in perfectly with this type of architecture, and, very\nimportantly, are vendor agnostic, meaning that they are not locked into a\nspecific cloud vendor and you can even run workloads on-premises as required.\n\n## Conclusion\n\nHopefully you have found this article beneficial for how to think about\nnarrowing down and focusing on data engineering challenges. Thanks to tools\nlike Airbyte, you can make data Extraction as seamless as turning on the\nlights, freeing up valuable time and efforts for your advanced analytics\nresources to develop models that will help take advantage of the recent wave\nin Artificial Intelligence.\n\nLimitless data movement with free Alpha and Beta connectors\n\nIntroducing: our Free Connector Program ->\n\nThe data movement infrastructure for the modern data teams.\n\nTry a 14-day free trial\n\n### About the Author\n\nPierre Carpentier, B.Eng, MBA, brings a unique blend of management and\ntechnical expertise in big data engineering, AI/ML analytics, and cloud-native\napplication development, honed over 20 years in technology leadership roles of\nincreasing responsibility across diverse sectors. As the founder of Data-Sage,\nhe currently focuses on helping customers across asset heavy industries to\nadopt Advanced Data Engineering architectures and best practices. His prior\nroles include leading digital transformations at Cyient and contributing to\nstrategic initiatives at Pratt & Whitney Canada, where he consistently drove\ntechnological advancements and revenue growth. Pierre's significant experience\nalso extends to guiding startups as an advisor, where he emphasizes innovation\nand efficient scaling.\n\n### About the Author\n\n## Table of contents\n\nChallenge 1: Resource Efficiency in Data Management\n\nChallenge 2: The Complexity of Data Engineering Tooling\n\nChallenge 3: Infrastructure and Cost Management\n\nStrategies to Overcome Data Engineering Challenges\n\nStrategy 1: Optimizing Resource Allocation\n\nStrategy 2: Simplifying the Data Stack\n\nStrategy 3: Calculating Total Cost of Ownership\n\nConclusion\n\nExample H2\n\n## Join our newsletter to get all the insights on the data stack\n\n## Related posts\n\nArticle\n\nYou Can Now Manage and Orchestrate Airbyte Connections Using Python\n\nAJ Steers\n\n\u2022\n\nApril 18, 2024\n\n\u2022\n\n10 min read\n\nArticle\n\nCost-Conscious Advanced ELT Strategies for Data Deduplication\n\nEvan Tahler\n\n\u2022\n\nApril 17, 2024\n\n\u2022\n\n8 min read\n\nArticle\n\nReplicating MySQL: A Look at the Binlog and GTIDs\n\nJacob Prall\n\n\u2022\n\nMarch 15, 2024\n\n\u2022\n\n6 min\n\nArticle\n\nDBaaS Migration Speedrun: PlanetScale to Timescale Cloud\n\nJacob Prall\n\n\u2022\n\nMarch 13, 2024\n\n\u2022\n\n2 min read\n\nAirbyte is an open-source data integration engine that helps you consolidate\nyour data in your data warehouses, lakes and databases.\n\n\u00a9 2024 Airbyte, Inc.\n\nProduct\n\nFeaturesDemo AppConnectorsConnector Builder and CDKPyAirbyteAirbyte Open\nSourceAirbyte CloudAirbyte Self-ManagedCompare Airbyte\noffersPricingChangelogRoadmapCompare top ELT solutions\n\nRESOURCES\n\nDocumentationBlogAirbyte API DocsTerraform Provider DocsCommunityData\nEngineering ResourcesTutorialsQuickstartsNewsletterResource centerCommunity\nCallState of Data surveyTop ETL Tools\"How to Sync\" TutorialsConnectors\nDirectory\n\nCOMPANY\n\nCompany HandbookAbout UsCareersOpen employee referral programAirbyte YC\nStartup ProgramPartnersPressData protection - Trust reportTerms of\nServicePrivacy PolicyCookie PreferencesDo Not Sell/Share My Personal\nInformationContact Sales\n\n## Get answers quick on Airbyte Slack\n\nHi there! Did you know our Slack is the most active Slack community on data\nintegration? It\u2019s also the easiest way to get help from our vibrant community.\n\nJoin Airbyte SlackI\u2019m not interested in joining\n\n", "frontpage": false}
