{"aid": "40127440", "title": "How to Summarize Large Documents with LangChain and OpenAI", "url": "https://thenewstack.io/how-to-summarize-large-documents-with-langchain-and-openai/", "domain": "thenewstack.io", "votes": 1, "user": "Bella-Xiang", "posted_at": "2024-04-23 01:19:48", "comments": 2, "source_title": "How to Summarize Large Documents with LangChain and OpenAI", "source_text": "How to Summarize Large Documents with LangChain and OpenAI - The New Stack\n\nTNS\n\nSUBSCRIBE\n\nJoin our community of software engineering leaders and aspirational\ndevelopers. Always stay in-the-know by getting the most important news and\nexclusive content delivered fresh to your inbox to learn more about at-scale\nsoftware development.\n\nREQUIRED\n\nIt seems that you've previously unsubscribed from our newsletter in the past.\nClick the button below to open the re-subscribe form in a new tab. When you're\ndone, simply close that tab and continue with this form to complete your\nsubscription.\n\nThe New Stack does not sell your information or share it with unaffiliated\nthird parties. By continuing, you agree to our Terms of Use and Privacy\nPolicy.\n\nWelcome and thank you for joining The New Stack community!\n\nPlease answer a few simple questions to help us deliver the news and resources\nyou are interested in.\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nGreat to meet you!\n\nTell us a bit about your job so we can cover the topics you find most\nrelevant.\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nWelcome!\n\nWe\u2019re so glad you\u2019re here. You can expect all the best TNS content to arrive\nMonday through Friday to keep you on top of the news and at the top of your\ngame.\n\nWhat\u2019s next?\n\nCheck your inbox for a confirmation email where you can adjust your\npreferences and even join additional groups.\n\nFollow TNS on your favorite social media networks.\n\nBecome a TNS follower on LinkedIn.\n\nCheck out the latest featured and trending stories while you wait for your\nfirst TNS newsletter.\n\nPREV\n\n1 of 2\n\nNEXT\n\nVOXPOP\n\nWhat\u2019s Slowing You Down?\n\nWhat is your biggest inhibitor to shipping software faster?\n\n\u2713\n\nComplicated codebase and technical debt.\n\n0%\n\n\u2713\n\nQA, writing tests, and debugging.\n\n0%\n\n\u2713\n\nWaiting for PR review or stakeholder approval.\n\n0%\n\n\u2713\n\nI'm always waiting due to long build times.\n\n0%\n\n\u2713\n\nRework due to unclear or incomplete specifications.\n\n0%\n\n\u2713\n\nInadequate tooling or infrastructure.\n\n0%\n\n\u2713\n\nOther.\n\n0%\n\nThanks for your opinion! Subscribe below to get the final results, published\nexclusively in our TNS Update newsletter:\n\nARCHITECTURE\n\nCloud Native Ecosystem Containers Edge Computing Microservices Networking\nServerless Storage\n\nENGINEERING\n\nAI Large Language Models Frontend Development Software Development API\nManagement Python JavaScript TypeScript WebAssembly Cloud Services Data\nSecurity\n\nOPERATIONS\n\nPlatform Engineering Operations CI/CD Tech Careers Tech Culture DevOps\nKubernetes Observability Service Mesh\n\nCHANNELS\n\nPodcasts Ebooks Events Newsletter TNS RSS Feeds\n\nTHE NEW STACK\n\nAbout / Contact Sponsors Sponsorship Contributions\n\nPODCASTS EBOOKS EVENTS NEWSLETTER\n\nARCHITECTURE ENGINEERING OPERATIONS\n\nCloud Native Ecosystem Containers Edge Computing Microservices Networking\nServerless Storage\n\nHow Giant Swarm Is Helping to Support the Future of Flux\n\nApr 22nd 2024 7:59am, by Heather Joslyn\n\nWhat\u2019s Next for Companies Built on Open Source?\n\nApr 18th 2024 7:13am, by Heather Joslyn\n\nYour Engineering Organization Is too Expensive\n\nApr 17th 2024 11:19am, by Luca Galante\n\nTetrate Enterprise Gateway for Envoy Graduates\n\nApr 10th 2024 9:00am, by Steven J. Vaughan-Nichols\n\nThe Open Source Market\u2019s in Flux. How Can IT Managers Cope?\n\nApr 8th 2024 10:57am, by Joe Fay\n\nHow to Use Low-CVE Chainguard Container Images on Docker Hub\n\nApr 19th 2024 8:04am, by B. Cameron Gain\n\nKubernetes vs. YARN for Resource Management: How to Choose\n\nApr 10th 2024 8:16am, by Jacob Simkovich\n\nUse Podman to Create and Work with Virtual Machines\n\nApr 6th 2024 6:00am, by Jack Wallen\n\nPodman 5 Arrives with Multiplatform Images, VM Support\n\nApr 4th 2024 5:00am, by Jack Wallen\n\nChainguard: Outdated Containers Accumulate Vulnerabilities\n\nMar 29th 2024 3:00am, by Joab Jackson\n\nAmbient AI? Humane's 'Ai Pin' Embarks on a Dream's Long Road\n\nApr 21st 2024 6:00am, by David Cassel\n\nChipmakers Putting a Laser Focus on Edge AI\n\nApr 12th 2024 10:06am, by Jeffrey Burt\n\nThe Future of AI: Hybrid Edge Deployments Are Indispensable\n\nMar 22nd 2024 10:00am, by Luis Ceze\n\nHow RapidAI Uses Edge, Kubernetes and AI to Boost Stroke Care\n\nMar 15th 2024 10:30am, by Charles Humble\n\nTrusted Boot: What to Know About Securing Devices at the Edge\n\nMar 14th 2024 7:15am, by Ettore di Giacinto\n\nAPI Design Is Pretty Bad \u2014 Here's How to Fix It\n\nApr 3rd 2024 6:01am, by Lebin Cheng\n\nWill Spotify Open Source its Microservices Framework?\n\nApr 2nd 2024 7:45am, by Loraine Lawson\n\nEnhancing Business Security and Compliance with Service Mesh\n\nApr 1st 2024 10:00am, by Ninad Desai\n\n10 Ways Kubernetes Observability Boosts Productivity, Cuts Costs\n\nMar 27th 2024 6:08am, by Eric Schabell\n\nEvolve Manual and Templated Dockerfiles with Automation\n\nMar 26th 2024 10:33am, by Rak Siva\n\nGuider Daemon Automates Linux Performance Monitoring\n\nApr 19th 2024 11:16am, by Joab Jackson\n\nEnhancing Kubernetes Network Security with Microsegmentation\n\nApr 11th 2024 6:23am, by Dhiraj Sehgal\n\nTetrate Enterprise Gateway for Envoy Graduates\n\nApr 10th 2024 9:00am, by Steven J. Vaughan-Nichols\n\nZero Trust for Legacy Apps: Load Balancer Layer Can Be a Solution\n\nApr 10th 2024 7:22am, by Prabhat Dixit\n\nHow Observability Is Different for Web3 Apps\n\nMar 15th 2024 12:00pm, by Sarah Morgan\n\nMeet DBOS: A Database Alternative to Kubernetes\n\nMar 12th 2024 4:00am, by Joab Jackson\n\nPulumi Templates for GenAI Stacks: Pinecone, LangChain First\n\nFeb 21st 2024 9:00am, by Joab Jackson\n\nCNCF CloudEvents: A Li'l Message Envelope That Travels Far\n\nJan 31st 2024 4:00am, by Joab Jackson\n\nBringing the AWS Serverless Strategy to Azure\n\nJan 19th 2024 6:00am, by Rak Siva\n\nServerless Computing In 2024: GenAI Influence, Security, 5G\n\nJan 4th 2024 5:00am, by Chris J. Preimesberger\n\nHow to Get Peak Performance without a Vast Amount of Memory\n\nApr 9th 2024 10:17am, by Behrad Babaee\n\nFrom Postgres to ScyllaDB NoSQL, with a 349x Speed Boost\n\nApr 1st 2024 11:27am, by Cynthia Dunlop\n\nThe Architect\u2019s Guide: A Modern Data Lake Reference Architecture\n\nMar 26th 2024 9:17am, by Keith Pijanowski\n\nCloud Data Migration or Cloud Data Tiering?\n\nMar 25th 2024 10:00am, by Kumar Goswami\n\nKubeCon24: MinIO Object Store Equipped with Enterprise Features\n\nMar 19th 2024 2:00pm, by Joab Jackson\n\nAI Large Language Models Frontend Development Software Development API\nManagement Python JavaScript TypeScript WebAssembly Cloud Services Data\nSecurity\n\nHow to Summarize Large Documents with LangChain and OpenAI\n\nApr 22nd 2024 9:41am, by Usama Jamil\n\nAI in Platform Engineering: Concerns Grow Alongside Advantages\n\nApr 22nd 2024 9:04am, by Nicola Campagna\n\nHow an AI Chatbot Can Boost Developer Productivity\n\nApr 19th 2024 6:27am, by Asmitha Rathis\n\nIntegrating Real-Time and Historical Data Enhances Decision-Making\n\nApr 18th 2024 6:34am, by Rahul Pradhan\n\nApplying Agile Techniques to AI: Lessons from Amazon Fresh\n\nApr 17th 2024 5:00am, by David Eastman\n\nHow to Summarize Large Documents with LangChain and OpenAI\n\nApr 22nd 2024 9:41am, by Usama Jamil\n\nHow One Programmer Built an AI-Powered Interactive FAQ\n\nApr 16th 2024 9:04am, by Loraine Lawson\n\nA Developer's Guide to Getting Started with LlamaIndex\n\nApr 13th 2024 5:00am, by David Eastman\n\nTool Fragmentation \u2014 Is There a Fix?\n\nApr 12th 2024 9:37am, by Burhan Drak Sibai\n\n3 Reasons Tech Execs Are Slowing Down GenAI Projects\n\nApr 12th 2024 6:04am, by Mandi Walls\n\nDev News: Vercel Preps for React 19; New jQuery, pnpm Releases\n\nApr 20th 2024 4:00am, by Loraine Lawson\n\nNew Wasm Project Brings Web Components to Backend Languages\n\nApr 18th 2024 9:36am, by Loraine Lawson\n\nWhy PHP Usage Has Declined by 40% in Just Over 2 Years\n\nApr 18th 2024 8:27am, by Richard MacManus\n\nDid Signals Just Land in React?\n\nApr 18th 2024 5:00am, by Paul Scanlon\n\nTop 5 Underutilized JavaScript Features\n\nApr 16th 2024 10:30am, by Alexander T. Williams\n\nHow to Speed up Regular Expressions under Production Pressure\n\nApr 20th 2024 5:00am, by David Eastman\n\nScala Creator Proposes 'Lean Scala' for Simpler Code\n\nApr 17th 2024 10:14am, by Darryl K. Taft\n\nLinux Foundation Overture Maps the Globe with Open Data\n\nApr 17th 2024 9:04am, by Joab Jackson\n\nZero-Day Vulnerabilities: A Beginner\u2019s Guide\n\nApr 17th 2024 8:31am, by Aaron Linskens\n\nWhat Are Python 'Sets' and How Do You Use Them?\n\nApr 17th 2024 6:17am, by Jack Wallen\n\nAPI Builders Must Sell to Developers or Die Slowly\n\nApr 22nd 2024 7:17am, by Nolan Di Mare Sullivan\n\nDev News: Vercel Preps for React 19; New jQuery, pnpm Releases\n\nApr 20th 2024 4:00am, by Loraine Lawson\n\n5 Steps Toward Military-Grade API Security\n\nApr 18th 2024 8:02am, by Gary Archer\n\nIs Platform Engineering Really Just API Governance?\n\nApr 15th 2024 12:10pm, by Jennifer Riggins\n\nWhy You Should Have 100% Faith in Zero Trust\n\nApr 15th 2024 8:11am, by Kay James\n\nHow to Use Low-CVE Chainguard Container Images on Docker Hub\n\nApr 19th 2024 8:04am, by B. Cameron Gain\n\nWhat Are Python 'Sets' and How Do You Use Them?\n\nApr 17th 2024 6:17am, by Jack Wallen\n\nPython Tutorial: Use TensorFlow to Generate Predictive Text\n\nApr 16th 2024 11:00am, by Ryan Cartwright\n\nJavaScript, Python Neck and Neck in GitHub Developer Usage\n\nApr 15th 2024 9:45am, by Darryl K. Taft\n\nA Coder Perspective: What It's Like to Develop an AI App\n\nApr 11th 2024 9:47am, by Loraine Lawson\n\nDev News: Vercel Preps for React 19; New jQuery, pnpm Releases\n\nApr 20th 2024 4:00am, by Loraine Lawson\n\nNew Wasm Project Brings Web Components to Backend Languages\n\nApr 18th 2024 9:36am, by Loraine Lawson\n\nWhy PHP Usage Has Declined by 40% in Just Over 2 Years\n\nApr 18th 2024 8:27am, by Richard MacManus\n\nDid Signals Just Land in React?\n\nApr 18th 2024 5:00am, by Paul Scanlon\n\nTop 5 Underutilized JavaScript Features\n\nApr 16th 2024 10:30am, by Alexander T. Williams\n\nDev News: Deno Supports Open Source Repository JSR and an Offline AI\n\nMar 30th 2024 4:00am, by Loraine Lawson\n\nAdvanced OOP in TypeScript: Interfaces and Abstract Classes\n\nMar 22nd 2024 10:30am, by Bob Reselman\n\nHow to Get Advantages of TypeScript in JavaScript\n\nOct 27th 2023 10:51am, by Phil Nash\n\nDev News: Udemy's New Docker Program, Plus TypeScript Beta\n\nOct 7th 2023 5:01am, by Loraine Lawson\n\nThe Angular Renaissance: Why Frontend Devs Should Revisit It\n\nSep 26th 2023 8:15am, by Loraine Lawson\n\nNew Wasm Project Brings Web Components to Backend Languages\n\nApr 18th 2024 9:36am, by Loraine Lawson\n\n4 Big Developments in WebAssembly\n\nApr 18th 2024 8:56am, by Matt Butcher\n\nWebAssembly Adoption: Is Slow and Steady Winning the Race?\n\nApr 10th 2024 5:00am, by Richard Gall\n\nWhy WASI Preview 2 Makes WebAssembly Production Ready\n\nApr 5th 2024 6:21am, by Oscar Spencer\n\nKubeCon Europe: WebAssembly, eBPF Are Huge for Cloud Native\n\nMar 29th 2024 8:24am, by B. Cameron Gain\n\nWhy Observability Was Key to Citigroup\u2019s Cloud Native Transition\n\nApr 19th 2024 10:29am, by Eric Newcomer\n\nAnswers to the 5 Most Common Cloud Cost-Optimization Questions\n\nApr 17th 2024 7:38am, by Roman Yegorov\n\nKey Infrastructure Takeaways from Google Cloud Next 2024\n\nApr 16th 2024 12:00pm, by Chris J. Preimesberger\n\nGoogle Vaunts New Gemini Code Assist Tool at Cloud Next 2024\n\nApr 10th 2024 9:05am, by Chris J. Preimesberger\n\nIf Dev and Ops Had a Baby \u2014 It Would Be Called Winglang\n\nApr 5th 2024 10:00am, by Elad Ben-Israel\n\nHow to Summarize Large Documents with LangChain and OpenAI\n\nApr 22nd 2024 9:41am, by Usama Jamil\n\nIntegrating Real-Time and Historical Data Enhances Decision-Making\n\nApr 18th 2024 6:34am, by Rahul Pradhan\n\nPython Tutorial: Use TensorFlow to Generate Predictive Text\n\nApr 16th 2024 11:00am, by Ryan Cartwright\n\nQuery Apache Kafka with SQL\n\nApr 16th 2024 7:51am, by St\u00e9phane Derosiaux\n\nHow to Get Peak Performance without a Vast Amount of Memory\n\nApr 9th 2024 10:17am, by Behrad Babaee\n\nHow to Use Low-CVE Chainguard Container Images on Docker Hub\n\nApr 19th 2024 8:04am, by B. Cameron Gain\n\nProtobom: Paving the Path for SBOM Adoption\n\nApr 18th 2024 1:19pm, by Jeffrey Burt\n\n5 Steps Toward Military-Grade API Security\n\nApr 18th 2024 8:02am, by Gary Archer\n\nZero-Day Vulnerabilities: A Beginner\u2019s Guide\n\nApr 17th 2024 8:31am, by Aaron Linskens\n\nMeet the System Package Data Exchange: SPDX 3.0, with Profiles\n\nApr 16th 2024 3:28pm, by Steven J. Vaughan-Nichols\n\nPlatform Engineering Operations CI/CD Tech Careers Tech Culture DevOps\nKubernetes Observability Service Mesh\n\nAI in Platform Engineering: Concerns Grow Alongside Advantages\n\nApr 22nd 2024 9:04am, by Nicola Campagna\n\nYour Engineering Organization Is too Expensive\n\nApr 17th 2024 11:19am, by Luca Galante\n\nDrive Developer Self-Service with Crossplane, K8s and a Portal\n\nApr 17th 2024 9:46am, by Mor Paz\n\nWhat Comes after Internal Developer Platforms?\n\nApr 15th 2024 12:56pm, by Valerie Slaughter\n\nIs Platform Engineering Really Just API Governance?\n\nApr 15th 2024 12:10pm, by Jennifer Riggins\n\nHow Giant Swarm Is Helping to Support the Future of Flux\n\nApr 22nd 2024 7:59am, by Heather Joslyn\n\nInstall OpenProject with Linux and Docker\n\nApr 20th 2024 6:00am, by Jack Wallen\n\nCreating an EKS Cluster with No Manual Coding\n\nApr 19th 2024 8:53am, by Edan Evantal\n\nGolang: How to Write a For Loop\n\nApr 16th 2024 5:00pm, by Jack Wallen\n\nWant to Be a Tech Company? Try Platform Engineering!\n\nApr 10th 2024 10:26am, by Luca Galante\n\nCreating an EKS Cluster with No Manual Coding\n\nApr 19th 2024 8:53am, by Edan Evantal\n\nHow an AI Chatbot Can Boost Developer Productivity\n\nApr 19th 2024 6:27am, by Asmitha Rathis\n\n4 Big Developments in WebAssembly\n\nApr 18th 2024 8:56am, by Matt Butcher\n\n5 Steps Toward Military-Grade API Security\n\nApr 18th 2024 8:02am, by Gary Archer\n\nAre You Delivering on Developer Experience?\n\nApr 16th 2024 10:00am, by No\u010dnica Mellifera\n\nWhy Military Vets Are the Drama-Free Problem Solvers You Need\n\nMar 28th 2024 9:20am, by Joe Fay\n\nUsing AI to Improve Bad Business Writing\n\nMar 26th 2024 5:00am, by Jon Udell\n\nDevelopers Share What Helped Them Land New Roles\n\nMar 25th 2024 6:45am, by Jeff James\n\nUS Tech Cannot Comprehend the Digital Nomad Way of Life\n\nMar 23rd 2024 3:00am, by Paul Scanlon\n\nTech Works: How to Identify and Address Burnout on Your Team\n\nMar 22nd 2024 5:00am, by Jennifer Riggins\n\nAmbient AI? Humane's 'Ai Pin' Embarks on a Dream's Long Road\n\nApr 21st 2024 6:00am, by David Cassel\n\nLinus Torvalds on Security, AI, Open Source and Trust\n\nApr 19th 2024 9:57am, by David Cassel\n\nAre You Delivering on Developer Experience?\n\nApr 16th 2024 10:00am, by No\u010dnica Mellifera\n\nIT Pioneers Assess the Future Impact of AI\n\nApr 14th 2024 6:00am, by David Cassel\n\nC# Compiler Lead Jared Parsons on 20 Years at Microsoft\n\nApr 7th 2024 6:00am, by David Cassel\n\nAPI Builders Must Sell to Developers or Die Slowly\n\nApr 22nd 2024 7:17am, by Nolan Di Mare Sullivan\n\nQuery Apache Kafka with SQL\n\nApr 16th 2024 7:51am, by St\u00e9phane Derosiaux\n\nGitOps Makes for Great DevEx, but Pragmatism Matters\n\nApr 9th 2024 6:30am, by Steve Fenton\n\nPlatform Engineering and GenAI: \u2018Get Your House in Order\u2019\n\nApr 9th 2024 5:00am, by Loraine Lawson\n\nHow Platform Engineering Takes on DevOps Challenges\n\nApr 8th 2024 6:49am, by Kenn Hussey\n\n4 Big Developments in WebAssembly\n\nApr 18th 2024 8:56am, by Matt Butcher\n\nDrive Developer Self-Service with Crossplane, K8s and a Portal\n\nApr 17th 2024 9:46am, by Mor Paz\n\nGrafana 11: No Need to Create PromQL Queries for Prometheus\n\nApr 17th 2024 4:00am, by B. Cameron Gain\n\nAttack (or Penetrate Test) Cloud Native the Easy Way\n\nApr 15th 2024 7:21am, by B. Cameron Gain\n\nIngress: Kubernetes Example with ngrok\n\nApr 11th 2024 9:34am, by Eric Goebelbecker\n\nGuider Daemon Automates Linux Performance Monitoring\n\nApr 19th 2024 11:16am, by Joab Jackson\n\nWhy Observability Was Key to Citigroup\u2019s Cloud Native Transition\n\nApr 19th 2024 10:29am, by Eric Newcomer\n\nGrafana 11: No Need to Create PromQL Queries for Prometheus\n\nApr 17th 2024 4:00am, by B. Cameron Gain\n\nHighlight.io: Open Source Application Monitoring for Developers\n\nApr 9th 2024 10:00am, by Jay Khatri\n\nHow Conviva Uses Endpoint Event Data to Measure UX at Scale\n\nMar 29th 2024 9:16am, by Vicki Walker\n\nEnhancing Business Security and Compliance with Service Mesh\n\nApr 1st 2024 10:00am, by Ninad Desai\n\nSome Linkerd Users Must Pay: Fear and Anger Explained\n\nFeb 28th 2024 9:21am, by B. Cameron Gain\n\nBuoyant Revises Release Model for the Linkerd Service Mesh\n\nFeb 21st 2024 9:30am, by Joab Jackson\n\nIstio Advisor Plus GPT: Expert System Meets AI for Service Mesh\n\nDec 14th 2023 12:15pm, by Steven J. Vaughan-Nichols\n\nUsing JWTs to Authenticate Services Unravels API Gateways\n\nNov 8th 2023 6:53am, by Christian Posta and Peter Jausovec\n\n2024-04-22 09:41:34\n\nHow to Summarize Large Documents with LangChain and OpenAI\n\nsponsor-myscale,sponsored-post-contributed,\n\nAI / Data / Large Language Models\n\n# How to Summarize Large Documents with LangChain and OpenAI\n\nThere are still some limitations when summarizing very large documents. Here\nare some ways to mitigate these effects.\n\nApr 22nd, 2024 9:41am by Usama Jamil\n\nImage from Azston Designs on Shutterstock.\n\nVOXPOP\n\nTry our new 5 second poll. It's fast. And it's fun!\n\nWhat\u2019s Slowing You Down?\n\nWhat is your biggest inhibitor to shipping software faster?\n\nComplicated codebase and technical debt.\n\nQA, writing tests, and debugging.\n\nWaiting for PR review or stakeholder approval.\n\nI'm always waiting due to long build times.\n\nRework due to unclear or incomplete specifications.\n\nInadequate tooling or infrastructure.\n\nOther.\n\nWe'd love to hear what you think.\n\nMyScale sponsored this post.\n\nLarge language models have made many tasks easier like making chatbots,\nlanguage translation, text summarization, etc. We used to write models for\nsummarization, and then there was always the issue of performance. Now, we can\ndo this easily with the use of large language models (LLMs). For example,\nstate-of-the-art (SOTA) LLMs can already handle a whole book in its context\nwindow. But there are still some limitations when summarizing very large\ndocuments.\n\n## Limitations of Large Document Summarization by LLM\n\nContextual limit or context length in an LLM refers to the number of tokens\nthat a model can process. Each model has its own context length also known as\nmax tokens or token limit. For instance, a standard GPT-4 model has a context\nlength of 128,000 tokens. It will lose information for the tokens more than\nthat. Some SOTA LLMs have a contextual limit of up to 1 million tokens.\nHowever, as the contextual limit increases, LLMs suffer from limitations like\nrecency and primacy. We can also delve into ways to mitigate these effects.\n\n  * Primacy effect in LLMs refers to the model giving more importance to information presented at the beginning of a sequence.\n  * Recency effect pertains to the model emphasizing the most recent information it processes.\n\nBoth effects bias the model toward specific parts of the input data. The model\nmay skip important information in the middle of the sequence.\n\nThe second issue is cost. We can resolve the first issue of context limit by\nsplitting the text, but we simply can\u2019t pass the whole book directly to the\nmodel. It would cost a lot. For example, if we have 1 million tokens of a book\nand we directly pass it to the GPT4 model, our total cost would be around $90\n(prompt and completion tokens). We have to find a middle way to summarize our\ntext considering the price, contextual limit and the complete context of the\nbook.\n\nIn this tutorial, you\u2019ll learn to summarize a complete book considering the\nprice and the contextual limit of the model. Let\u2019s start.\n\nMyScale is an open-source SQL vector database that allows to effectively\nmanage massive volumes of both structured and vector data for developing\nrobust AI applications. It enables every developer to build production-grade\nGenAI applications with powerful and familiar SQL.\n\nLearn More\n\nThe latest from MyScale\n\n## Summarize Large Documents with LangChain and OpenAI\n\n### Setting up the Environment\n\nTo follow along with the tutorial, you need to have:\n\n  * Python installed\n  * An IDE (VS Code would work)\n\nTo install the dependencies, open your terminal and enter the command:\n\npip install langchain openai tiktoken fpdf2 pandas  \n---  \n  \nview raw MyScale1.sh hosted with \u2764 by GitHub\n\nThis command will install all the required dependencies.\n\nTRENDING STORIES\n\n  1. How to Set up and Run a Local LLM with Ollama and Llama 2\n  2. The Building Blocks of LLMs: Vectors, Tokens and Embeddings\n  3. The Rise of Small Language Models\n  4. How to Run a Local LLM via LocalAI, an Open Source Project\n  5. How to Build a RAG-Powered LLM Chat App with ChromaDB and Python\n\n### Load the Book\n\nYou will be using the book \u201cDavid Copperfield\u201d by Charles Dickens, which is\npublicly available for this project. Let\u2019s load the book using the PyPDFLoader\nutility provided by LangChain.\n\nfrom langchain.document_loaders import PyPDFLoader  \n---  \n# Load the book  \nloader = PyPDFLoader(\"David-Copperfield.pdf\")  \npages = loader.load_and_split()  \n  \nview raw MyScale2.py hosted with \u2764 by GitHub\n\nIt will load the complete book, but we are only interested in the content\npart. We can skip the pages like the Preface and Intro.\n\n# Cut out the open and closing parts  \n---  \npages = pages[6:1308]  \n# Combine the pages, and replace the tabs with spaces  \ntext = ' '.join([page.page_content.replace('\\t', ' ') for page in pages]  \n  \nview raw MyScale3.py hosted with \u2764 by GitHub\n\nNow, we have the content. Let\u2019s print the first 200 characters.\n\ntext[0:200]  \n---  \n  \nview raw MyScale5.py hosted with \u2764 by GitHub\n\n### Pre-processing\n\nLet\u2019s remove the unnecessary content from the text like non-printable\ncharacters, extra spaces, etc.\n\nimport re  \n---  \ndef clean_text(text):  \n# Remove the specific phrase 'Free eBooks at Planet eBook.com' and surrounding\nwhitespace  \ncleaned_text = re.sub(r'\\s*Free eBooks at Planet eBook\\\\.com\\s*', '', text,\nflags=re.DOTALL)  \n# Remove extra spaces  \ncleaned_text = re.sub(r' +', ' ', cleaned_text)  \n# Remove non-printable characters, optionally preceded by 'David Copperfield'  \ncleaned_text = re.sub(r'(David Copperfield )?[\\x00-\\x1F]', '', cleaned_text)  \n# Replace newline characters with spaces  \ncleaned_text = cleaned_text.replace('\\n', ' ')  \n# Remove spaces around hyphens  \ncleaned_text = re.sub(r'\\s*-\\s*', '', cleaned_text)  \nreturn cleaned_text  \nclean_text=clean_text(text)  \n  \nview raw MyScale6.py hosted with \u2764 by GitHub\n\nAfter cleaning the data, we are ready to dive into the summarizing problem.\n\n### Load the OpenAI API\n\nBefore using the OpenAI API, we need to configure it and provide credentials\nhere.\n\nimport os  \n---  \nos.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"  \n  \nview raw MyScale7.py hosted with \u2764 by GitHub\n\nEnter your API key there and it\u2019ll set up the environment variable.\n\nLet\u2019s see how many tokens we have in the book:\n\nfrom langchain import OpenAI  \n---  \nllm = OpenAI()  \nTokens = llm.get_num_tokens(clean_text)  \nprint (f\"We have {Tokens} tokens in the book\")  \n  \nview raw MyScale8.py hosted with \u2764 by GitHub\n\nWe have over 466,000 tokens in this book, and if we pass them all directly to\nthe LLM, it would charge us a lot. So, to reduce the cost, we will implement\nK-means clustering to extract the important chunks from the book.\n\nNote: The decision to use K-means clustering was inspired by data guru Greg\nKamradt\u2019s tutorial.\n\nTo get important parts of the book, let\u2019s first split the book into different\nchunks.\n\n### Split the Content into Documents\n\nWe will split the book content into documents by using the SemanticChunker\nutility of LangChain.\n\nfrom langchain_experimental.text_splitter import SemanticChunker  \n---  \nfrom langchain_openai.embeddings import OpenAIEmbeddings  \ntext_splitter = SemanticChunker(  \nOpenAIEmbeddings(), breakpoint_threshold_type=\"interquartile\"  \n)  \ndocs = text_splitter.create_documents([clean_text])  \n  \nview raw MyScale9.py hosted with \u2764 by GitHub\n\nThe SemanticChunker receives two arguments, the first one is the embeddings\nmodel. The embeddings generated by this model are used to split the text based\non the semantics. The second one is the breakpoint_threshold_type, which\ndetermines the points at which text should be split into different chunks\nbased on semantic similarity.\n\nNote: By processing these smaller, semantically similar chunks, we aim to\nminimize the recency and primacy effects in our LLM. This strategy allows our\nmodel to handle each small context more effectively, ensuring a more balanced\ninterpretation and response generation.\n\n### Find the Embeddings of Each Document\n\nNow, let\u2019s get the embeddings of each generated document. You will get the\nembeddings using the OpenAI default method.\n\nimport numpy as np  \n---  \nimport openai  \ndef get_embeddings(text):  \nresponse = openai.embeddings.create(  \nmodel=\"text-embedding-3-small\",  \ninput=text  \n)  \nreturn response.data  \nembeddings=get_embeddings([doc.page_content for doc in docs]  \n)  \n  \nview raw MyScale10.py hosted with \u2764 by GitHub\n\nThe get_embeddings method gives us the embeddings of all the documents.\n\nNote: The text-embedding-3-small method is specially released by OpenAI, which\nis considered cheaper and faster.\n\n### Rearrange the Data\n\nNext, we will convert lists of document contents and their embeddings into a\npandas DataFrame for easier data handling and analysis.\n\nimport pandas as pd  \n---  \ncontent_list = [doc.page_content for doc in docs]  \ndf = pd.DataFrame(content_list, columns=['page_content'])  \nvectors = [embedding.embedding for embedding in embeddings]  \narray = np.array(vectors)  \nembeddings_series = pd.Series(list(array))  \ndf['embeddings'] = embeddings_series  \n  \nview raw MyScale11.py hosted with \u2764 by GitHub\n\n### Apply Faiss for Efficient Clustering\n\nNow, we\u2019ll transform the document vectors into a format compatible with Faiss,\ncluster them into 50 groups using K-means, and then create a Faiss index for\nefficient similarity searches among documents.\n\nimport numpy as np  \n---  \nimport faiss  \n# Convert to float32 if not already  \narray = array.astype('float32')  \nnum_clusters = 50  \n# Vectors dimensionality  \ndimension = array.shape[1]  \n# Train KMeans with Faiss  \nkmeans = faiss.Kmeans(dimension, num_clusters, niter=20, verbose=True)  \nkmeans.train(array)  \n# Directly access the centroids  \ncentroids = kmeans.centroids  \n# Create a new index for the original dataset  \nindex = faiss.IndexFlatL2(dimension)  \n# Add original dataset to the index  \nindex.add(array)  \n  \nview raw MyScale12.py hosted with \u2764 by GitHub\n\nThis K-means clustering will group the documents into 50 groups.\n\nNote: The reason for choosing the K-means clustering is that each cluster will\nhave a similar content or similar context because all the documents within\nthat cluster have related embeddings, and we will select the one that is\nnearest to the nucleus.\n\n### Select the Import Documents\n\nNow, we will just select the most important document from each cluster. For\nthis, we will only select the first nearest vector to the centroid.\n\nD, I = index.search(centroids, 1)  \n---  \n  \nview raw MyScale13a.py hosted with \u2764 by GitHub\n\nThis code uses the search method on the index to find the closest document to\neach centroid in the list of centroids. It returns two arrays: D, which\ncontains the distances of the closest documents to their respective centroids,\nand I, which contains the indices of these closest documents. The second\nparameter 1 in the search method specifies that only the single closest\ndocument is to be found for each centroid.\n\nNow we need to sort the selected document indices because the documents are in\nsequence with respect to the sequence of the book.\n\nsorted_array = np.sort(I, axis=0)  \n---  \nsorted_array=sorted_array.flatten()  \nextracted_docs = [docs[i] for i in sorted_array]  \n  \nview raw MyScale14.py hosted with \u2764 by GitHub\n\n### Get the Summary of Each Document\n\nThe next step is to get the summary of each document using the GPT-4 model to\nsave money. To use GPT-4, let\u2019s define the model.\n\nmodel = ChatOpenAI(temperature=0,model=\"gpt-4\")  \n---  \n  \nview raw MyScale15.py hosted with \u2764 by GitHub\n\nDefine the prompt and make a prompt template using LangChain to pass it to the\nmodel.\n\nfrom langchain_core.output_parsers import StrOutputParser  \n---  \nfrom langchain_openai import ChatOpenAI  \nfrom langchain_core.prompts import ChatPromptTemplate  \nprompt = ChatPromptTemplate.from_template(\"\"\"  \nYou will be given different passages from a book one by one. Provide a summary\nof the following text. Your result must be detailed and atleast 2 paragraphs.\nWhen summarizing, directly dive into the narrative or descriptions from the\ntext without using introductory phrases like 'In this passage'. Directly\naddress the main events, characters, and themes, encapsulating the essence and\nsignificant details from the text in a flowing narrative. The goal is to\npresent a unified view of the content, continuing the story seamlessly as if\nthe passage naturally progresses into the summary.  \nPassage:  \n```{text}```  \nSUMMARY:  \n\"\"\"  \n)  \n  \nview raw MyScale16.py hosted with \u2764 by GitHub\n\nThis prompt template will help the model summarize the documents more\neffectively and efficiently.\n\nThe next step is to define a chain of the LangChain using LangChain Expression\nLanguage (LCEL).\n\nchain= (  \n---  \nprompt  \n| model  \n|StrOutputParser() )  \n  \nview raw MyScale17.py hosted with \u2764 by GitHub\n\nThe summarizing chain uses the StrOutputParser to parse the output. There are\nother output parsers as well to explore.\n\nYou can finally apply the defined chain on each document to get a summary.\n\nfrom tqdm import tqdm  \n---  \nfinal_summary = \"\"  \nfor doc in tqdm(extracted_docs, desc=\"Processing documents\"):  \n# Get the new summary.  \nnew_summary = chain2.invoke({\"text\": doc.page_content})  \n# Update the list of the last two summaries: remove the first one and add the\nnew one at the end.  \nfinal_summary+=new_summary  \n  \nview raw MyScale18.py hosted with \u2764 by GitHub\n\nThe code above applies the chain on each document one by one and concatenates\neach summary to the final_summary.\n\n### Save the Summary as a PDF\n\nThe next step is to format the summary and save it in PDF format.\n\nfrom fpdf import FPDF  \n---  \nclass PDF(FPDF):  \ndef header(self):  \n# Select Arial bold 15  \nself.set_font('Arial', 'B', 15)  \n# Move to the right  \nself.cell(80)  \n# Framed title  \nself.cell(30, 10, 'Summary', 1, 0, 'C')  \n# Line break  \nself.ln(20)  \ndef footer(self):  \n# Go to 1.5 cm from bottom  \nself.set_y(-15)  \n# Select Arial italic 8  \nself.set_font('Arial', 'I', 8)  \n# Page number  \nself.cell(0, 10, 'Page %s' % self.page_no(), 0, 0, 'C')  \n# Instantiate PDF object and add a page  \npdf = PDF()  \npdf.add_page()  \npdf.set_font(\"Arial\", size=12)  \n# Ensure the 'last_summary' text is treated as UTF-8  \n# Replace 'last_summary' with your actual text variable if different  \n# Make sure your text is a utf-8 encoded string  \nlast_summary_utf8 = last_summary.encode('latin-1',\n'replace').decode('latin-1')  \npdf.multi_cell(0, 10, last_summary_utf8)  \n# Save the PDF to a file  \npdf_output_path = \"s_output1.pdf\"  \npdf.output(pdf_output_path)  \n  \nview raw MyScale19.py hosted with \u2764 by GitHub\n\nSo, here we have the complete summary of the book in PDF format.\n\n## Conclusion\n\nIn this tutorial, we\u2019ve navigated the complexities of summarizing large texts\nsuch as entire books using LLMs while addressing challenges related to\ncontextual limits and cost. We have learned the steps to preprocess the text\nand implement a strategy combining semantic chunking and K-means clustering to\nmanage the model\u2019s contextual limitations effectively.\n\nBy using efficient clustering, we efficiently extracted key passages, reducing\nthe overhead of processing massive texts directly. This approach not only\nreduces costs significantly by minimizing the number of tokens processed but\nalso mitigates the recency and primacy effects inherent in LLMs, ensuring a\nbalanced consideration of all text segments.\n\nThere has been significant excitement about developing AI applications through\nthe APIs of LLMs, where vector databases play a significant role by offering\nefficient storage and retrieval of contextual embeddings. MyScaleDB is a\nvector database that has been designed specifically for AI applications,\nkeeping all the factors in mind such as cost, accuracy and speed. Its SQL-\nfriendly interface allows developers to start developing their AI applications\nwithout learning something new.\n\nIf you want to discuss more with us, welcome to join MyScale Discord to share\nyour thoughts and feedback.\n\nUsama Jamil, a developer advocate at MyScale, brings with him a wealth of\nexperience and a profound interest in data science. With a passion for\nexploring new trends in the AI/ML domain, Usama strives to make complex\nconcepts accessible to...\n\nRead more from Usama Jamil\n\nMyScale sponsored this post.\n\nSHARE THIS STORY\n\nTRENDING STORIES\n\n  1. How to Set up and Run a Local LLM with Ollama and Llama 2\n  2. The Building Blocks of LLMs: Vectors, Tokens and Embeddings\n  3. The Rise of Small Language Models\n  4. How to Run a Local LLM via LocalAI, an Open Source Project\n  5. How to Build a RAG-Powered LLM Chat App with ChromaDB and Python\n\nSHARE THIS STORY\n\nTRENDING STORIES\n\n  1. How to Set up and Run a Local LLM with Ollama and Llama 2\n  2. The Building Blocks of LLMs: Vectors, Tokens and Embeddings\n  3. The Rise of Small Language Models\n  4. How to Run a Local LLM via LocalAI, an Open Source Project\n  5. How to Build a RAG-Powered LLM Chat App with ChromaDB and Python\n\nInsights From Our Sponsor\n\nTNS DAILY NEWSLETTER Receive a free roundup of the most recent TNS articles in\nyour inbox each day.\n\nThe New Stack does not sell your information or share it with unaffiliated\nthird parties. By continuing, you agree to our Terms of Use and Privacy\nPolicy.\n\nARCHITECTURE\n\nCloud Native Ecosystem Containers Edge Computing Microservices Networking\nServerless Storage\n\nENGINEERING\n\nAI Large Language Models Frontend Development Software Development API\nManagement Python JavaScript TypeScript WebAssembly Cloud Services Data\nSecurity\n\nOPERATIONS\n\nPlatform Engineering Operations CI/CD Tech Careers Tech Culture DevOps\nKubernetes Observability Service Mesh\n\nCHANNELS\n\nPodcasts Ebooks Events Newsletter TNS RSS Feeds\n\nTHE NEW STACK\n\nAbout / Contact Sponsors Sponsorship Contributions\n\nroadmap.sh\n\nCommunity created roadmaps, articles, resources and journeys for developers to\nhelp you choose your path and grow in your career.\n\nFrontend Developer Roadmap Backend Developer Roadmap Devops Roadmap\n\n\u00a9 The New Stack 2024\n\nDisclosures Terms of Use Advertising Terms & Conditions Privacy Policy Cookie\nPolicy\n\nFOLLOW TNS\n\nFOLLOW TNS\n\nTNS DAILY\n\nSome TNS posts require third-party cookies to view embedded content (video,\naudio, technical & interactive content).\n\nBy clicking \u201cAccept\u201d you agree to our use of these cookies in accordance with\nour Cookie Notice.\n\nCookie Policy\n\n## The New Stack's Cookies Usage\n\nWhen you visit, the website may store or retrieve information on your browser,\nmostly in the form of cookies. This information might be about you, your\npreferences or your device, but does not usually directly identify you. The\ninformation is mostly used to make the website display the embedded content\nyou expect to see and work the way you expect it to. Cookie Policy\n\n### Manage Consent Preferences\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched\noff in our systems. They are usually only set in response to actions made by\nyou which amount to a request for services, such as setting your privacy\npreferences, logging in or filling in forms. You can set your browser to block\nor alert you about these cookies, but some parts of the site will not then\nwork. These cookies do not store any personally identifiable information.\n\n#### Functional Cookies\n\nThese cookies enable the website to provide enhanced functionality and\npersonalisation. They may be set by us or by third party providers whose\nservices we have added to our pages. If you do not allow these cookies then\nsome or all of these services may not function properly.\n\n#### Performance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure\nand improve the performance of our site. They help us to know which pages are\nthe most and least popular and see how visitors move around the site. All\ninformation these cookies collect is aggregated and therefore anonymous. If\nyou do not allow these cookies we will not know when you have visited our\nsite, and will not be able to monitor its performance.\n\n#### Targeting Cookies\n\nThese cookies may be set through our site by our advertising partners. They\nmay be used by those companies to build a profile of your interests and show\nyou relevant adverts on other sites. If you do not allow these cookies, you\nwill experience less targeted advertising.\n\n### Vendors List\n\nlabel\n\nConsent Leg.Interest\n\nlabel\n\nlabel\n\nlabel\n\n", "frontpage": false}
