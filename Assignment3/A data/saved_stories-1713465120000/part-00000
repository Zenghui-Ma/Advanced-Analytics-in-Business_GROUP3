{"aid": "40075514", "title": "Information Retrieval with Entity Linking", "url": "https://arxiv.org/abs/2404.08678", "domain": "arxiv.org", "votes": 1, "user": "PaulHoule", "posted_at": "2024-04-18 12:31:33", "comments": 0, "source_title": "Information Retrieval with Entity Linking", "source_text": "[2404.08678] Information Retrieval with Entity Linking\n\nSkip to main content\n\nWe gratefully acknowledge support from the Simons Foundation, member\ninstitutions, and all contributors. Donate\n\n> cs > arXiv:2404.08678\n\n# Computer Science > Information Retrieval\n\narXiv:2404.08678 (cs)\n\n[Submitted on 7 Apr 2024]\n\n# Title:Information Retrieval with Entity Linking\n\nAuthors:Dahlia Shehata\n\nView a PDF of the paper titled Information Retrieval with Entity Linking, by\nDahlia Shehata\n\nView PDF HTML (experimental)\n\n> Abstract:Despite the advantages of their low-resource settings, traditional\n> sparse retrievers depend on exact matching approaches between high-\n> dimensional bag-of-words (BoW) representations of both the queries and the\n> collection. As a result, retrieval performance is restricted by semantic\n> discrepancies and vocabulary gaps. On the other hand, transformer-based\n> dense retrievers introduce significant improvements in information retrieval\n> tasks by exploiting low-dimensional contextualized representations of the\n> corpus. While dense retrievers are known for their relative effectiveness,\n> they suffer from lower efficiency and lack of generalization issues, when\n> compared to sparse retrievers. For a lightweight retrieval task, high\n> computational resources and time consumption are major barriers encouraging\n> the renunciation of dense models despite potential gains. In this work, I\n> propose boosting the performance of sparse retrievers by expanding both the\n> queries and the documents with linked entities in two formats for the entity\n> names: 1) explicit and 2) hashed. A zero-shot end-to-end dense entity\n> linking system is employed for entity recognition and disambiguation to\n> augment the corpus. By leveraging the advanced entity linking methods, I\n> believe that the effectiveness gap between sparse and dense retrievers can\n> be narrowed. Experiments are conducted on the MS MARCO passage dataset using\n> the original qrel set, the re-ranked qrels favoured by MonoT5 and the latter\n> set further re-ranked by DuoT5. Since I am concerned with the early stage\n> retrieval in cascaded ranking architectures of large information retrieval\n> systems, the results are evaluated using recall@1000. The suggested approach\n> is also capable of retrieving documents for query subsets judged to be\n> particularly difficult in prior work.\n\nSubjects:| Information Retrieval (cs.IR)  \n---|---  \nCite as:| arXiv:2404.08678 [cs.IR]  \n(or arXiv:2404.08678v1 [cs.IR] for this version)  \nhttps://doi.org/10.48550/arXiv.2404.08678arXiv-issued DOI via DataCite  \n  \n## Submission history\n\nFrom: Dahlia Shehata [view email] [v1] Sun, 7 Apr 2024 08:41:51 UTC (2,754 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Information Retrieval with Entity Linking, by\nDahlia Shehata\n\n  * View PDF\n  * HTML (experimental)\n  * TeX Source\n  * Other Formats\n\nview license\n\nCurrent browse context:\n\ncs.IR\n\n< prev | next >\n\nnew | recent | 2024-04\n\nChange to browse by:\n\ncs\n\n### References & Citations\n\n  * NASA ADS\n  * Google Scholar\n  * Semantic Scholar\n\na export BibTeX citation Loading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer (What is the Explorer?)\n\nLitmaps (What is Litmaps?)\n\nscite Smart Citations (What are Smart Citations?)\n\n# Code, Data and Media Associated with this Article\n\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\n\nDagsHub (What is DagsHub?)\n\nGotit.pub (What is GotitPub?)\n\nPapers with Code (What is Papers with Code?)\n\nScienceCast (What is ScienceCast?)\n\n# Demos\n\nReplicate (What is Replicate?)\n\nHugging Face Spaces (What is Spaces?)\n\nTXYZ.AI (What is TXYZ.AI?)\n\n# Recommenders and Search Tools\n\nInfluence Flower (What are Influence Flowers?)\n\nConnected Papers (What is Connected Papers?)\n\nCORE Recommender (What is CORE?)\n\n  * Author\n  * Venue\n  * Institution\n  * Topic\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new\narXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and\naccepted our values of openness, community, excellence, and user data privacy.\narXiv is committed to these values and only works with partners that adhere to\nthem.\n\nHave an idea for a project that will add value for arXiv's community? Learn\nmore about arXivLabs.\n\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n\n  * About\n  * Help\n\n  * Contact\n  * Subscribe\n\n  * Copyright\n  * Privacy Policy\n\n  * Web Accessibility Assistance\n  * arXiv Operational Status Get status notifications via email or slack\n\n", "frontpage": false}
