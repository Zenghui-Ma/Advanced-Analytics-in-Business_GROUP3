{"aid": "40103281", "title": "Connect Private GitHub Repository to Tabby", "url": "https://tabby.tabbyml.com/blog/2024/04/08/connect-private-github-repository-to-tabby/", "domain": "tabbyml.com", "votes": 1, "user": "wsxiaoys", "posted_at": "2024-04-21 04:54:15", "comments": 0, "source_title": "Connect Private GitHub Repository to Tabby", "source_text": "Connect Private GitHub Repository to Tabby | Tabby\n\nSkip to main content\n\n# Connect Private GitHub Repository to Tabby\n\nApril 8, 2024 \u00b7 5 min read\n\nZhiming Ma\n\nA few months ago, we published a blog Repository context for LLM assisted code\ncompletion, introducing the Repository Context feature in Tabby. This feature\nhas been widely embraced by many users to incorporate repository-level\nknowledge into Tabby, thus improving the relevance of code completion\nsuggestions within the working project.\n\nIn this blog, I will guide you through the steps of setting up a Tabby server\nconfigured with a private Git repositories context, aiming to simplify and\nstreamline the integration process.\n\n## Generating a Personal Access Token\n\nIn order to provide the Tabby server with access to your private Git\nrepositories, it is essential to create a Personal Access Token (PAT) specific\nto your Git provider. The following steps outline the process with GitHub as a\nreference:\n\n  1. Visit GitHub Personal Access Tokens Settings and select Generate new token.\n  2. Enter the Token name, specify an Expiration date, an optional Description, and select the repositories you wish to grant access to.\n  3. Within the Permissions section, ensure that Contents is configured for Read-only access.\n  4. Click Generate token to generate the new PAT. Remember to make a copy of the PAT before closing the webpage.\n\nFor additional information, please refer to the documentation on Managing your\npersonal access tokens.\n\nNote: For users of GitLab, guidance on creating a personal access token can be\nfound in the documentation Personal access tokens - GitLab.\n\n## Configuration\n\nTo configure the Tabby server with your private Git repositories, you need to\nprovide the required settings in a YAML file. Create and edit a configuration\nfile located at ~/.tabby/config.yaml:\n\n    \n    \n    ## Add the private repository [[repositories]] name = \"my_private_project\" git_url = \"https://<PAT>@github.com/icycodes/my_private_project.git\"\n    \n    ## More repositories can be added like this [[repositories]] name = \"another_project\" git_url = \"https://<PAT>@github.com/icycodes/another_project.git\"\n\nFor more detailed about the configuration file, you can refer to the\nconfiguration documentation.\n\nNote: The URL format for GitLab repositories may vary, you can check the\nofficial documentation for specific guidelines.\n\n## Building the Index\n\nIn the process of building the index, we will parse the repository and extract\ncode components for indexing, using the parser tree-sitter. This will allow\nfor quick retrieval of related code snippets before generating code\ncompletions, thereby enhancing the context for suggestion generation.\n\ntip\n\nThe commands provided in this section are based on a Linux environment and\nassume the pre-installation of Docker with CUDA drivers. Adjust the commands\nas necessary if you are running Tabby on a different setup.\n\nOnce the configuration file is set up, proceed with running the scheduler to\nsynchronize git repositories and construct the index. In this scenario,\nutilizing the tabby-cpu entrypoint will avoid the requirement for GPU\nresources.\n\n    \n    \n    docker run -it --entrypoint /opt/tabby/bin/tabby-cpu -v $HOME/.tabby:/data tabbyml/tabby scheduler --now\n\nThe expected output looks like this:\n\n    \n    \n    icy@Icys-Ubuntu:~$ docker run -it --entrypoint /opt/tabby/bin/tabby-cpu -v $HOME/.tabby:/data tabbyml/tabby scheduler --now Syncing 1 repositories... Cloning into '/data/repositories/my_private_project'... remote: Enumerating objects: 51, done. remote: Total 51 (delta 0), reused 0 (delta 0), pack-reused 51 Receiving objects: 100% (51/51), 7.16 KiB | 2.38 MiB/s, done. Resolving deltas: 100% (18/18), done. Building dataset... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:00<00:00, 55.56it/s] Indexing repositories... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:00<00:00, 73737.70it/s]\n\nSubsequently, launch the server using the following command:\n\n    \n    \n    docker run -it --gpus all -p 8080:8080 -v $HOME/.tabby:/data tabbyml/tabby serve --model StarCoder-1B --device cuda\n\nThe expected output upon successful initiation of the server should like this:\n\n    \n    \n    icy@Icys-Ubuntu:~$ docker run -it --gpus all -p 8080:8080 -v $HOME/.tabby:/data tabbyml/tabby serve --model StarCoder-1B --device cuda 2024-03-21T16:16:47.189632Z INFO tabby::serve: crates/tabby/src/serve.rs:118: Starting server, this might take a few minutes... 2024-03-21T16:16:47.190764Z INFO tabby::services::code: crates/tabby/src/services/code.rs:53: Index is ready, enabling server... ggml_init_cublas: GGML_CUDA_FORCE_MMQ: no ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes ggml_init_cublas: found 1 CUDA devices: Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes 2024-03-21T16:16:52.464116Z INFO tabby::routes: crates/tabby/src/routes/mod.rs:35: Listening at 0.0.0.0:8080\n\nNotably, the line Index is ready, enabling server... signifies that the server\nhas been successfully launched with the constructed index.\n\n## Verifying Indexing Results\n\nTo confirm that the code completion is effectively utilizing the built index,\nyou can employ the code search feature to validate the indexing process:\n\n  1. Access the Swagger UI page at http://localhost:8080/swagger-ui/#/v1beta/search.\n  2. Click on the Try it out button, and input the query parameter q with a symbol to search for.\n  3. Click the Execute button to trigger the search and see if there are any relevant code snippets was found.\n\nIn the screenshot below, we use CodeSearch as the query string and find some\ncode snippets related in the Tabby repository:\n\nAlternatively, if you have utilized the code completion with the constructed\nindex, you can examine the server log located in ~/.tabby/events to inspect\nhow the prompt is enhanced during code completion.\n\n## Additional Notes\n\nStarting from version v0.9, Tabby offers a web UI to manage your git\nrepository contexts. Additionally, a scheduler job management system has been\nintegrated, streamlining the process of monitoring scheduler job statuses.\nWith these enhancements, you can save a lot of effort in maintaining yaml\nconfig files and docker compose configurations. Furthermore, users can easily\nmonitor visualized indexing results through the built-in code browser. In the\nupcoming v0.11, a new feature will be introduced that enables a direct\nconnection to GitHub, simplifying and securing your access to private GitHub\nrepositories.\n\nFor further details and guidance, please refer to administration documents.\n\nTags:\n\n  * deployment\n  * repository context\n\nEdit this page\n\n  * Generating a Personal Access Token\n  * Configuration\n  * Building the Index\n  * Verifying Indexing Results\n  * Additional Notes\n\nLinks\n\n  * Docs\n  * Playground\n  * API\n\nCommunity\n\n  * Slack\n  * GitHub\n\nMore\n\n  * Blog\n  * Status\n  * Media Kit\n\nCopyright \u00a9 2024 TabbyML, Inc.\n\n", "frontpage": false}
