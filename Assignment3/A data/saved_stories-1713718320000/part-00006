{"aid": "40103479", "title": "Intel Introduces Gaudi3 Accelerator", "url": "https://www.anandtech.com/show/21342/intel-introduces-gaudi-3-accelerator-going-bigger-and-aiming-higher", "domain": "anandtech.com", "votes": 2, "user": "g42gregory", "posted_at": "2024-04-21 06:00:32", "comments": 0, "source_title": "Intel Introduces Gaudi 3 AI Accelerator: Going Bigger and Aiming Higher In AI Market", "source_text": "Intel Introduces Gaudi 3 AI Accelerator: Going Bigger and Aiming Higher In AI\nMarket\n\n## We value your privacy\n\nWe and our store and/or access information on a device, such as cookies and\nprocess personal data, such as unique identifiers and standard information\nsent by a device for personalised advertising and content, advertising and\ncontent measurement, audience research and services development. With your\npermission we and our partners may use precise geolocation data and\nidentification through device scanning. You may click to consent to our and\nour 890 partners\u2019 processing as described above. Alternatively you may access\nmore detailed information and change your preferences before consenting or to\nrefuse consenting. Please note that some processing of your personal data may\nnot require your consent, but you have a right to object to such processing.\nYour preferences will apply to this website only. You can change your\npreferences or withdraw your consent at any time by returning to this site and\nclicking the \"Privacy\" button at the bottom of the webpage.\n\nPlease note that this website/app uses one or more Google services and may\ngather and store information including but not limited to your visit or usage\nbehaviour. You may click to grant or deny consent to Google and its third-\nparty tags to use your data for below specified purposes in below Google\nconsent section.\n\n  * ABOUT\n  * BENCH\n  * FORUMS\n  * PODCAST\n\nABOUT BENCH FORUMS PODCAST LOGIN REGISTER\n\nPC Components\u25bc\n\n  * CPUs\n  * GPUs\n  * Motherboards\n  * SSDs\n  * Cases/Cooling/PSUs\n  * Memory\n  * NAS\n  * Storage\n\nSmartphones & tablets\u25bc\n\n  * Smartphones\n  * Tablets\n  * Huawei\n  * HTC\n  * Samsung\n  * Google/Android\n  * Microsoft\n  * Apple\n  * SoCs\n\nSystems\u25bc\n\n  * Notebook Reviews\n  * Desktop Reviews\n  * Mac Reviews\n  * Ultrabooks\n\nENTERPRISE & IT\n\nGUIDES\u25bc\n\n  * Best CPUs\n  * Best SSDs\n  * Best Laptops\n  * Best Android Phones\n  * Best Video Cards\n  * Best PSUs\n  * Best Motherboards\n  * Best Gaming Laptops\n  * Best Mechanical Keyboards\n  * Best Consumer HDDs\n\nDEALS\n\n# Intel Introduces Gaudi 3 AI Accelerator: Going Bigger and Aiming Higher In\nAI Market\n\nby Ryan Smith on April 9, 2024 11:35 AM EST\n\n  * Posted in\n  * GPUs\n  * Intel\n  * Accelerator\n  * AI\n  * HBM2E\n  * Habana\n  * Gaudi\n  * Gaudi 3\n  * Intel Vision 2024\n\n20 Comments | Add A Comment\n\n20 Comments + Add A Comment\n\nIntel this morning is kicking off the second day of their Vision 2024\nconference, the company\u2019s annual closed-door business and customer-focused\nget-together. While Vision is not typically a hotbed for new silicon\nannouncements from Intel \u2013 that\u2019s more of an Innovation thing in the fall \u2013\nattendees of this year\u2019s show are not coming away empty handed. With a heavy\nfocus on AI going on across the industry, Intel is using this year\u2019s event to\nformally introduce the Gaudi 3 accelerator, the next-generation of Gaudi high-\nperformance AI accelerators from Intel\u2019s Habana Labs subsidiary.\n\nThe latest iteration of Gaudi will be launching in the third quarter of 2024,\nand Intel is already shipping samples to customers now. The hardware itself is\nsomething of a mixed bag in some respects (more on that in a second), but with\n1835 TFLOPS of FP8 compute throughput, Intel believes it\u2019s going to be more\nthan enough to carve off a piece of the expansive (and expensive) AI market\nfor themselves. Based on their internal benchmarks, the company expects to be\nable beat NVIDIA\u2019s flagship Hx00 Hopper architecture accelerators in at least\nsome critical large language models, which will open the door to Intel\ngrabbing a larger piece of the AI accelerator market at a critical time in the\nindustry, and a moment when there simply isn\u2019t enough NVIDIA hardware to go\naround.\n\nThe upcoming launch of Gaudi 3 also comes amidst a change in how Intel is\npositioning its AI accelerator products \u2013 one that has seen the Gaudi lineup\nelevated to Intel\u2019s flagship server accelerator. Traditionally downplayed in\nfavor of Intel\u2019s GPU Data Center Max products (Ponte Vecchio), Habana Labs and\nGaudi have gained a new respect within Intel following the cancellation of\nRialto Bridge in favor of the 2025 release of Falcon Shores. In short, Intel\ndoesn\u2019t have any other new AI accelerator silicon coming out besides Gaudi 3,\nso Intel is going to war with the chip that it has.\n\nAbove: Intel 2023 Data Center Silicon Roadmap, With GPUs\n\nWhich is not to knock Habana Labs or Gaudi 3 in advance. Intel thinks they can\nwin here on performance; if they can, that\u2019s a big deal. But this is a product\nthat\u2019s clearly been uplifted from a side-project under the Intel umbrella to a\nfront-and-center processor. So the scope of Gaudi 3\u2019s abilities, hardware, and\nwhat kind of markets Intel is chasing, is narrower than we\u2019ve seen with some\nof their other flagship products.\n\nGaudi Accelerator Specification Comparison  \n---  \nGaudi 3| Gaudi 2| Gaudi (1)  \nMatrix Math Engines| 8| 2| 1  \nTensor Cores| 64| 24| 8  \nClockspeed| ?| ?| ?  \nMemory Clock| 3.7Gbps HBM2e| 3.27Gbps HBM2e| 2Gbps HBM2  \nMemory Bus Width| 2x 4096-bit| 6144-bit| 4096-bit  \nMemory Bandwidth| 3.7TB/sec| 2.45TB/sec| 1TB/sec  \nVRAM| 128GB (2x 64GB)| 96GB| 32GB  \nFP8 Matrix| 1835 TFLOPS| 865 TFLOPS| N/A  \nBF16 Matrix| 1835 TFLOPS| 432 TFLOPS| ? TFLOPS  \nInterconnect| 200Gb Ethernet 24 Links (600GB/sec)| 100Gb Ethernet 24 Links\n(300GB/sec)| 100Gb Ethernet 10 Links (120GB/sec)  \nProcessor| Gaudi 3| Gaudi 2| Gaudi (1)  \nTransistor Count| 2x (A lot)| ?| ?  \nTDP| 900W| 600W| 350W  \nManufacturing Process| TSMC 5nm| TSMC 7nm| TSMC 16nm  \nInterface| OAM 2.0| OAM 1.1| OAM  \n  \nDiving in to the hardware itself, let\u2019s take a look at Gaudi 3.\n\nGaudi 3 is a direct evolution of the Gaudi 2 hardware. Habana Labs has settled\non an architecture they like and consider successful, so Gaudi 3 isn\u2019t\norchestrating a massive overhaul of their architecture (that will come with\nFalcon Shores). The flip side to that, however, is that there\u2019s not a ton to\ntalk about here in terms of new features \u2013 or features that Intel wants to\ndisclose, at least \u2013 so at a high level, Gaudi 3 is more of a good thing.\n\nWith the previous-generation Gaudi 2 accelerator being built on TSMC\u2019s 7nm\nprocess, Habana has brought Gaudi 3 to the newer 5nm process. The Gaudi 3 die,\nin turn, has added a modest amount of computational hardware, expanding from 2\nMatrix Math Engines and 24 Tensor Cores to 4 Matrix Math Engines and 32 Tensor\ncores. Given the limited architecture changes with Gaudi 3, I\u2019m presuming that\nthese tensor cores are still 256 byte-wide VLIW SIMD units, as they were in\nGaudi 2.\n\nWhile Intel isn\u2019t disclosing the total transistor count of the Gaudi 3 die,\nthe limited addition of new hardware has made Gaudi 3 small enough that Intel\nhas been able to pack two dies on to a single chip, making the full Gaudi 3\naccelerator a dual-die setup. Similar to NVIDIA\u2019s recently announced Blackwell\naccelerator, two identical dies are placed on a single package, and are\nconnected via a high bandwidth link in order to give the chip a unified memory\naddress space. According to Intel, the combined dies will behave as a single\nchip, though as the company isn\u2019t disclosing any significant details on the\ndie-to-die link connecting the chips, it remains unclear just how much\nbandwidth is actually available to cross the dies, and at what latency.\n\nIn a rarity for the Habana team, they have disclosed the total throughput of\nthe chip for FP8 precision: 1835 TFLOPS, which is twice the FP8 performance of\nGaudi 2. More interesting is that BF16 performance has apparently increased by\n4x over Gaudi 2, however Intel hasn\u2019t disclosed an official throughput number\nfor that mode, or what architectural changes have led to that improvement.\nEither way, Intel needs to maximize the performance of Gaudi 3 if they\u2019re\ngoing to carve off a piece of the AI market for themselves.\n\nUpdate, 3pm: Habana has since published a whitepaper for Gaudi 3 this\nafternoon, which includes a few more details on the architecture and its\nperformance. The chip's BF16 performance is now 1835 TFLOPS, putting it at\nparity with FP8 performance. This is somewhat surprising to see, since most\narchitectures can execute FP8 at twice their FP16/BF16 rate. Either way, this\nputs Gaudi 3 in a better position than we first thought for higher precision\nBF16 training.\n\nFeeding the beast is an oddly outdated HBM2e memory controller, the same\nmemory type supported by Gaudi 2. While Intel is probably a smidge too early\nfor HBM3E, I am very surprised not to see HBM3 supported, both for the greater\nmemory bandwidth and greater memory capacity the HBM3 lineage affords. As a\nresult of sticking with HBM2e, the highest capacity stacks available are 16GB,\ngiving the accelerator a total of 128GB of memory. This is clocked at\n3.7Gbps/pin, for a total memory bandwidth of 3.7TB/second. Each Gaudi 3 die\noffers 4 HBM2e PHYs, bringing the chip\u2019s total to 8 stacks of memory.\n\nMeanwhile, each Gaudi 3 die has 48MB of SRAM on-board, giving the complete\nchip 96MB of SRAM. According to Intel, the aggregate SRAM bandwidth is\n12.8TB/second.\n\nIntel is not disclosing the clockspeed of the Gaudi 3 accelerator (nor did\nthey ever disclose Gaudi 2\u2019s, for that matter). However given that Intel has\nmore than doubled the hardware on-hand, we\u2019re likely looking at lower\nclockspeeds overall. Even with the smaller 5nm die, two dies means a whole lot\nmore transistors to feed, and not a ton of additional power to do it.\n\nOn that note, the TDP for the basic, air-cooled Gaudi 3 accelerator is 900\nWatts, 50% higher than the 600W limit of its predecessor. Intel is making use\nof the OAM 2.0 form factor here, which affords a higher power limit than OAM\n1.x (700W). However, Intel is also developing and qualifying liquid-cooled\nversions of Gaudi 3, which will offer higher performance in exchange for even\nhigher TDPs. All forms of Gaudi 3 will use PCIe backhaul to connect to their\nhost CPU, with Gaudi 3 sporting a PCIe Gen 5 x16 link.\n\nBroadly speaking, the limited details on the Gaudi architecture remind me a\ngreat deal of AMD\u2019s Instinct MI250X accelerator. That CDNA 2 part was in many\nways a pair of die-shrunk MI100s placed together on a single chip, bringing\nfew new architectural features, but a whole lot more silicon to do the heavy\nlifting. Critically, however, MI250X presented itself as two accelerators\n(despite the Infinity Fabric links between the dies), whereas Gaudi 3 is\nsupposed to behave as a single unified accelerator.\n\n### Networking: Ethernet Taken To The Extreme\n\nOutside of the core architecture of the Gaudi 3, Habana\u2019s other big\ntechnological upgrade with Gaudi 3 has been on the I/O side of matters. Going\nback to the earliest days of Gaudi, Habana has relied on an all-Ethernet\narchitecture for their chips, using Ethernet for both on-node chip-to-chip\nconnectivity, and scale-out node-to-node connectivity. It is essentially the\ninverse of what NVIDIA has done, scaling Ethernet down to the chip level,\nrather than scaling NVLink up to the rack level.\n\nGaudi 2 offered 24 100Gb Ethernet links per chip; Gaudi 3 doubles the\nbandwidth of those links to 200Gb/second, giving the chip a total external\nEthernet I/O bandwidth of 8.4TB/second cumulative up/down.\n\nThe recommended topology for Gaudi 3 \u2013 and what Intel will be employing in\ntheir own baseboards \u2013 is a 21/3 split. 21 links will be used for on-node,\nchip-to-chip connectivity, with 3 links going to each of the other 7 Gaudi 3\naccelerators on a fully populated 8-way node.\n\nThe remaining 3 links from each chip, meanwhile, will be used to feed a sextet\nof 800Gb Octal Small Form Factor Pluggable (OSFP) Ethernet links. Via the use\nof retimers, the ports will be split up in blocks of two, and then balanced\nover 5 accelerators.\n\nUltimately, Intel is looking to push the scalability of Gaudi 3 here, both in\nterms of performance and marketability. With the largest of LLMs requiring\nmany nodes to be linked together to form a single cluster to provide the\nnecessary memory and compute performance for training, the biggest customers\nthat Intel is chasing with Gaudi 3 will need an AI accelerator that can scale\nout to these large sizes \u2013 and thus giving Intel plenty of opportunity to sell\nan equally large number of accelerators. All the while, by embracing a pure\nEthernet setup, Intel is banking on winning over customers who don\u2019t want to\ninvest in proprietary/alternative interconnects such as InfiniBand.\n\nUltimately, Intel has networking topologies for as many as 512 nodes already\ndeveloped, using 48 spine switches to connect up to 32 clusters \u2013 each of\nwhich houses 16 nodes. And according to Intel, Gaudi 3 can still scale further\nthan that, out to thousands of nodes.\n\n### Performance: Beating H100 At Llamas and Falcons\n\nThroughout the lifetime of the Gaudi accelerators, Intel and Habana have\npreferred to focus on talking about the performance of the chips instead of\njust the specifications, and for Gaudi 3 that is not changing. With the bulk\nof Vision\u2019s attendees being business clientele, Intel is looking to make a\nsplash with benchmark-based performance figures that demonstrate what Gaudi 3\ncan actually do.\n\nI\u2019m not going to spend too much time going over these since they\u2019re primarily\ncompetitive performance claims that we can\u2019t validate. But it\u2019s noteworthy\nhere that the Gaudi team opted to go straight at NVIDIA here by using their\nown benchmarks and result sets. In other words, the Gaudi performance figures\nprovided by Intel are plotted against NVIDIA\u2019s own self-reported figures,\nrather than Intel cooking up scenarios to disadvantage NVIDIA. That said, it\nmust also be noted that these are performance projections, and not measured\nperformance of assembled systems (and I doubt Intel has 8192 Gaudi 3s sitting\naround for this).\n\nCompared to H100, Intel is claiming that Gaudi 3 should beat H100 by up to\n1.7x in training Llama2-13B in a 16 accelerator cluster at FP8 precision. Even\nthough H100 is coming up on 2 years old, beating H100 at training anything by\na significant degree would be a big win for Intel if it pans out.\n\nMeanwhile, Intel is projecting 1.3x to 1.5x the inferencing performance of\nH200/H100 with Gaudi 3, and perhaps most notably, at up to 2.3x the power\nefficiency.\n\nAs always, however, the devil is in the details. Intel still loses to the H100\nat times in these inference workloads \u2013 particularly those without 2K outputs\n\u2013 so the Gaudi 3 is far from a clean sweep. And, of course, there are all of\nthe benchmark results that Intel isn\u2019t promoting.\n\nTo Intel\u2019s credit, however, they are the only other major hardware\nmanufacturer who has been providing MLPerf results as of late. So however\nGaudi 3 will perform (and how Gaudi 2 currently performs), they have been far\nmore above-board than most in publishing results for industry-standard tests.\n\n### OAM and PCIe Cards Launching In Second-Half of 2024\n\nWrapping things up, Intel will be releasing their first Gaudi 3 products in\nthe next quarter. The company already has air-cooled versions of the OEAM\naccelerator in their labs for qualification and out to customers for sampling,\nmeanwhile the liquid-cooled versions will be sampling this quarter.\n\nFinally, in a first time for the Gaudi team, Intel will be offering a version\nof Gaudi 3 in a more traditional PCIe form factor as well. The HL-338 card is\na 10.5-inch full height dual-slot PCIe card. It offers all of the same\nhardware as the OAM Gaudi 3, right on down to the peak performance of 1835\nTFLOPS FP8. However it will ship with a far more PCIe-slot friendly TDP of 600\nWatts \u2013 300 Watts less than the OAM card \u2013 so sustained performance should be\nnotably lower.\n\nThough not pictured in Intel\u2019s slide, the PCIe cards offer two 400Gb Ethernet\nports for scale-out configurations. Meanwhile Intel will be offering a \u201ctop\nboard\u201d for the PCIe cards that, similar to NVIDIA\u2019s NVLink bridges, can link\nup to 4 of them for inter-card communication. The OAM form factor will remain\nthe way to go for both highest performance on a per-accelerator basis and to\nmaximize scale-out potential, but for customers who need something to plug and\ngo in traditional PCIe slots, there is finally an option for that for a Gaudi\naccelerator.\n\nThe PCIe version of the Gaudi 3 is set to launch in the 4^th quarter of this\nyear, alongside the liquid cooled version of the OAM module.\n\nGallery: Intel Gaudi 3 Press Deck\n\nPRINT THIS ARTICLE\n\n  * ### Post Your Comment\n\nPlease log in or sign up to comment.\n\nPOST A COMMENT\n\n## 20 Comments\n\n### View All Comments\n\n  * #### trivik12 - Tuesday, April 9, 2024 - link\n\nThis is not firing on all cylinders. Should have used HBM3 and TSMC N3B or\nIntel 3. This is the most important product in today's times and Intel is\nbeing too conservative with their choices. Its not going to make much of a\nsplash in the market. Hopefully Falcon Shores goes all in with Intel 18A, HBM\n3E and everything else. Reply\n\n  * #### elmagio - Tuesday, April 9, 2024 - link\n\nA chip that size on a 3nm node would cost so much and have yields so\ncatastrophic they'd probably lose money even at the insane pricing of AI\nchips.\n\nRegardless, it's most likely a foolish endeavor to bet everything on producing\nthe *best* AI chip at any cost today considering Nvidia's headstart. It's a\nmuch smarter play to aim for somewhere between a H100 and H200 at acceptable\ncosts because that's actually a realistic goal. Reply\n\n  * #### Threska - Tuesday, April 9, 2024 - link\n\nAI in a lot of IoT. Reply\n\n  * #### Silma - Wednesday, April 10, 2024 - link\n\nEven NVIDIA is going for TSMC's 4nm, not the 3nm. There must be a reason.\nEither low yield or cost or Apple's exclusivity.\n\nRegarding memory, it's strange. I wonder if Intel's decision is based on not\nwanting to spend money, or if there aren't enough HBM3/E available on the\nmarket. After all, NVIDIA surely did secure enough memory chips for its\naccelerators. Reply\n\n  * #### Bruzzone - Friday, April 19, 2024 - link\n\nDepreciated process cost TSMC 4__. mb Reply\n\n  * #### Kevin G - Tuesday, April 9, 2024 - link\n\nWhile a step up from Gaudi 2, this seems too little too late given that\nnVidia's Blackwell was announced beforehand. Granted neither of these are\nshipping with the common comparison point being Hopper. While faster than that\ncomparison point via Intel's chosen benchmarks, it really has to do better\nthan Blackwell which doesn't seem likely given what nVidia has said about its\nown generational improvements.\n\nThe other huge factor here is interconnects to scale up. Ethernet is a more\ncommodity choice but does permit scaling upward to huge numbers and has\nbenefits of being able to interop with other systems/accelerators. It would\nhave been nice if Intel hadn't sold off their Ethernet switch division 15\nmonths ago as there is a good pairing of technologies here. Essentially throw\na newer Barefoot switch ASIC on the base board and leverage a 100GbaseKX style\nspec to link everything together on the board with massive uplink bandwidth to\ngo outside of the node.\n\nScaling counts upward is supposed to be Gaudi 3's specialty and Intel should\npower and price these to enable this and permit clusters outperform those form\ntheir competitors. If you can't win on a 1:1 battle, make it a 2:1 battle\nwhere you can win. At 900W per board, there are costs and cooling complexities\nthere if Intel is driving the design hard. Lowering clocks and voltages maybe\nwarranted if operating at 600W can do 85% of the performance at 900W. It'd\nmake things cheaper to cool and maintain. There is a niche opportunity win to\nbe able to replace existing clusters without needing to go to liquid cooling\nwhich given Intel's position should press hard. Similarly Intlel should be\nundercutting its competitors in price in an effort to gain market share here\nwhile emphasizing performance per dollar (which includes the power side of\nthings). I don't see Intel going in this direction for various reasons and\nthey'll wind up with another 'success' like Ponte Vecchio on their hands.\nReply\n\n  * #### Blastdoor - Tuesday, April 9, 2024 - link\n\nKind of a bummer that Intel isn\u2019t manufacturing this themselves, but rather\nrelying on TSMC. Reply\n\n  * #### ballsystemlord - Tuesday, April 9, 2024 - link\n\nWhy sell off their fabs when they can outsource both their production\ncapabilities and needs? (sarcasm). Reply\n\n  * #### name99 - Saturday, April 20, 2024 - link\n\nI think the word you mean is \u201cred flag\u201d, not \u201cbummer\u201d... Reply\n\n  * #### Oxford Guy - Tuesday, April 9, 2024 - link\n\n'Lowering clocks and voltages maybe warranted if operating at 600W can do 85%\nof the performance at 900W. It'd make things cheaper to cool and maintain.'\n\nPer the article, Intel will sell a 600W PCI-e version. Reply\n\n## PIPELINE STORIES\n\n\\+ Submit News\n\nSK Hynix and TSMC Team Up for HBM4 Development AMD Announces Ryzen Pro 8000\nand Ryzen Pro 8040 Series CPUs: Commercial Desktop Gets AI TSMC Posts Q1'24\nResults: 3nm Revenue Share Drops Steeply, but HPC Share Rises\n\n  * ASML Patterns First Wafer Using High-NA EUV Tool, Ships Second High-NA Scanner\n  * Intel and Sandia National Labs Roll Out 1.15B Neuron \u201cHala Point\u201d Neuromorphic Research System\n  * Samsung Unveils 10.7Gbps LPDDR5X Memory - The Fastest Yet\n  * Samsung To Receive $6.4 Billion Under CHIPS Act to Build $40 Billion Fab in Texas\n  * NVIDIA Intros RTX A1000 and A400: Entry-Level ProViz Cards Get Ray Tracing\n  * Corsair Enters Workstation Memory Market with WS Series XMP/EXPO DDR5 RDIMMs\n  * Western Digital Previews 4 TB SD Card: World's Highest-Capacity\n  * AMD Quietly Launches Ryzen 7 8700F and Ryzen 5 8400F Processors\n  * Intel Teases Lunar Lake At Intel Vision 2024: 100+ TOPS Overall, 45 TOPS From NPU Alone\n\n## LINKS\n\n  * Home\n  * About\n  * Forums\n  * RSS\n  * Pipeline News\n  * Bench\n  * Terms of Use\n  * Contact Us\n  * Accessibility Statement\n\n## TOPICS\n\n  * CPUs\n  * Motherboards\n  * SSD/HDD\n  * GPUs\n  * Mobile\n  * Enterprise & IT\n  * Smartphones\n  * Memory\n  * Cases/Cooling/PSU(s)\n\n  * Displays\n  * Mac\n  * Systems\n  * Cloud\n  * Trade Shows\n  * Guides\n\n## FOLLOW\n\n  * Facebook\n  * Twitter\n  * RSS\n\nThe Most Trusted in Tech Since 1997\n\n  * About\n  * Advertising\n  * Privacy Policy\n\nCopyright \u00a9 2024. All rights reserved.\n\n  * TOPICS\n  * FOLLOW\n  * ABOUT\n\n  * CPUs\n  * Motherboards\n  * SSD/HDD\n  * GPUs\n  * Mobile\n\n  * Enterprise & IT\n  * Smartphones\n  * Memory\n  * Cases/Cooling/PSU(s)\n  * Displays\n\n  * Mac\n  * Systems\n  * Cloud\n  * Trade Shows\n  * Guides\n\nFacebook\n\nTwitter\n\nRSS\n\nAbout\n\nAdvertising\n\nPrivacy Policy\n\nContact Us\n\nTerms of Use\n\nShow Full Site\n\nCopyright \u00a9 2024. All rights reserved.\n\nBENCH\n\n  * CPU\n  * SSD\n  * GPU 2013\n  * GPU 2012\n  * Smartphone 2011\n  * Mobile\n\nTOPICS\n\n  * CPUs\n  * Motherboards\n  * SSD/HDD\n  * GPUs\n  * Mobile\n  * Enterprise & IT\n  * Smartphones\n  * Memory\n\n  * Cases/Cooling/PSU(s)\n  * Displays\n  * Mac\n  * Systems\n  * Cloud\n  * Trade Shows\n  * Guides\n\nFOLLOW\n\nFacebook\n\nTwitter\n\nRSS\n\nABOUT\n\n  * About\n  * Advertising\n  * Privacy Policy\n  * Contact Us\n  * Show Full Site\n  * Copyright \u00a9 2024. All rights reserved.\n\n## Log in\n\n### Don't have an account? Sign up now\n\nLost your password?\n\nWe\u2019ve updated our terms. By continuing to use the site and/or by logging into\nyour account, you agree to the Site\u2019s updated Terms of Use and Privacy Policy.\n\n", "frontpage": false}
