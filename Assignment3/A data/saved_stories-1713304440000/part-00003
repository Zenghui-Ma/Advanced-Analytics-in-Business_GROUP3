{"aid": "40052436", "title": "Chaz: An LLM <-> Matrix Chatbot", "url": "https://jackson.dev/post/chaz/", "domain": "jackson.dev", "votes": 1, "user": "Arcuru", "posted_at": "2024-04-16 14:30:36", "comments": 0, "source_title": "Chaz: An LLM <-> Matrix Chatbot", "source_text": "Chaz: An LLM <-> Matrix Chatbot \u00b7 Patrick Jackson\n\n# Chaz: An LLM <-> Matrix Chatbot\n\nChaz is a Matrix bot that connects you to a large number of LLM models. It is\na replacement for the Chat interfaces that you might be used to when working\nwith LLMs.\n\nCode repository\n\nInstead of dealing with each company\u2019s custom interfaces, this just moves your\nchats into Matrix with all the features of your favorite Matrix client.\n\n(Chaz is written in Rust, and while building this I also built a very basic\nMatrix Bot Framework in Rust, headjack)\n\nBy plugging into Matrix, we get a few things for free:\n\n  1. Use any Matrix client you want, and any Matrix tooling since they are just Matrix chats.\n  2. Let anyone you want use it (there\u2019s an allow_list). For example, run a bot yourself and share access to your API keys with your less technical friends. Or access to your internal company models/keys.\n  3. Share a chat session with anyone. Just add them into the Room.\n\nOriginally I wanted to allow users to use their own API keys, so you could run\nthis as a simple service and just point people to it instead of making\neveryone run this themselves. There are obvious security implications with\nthis though since whoever controlled the bot would have access to the keys,\nand I don\u2019t want to deal with that now.\n\nI have setup a demo account if you want to test it out a little, but long term\nthis is something you\u2019ll need to run yourself. You\u2019ll only be able to send a\nfew messages to the demo account, and you won\u2019t be able to use it in large\nrooms. It\u2019s also running a system prompt that is more for amusement than\npracticality.\n\nThe demo is @chaz-demo:jackson.dev\n\n## Why Link to heading\n\nA few weeks ago I was trying to play with different LLMs. Running some locally\nwith ollama or llamafile, using ChatGPT or Gemini, or other APIs like\nTogether.ai or Groq. All of those have different interfaces, either custom\nmade or only available over API.\n\nBut it\u2019s just a Chat interface, and I have already been moving all of my chats\ninto Matrix.\n\nAIChat was the missing piece that tied it together for me. It\u2019s a command line\ninterface that lets you setup a lot of different backends and select them on\nthe command line. Pushing ollama and ChatGPT into the same interface.\n\nSo I had an idea, it\u2019d be easy to write a simple Matrix bot, with a mostly\ntext interface, and use AIChat as the backend to unify everything into Matrix.\n\n### Why is it called Chaz? Link to heading\n\nSeveral months ago I saw someone on Hackernews mention that they use a system\nprompt requesting that the models refer to themselves as Chaz in the 3rd\nperson. I\u2019ve been using it myself and I find it hilarious.\n\nI think it was a reference to Chazzzzz from the show Disenchantment.\n\n## Results Link to heading\n\nAfter a bit of work, I now have Chaz. It is pretty rough, but I already use it\nas a mostly fully capable replacement for the other interfaces. You can:\n\n  1. Send the chats to any backend setup in AIChat.\n  2. Send images to the image models.\n  3. Switch between backends in the middle of a session.\n  4. Rename the Room/Topic using a model.\n  5. Setup a role/system prompt to whatever you want.\n\nIt very quickly became a workable replacement for the Chat interfaces I had\nbeen using.\n\n### Matrix Bot Framework for Rust Link to heading\n\nI wrote this in Rust but there doesn\u2019t seem to exist a Matrix bot framework\nfor Rust. So I ended up splitting out headjack into it\u2019s own project.\n\nIt handles the bare minimum necessary to deal with the Matrix protocol with a\nlean towards helping write bots. A very simple bot could be written on top of\nheadjack with minimal effort\n\n## Usage Link to heading\n\nChaz supports commands (currently everything prefixed with a \u2018.\u2019 to match\nAIChat, but that may change)\n\n    \n    \n    .help Available commands: - .print - Print the conversation - .send - <message> - Send this message without context - .model - <model> - Select the model to use - .list - List available models - .clear - Ignore all messages before this point - .rename - Rename the room and set the topic based on the chat content - .help - Show this message\n\nAny message that isn\u2019t a command causes the entire conversation (up to the\nlast .clear command) to be send to AIChat for completion.\n\n## Future Link to heading\n\nHere are some things I want to do with this, most of which just require some\ntyping and not building anything novel:\n\n  1. Login as your own Matrix account to provide suggested responses to messages. (I\u2019m not sure the cleanest way to setup that interface).\n\n    1. This one is definitely better when it\u2019s builtin to your client, but we may be able to fake this one ok.\n    2. Ideally I\u2019d want to be able to edit my drafts from the bot, but I don\u2019t think Matrix syncs drafts.\n    3. e.g. Give it access to your own account, so you can ask Chaz \u201cHelp me draft a reply in room \u2018Fizx Gang\u2019, I want to explain XYZ\u201d.\n  2. Possibly use the Room Topic to store the configuration, for display/editing of the settings.\n  3. Send to multiple backends in a single session.\n  4. Respond to Reactions (thumbs up/down/etc). Maybe by regenerating responses, selecting the response you want to continue with when using multiple backends, etc.\n  5. Support both sending and receiving files, to hookup to image generation backends.\n  6. Replace AIChat as the backend, as using that as the \u201cAPI\u201d is fairly limiting.\n  7. LLamafile support.\n  8. Support for changing the model settings from the chat. Temperature, Grammar, Tokens requested, etc.\n\n\u00a9 2024 Patrick Jackson \u00b7 Powered by Hugo & Coder.\n\n", "frontpage": false}
