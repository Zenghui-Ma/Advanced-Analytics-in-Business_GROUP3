{"aid": "40052641", "title": "Advanced PostgreSQL Partitioning by Date with YugabyteDB Auto Sharding", "url": "https://www.yugabyte.com/blog/postgresql-advanced-partitioning-by-date/", "domain": "yugabyte.com", "votes": 6, "user": "franckpachot", "posted_at": "2024-04-16 14:45:42", "comments": 0, "source_title": "PostgreSQL Advanced Partitioning with YugabyteDB Sharding", "source_text": "PostgreSQL Advanced Partitioning with YugabyteDB Sharding\n\nSkip to content\n\n  * Sign In\n  * Get Started\n\n    * Try YugabyteDB Managed FreeCloud database managed by us\n    * Download YugabyteDBFree open source database\n    * Book a DemoPersonalized demo\n\nBack to Blog Home\n\n# Advanced PostgreSQL Partitioning by Date with YugabyteDB Auto Sharding\n\nFranck Pachot\n\nApril 16, 2024\n\nRecently, I wrote about how YugabyteDB can scale without having to use\nPostgreSQL declarative partitioning and working around its limitations. I\nreferenced a table from Kyle Hailey\u2019s blog detailing a PostgreSQL production\nissue involving a \u201cpayments\u201d table, where \u201cpayment_id\u201d is the primary key.\nKyle\u2019s post pointed out that including a partition key in the primary key is\nmandatory in PostgreSQL.\n\nIn my blog post, I discussed the scaling process and explained how to hash\nshard the \u201cpayments\u201d table on the \u201cpayment_id\u201d without changing its primary\nkey. This method ensures fast inserts by distributing the table rows across\nthe cluster\u2019s nodes. This approach works seamlessly with YugabyteDB\u2019s\nautomatic sharding and supports the use of any secondary index for additional\nuse cases.\n\nI received some feedback on Reddit and other sites that partitioning on a\ndifferent column may be better. This is true for PostgreSQL, where the\npartition key limits the partitioning of the table and all the indexes.\nHowever, with YugabyteDB sharding, I don\u2019t need to change the table\npartitioning to query a range of dates. YugabyteDB\u2019s secondary indexes are\nglobal, meaning they don\u2019t need to share a sharding key with their table. In\naddition, distributing the rows in a distributed PostgreSQL database like\nYugabyteDB offers extra benefits since it spreads data across multiple active\nservers.\n\nTo query a range of dates, you can create an index on the date and add more\ncolumns for an Index Only Scan. When defined as ascending or descending, this\nindex will be range-sharded and distributed based on its key. Here\u2019s an\nexample:\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\ncreate index on payments ( created ASC, payment_id ) include ( amount );\n\ncreate index on payments ( created ASC, payment_id ) include ( amount );\n\n    \n    \n    create index on payments ( created ASC, payment_id ) include ( amount );\n\nIf you have a reason to partition the table by date to group close dates\ntogether, you can also do that in YugabyteDB. Here is an example.\n\n## Sharding by a Range of Dates\n\nI\u2019ve modified the table\u2019s primary key to include the \u201ccreated\u201d column, similar\nto how you would partition in PostgreSQL.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\ncreate table payments (\n\nprimary key (created ASC, payment_id)\n\n, unique(payment_id)\n\n, payment_id bigint not null generated always as identity (cache 1000)\n\n, created timestamptz not null default now()\n\n, account_id bigint not null\n\n, amount decimal(10,2) not null\n\n)\n\nsplit at values ( ('2001-01-01'),('2002-01-01'),('2003-01-01'),('2004-01-01')\n)\n\n;\n\ncreate table payments ( primary key (created ASC, payment_id) ,\nunique(payment_id) , payment_id bigint not null generated always as identity\n(cache 1000) , created timestamptz not null default now() , account_id bigint\nnot null , amount decimal(10,2) not null ) split at values (\n('2001-01-01'),('2002-01-01'),('2003-01-01'),('2004-01-01') ) ;\n\n    \n    \n    create table payments ( primary key (created ASC, payment_id) , unique(payment_id) , payment_id bigint not null generated always as identity (cache 1000) , created timestamptz not null default now() , account_id bigint not null , amount decimal(10,2) not null ) split at values ( ('2001-01-01'),('2002-01-01'),('2003-01-01'),('2004-01-01') ) ;\n\nMy reasoning behind this approach includes three key points.\n\n  1. I set payment_id as a unique key to ensure it\u2019s indexed and enforced with no duplicates. In SQL, a unique key with non-nullable columns is similar to a primary key. The main difference is its physical organization. By starting the primary key with the \u201ccreated\u201d date, I can group close dates together, which is useful when date range queries are the critical access pattern vs. distributing the inserts.\n  2. I added \u2018ASC\u2018 to the primary key because YugabyteDB defaults to \u2018HASH\u2018 on the first column of the primary key. Since I want to organize the table by a range of dates, I do not want to apply a hash function to this column. If you frequently query for the latest date with \u2018order by created desc limit 10\u2018, then it is better to avoid a backward scan and define it as \u2018HASH\u2018. Both options allow for range sharding.\n  3. Although not mandatory (because the table will be split automatically by YugabyteDB as it grows), I added \u2018split at values\u2018 clause to pre-split the table to five tablets. In my previous blog, I demonstrated that the number of tablets could number in the hundreds or thousands. While it is possible to pre-create hundreds of tablets by providing more splitting values, I opted for simplicity and stuck to the auto-splitting thresholds.\n\nThe table is empty with five tablets, and the hash-sharded index for the\nunique constraints has one tablet per node:\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> select num_tablets from yb_table_properties('payments'::regclass);\n\nnum_tablets\n\n\\-------------\n\n5\n\n(1 row)\n\nyugabyte=> select num_tablets from\nyb_table_properties('payments_payment_id_key'::regclass);\n\nnum_tablets\n\n\\-------------\n\n9\n\n(1 row)\n\nyugabyte=> select num_tablets from yb_table_properties('payments'::regclass);\nnum_tablets ------------- 5 (1 row) yugabyte=> select num_tablets from\nyb_table_properties('payments_payment_id_key'::regclass); num_tablets\n------------- 9 (1 row)\n\n    \n    \n    yugabyte=> select num_tablets from yb_table_properties('payments'::regclass); num_tablets ------------- 5 (1 row) yugabyte=> select num_tablets from yb_table_properties('payments_payment_id_key'::regclass); num_tablets ------------- 9 (1 row)\n\nI can view the tablet boundaries from the console, which shows the data ranges\nin their internal int64 representation, which corresponds to the PostgreSQL\nEpoch (number of microseconds since Jan 1st, 2020):\n\nList of table\u2019s tablets before loading: SplitDepth is zero.\n\n## Auto-Splitting: Let\u2019s Insert a Hundred Million Rows\n\nI will insert the same number of rows as I did in the previous blog: a hundred\nmillion.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> insert into payments (account_id, amount, created)\n\nselect 1000 * random() as account, random() as amount,\n\nrandom() * interval '24.25 year' + timestamp '2000-01-01 00:00:00' as created\n\nfrom generate_series(1,100000) account_id\n\n\\watch c=1000\n\nyugabyte=> insert into payments (account_id, amount, created) select 1000 *\nrandom() as account, random() as amount, random() * interval '24.25 year' +\ntimestamp '2000-01-01 00:00:00' as created from generate_series(1,100000)\naccount_id \\watch c=1000\n\n    \n    \n    yugabyte=> insert into payments (account_id, amount, created) select 1000 * random() as account, random() as amount, random() * interval '24.25 year' + timestamp '2000-01-01 00:00:00' as created from generate_series(1,100000) account_id \\watch c=1000\n\nWhile the table was growing, the tablets were split, and more tablets became\nvisible in the console. \u201cSplitDepth\u201d counted the number of automatic splits\nthat resulted in each tablet.\n\nList of table\u2019s tablets after loading: there are more tablets with higher\nSplitDepth.\n\nAt the end of the load, I have 17 tablets for the table (ranges of date) and\nthe same for the unique index (by hash).\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from\nyb_table_properties('payments'::regclass);\n\nnum_tablets | pg_size_pretty\n\n\\-------------+----------------\n\n17 | 5738 MB\n\n(1 row)\n\nyugabyte=> select num_tablets,\npg_size_pretty(pg_table_size('payments_payment_id_key')) from\nyb_table_properties('payments_payment_id_key'::regclass);\n\nnum_tablets | pg_size_pretty\n\n\\-------------+----------------\n\n17 | 4527 MB\n\n(1 row)\n\nyugabyte=>\n\nyugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from yb_table_properties('payments'::regclass); num_tablets | pg_size_pretty -------------+---------------- 17 | 5738 MB (1 row) yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments_payment_id_key')) from yb_table_properties('payments_payment_id_key'::regclass); num_tablets | pg_size_pretty -------------+---------------- 17 | 4527 MB (1 row) yugabyte=>\n    \n    \n    yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from yb_table_properties('payments'::regclass); num_tablets | pg_size_pretty -------------+---------------- 17 | 5738 MB (1 row) yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments_payment_id_key')) from yb_table_properties('payments_payment_id_key'::regclass); num_tablets | pg_size_pretty -------------+---------------- 17 | 4527 MB (1 row) yugabyte=>\n\nTo view the number of tablets created by range sharding, you can utilize the\nyb_get_range_split_clause() function. This function provides the range clause\nneeded if you want to replicate the table with the same tablet division:\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> select yb_get_range_split_clause('payments'::regclass);\n\nyb_get_range_split_clause\n\n\\-----------------------------------------------------------------------------------------\n\nSPLIT AT VALUES (('2001-01-01 00:00:00+00', MINVALUE), ('2002-01-01\n00:00:00+00', MINVALUE), ('2003-01-01 00:00:00+00', MINVALUE), ('2004-01-01\n00:00:00+00', MINVALUE), ('2005-07-24 14:37:18.5088+00', 2040738),\n('2006-12-29 17:30:45.9936+00', 13050457), ('2009-08-15 00:22:12.5472+00',\n15029518), ('2010-12-14 10:55:54.6816+00', 46169115), ('2011-12-30\n05:40:38.8704+00', 38646207), ('2014-04-03 01:05:37.4208+00', 5689338),\n('2015-10-23 17:18:36.1728+00', 16944332), ('2017-04-06 17:42:07.8624+00',\n14921933), ('2018-08-19 21:15:27.6768+00', 63227870), ('2019-10-15\n04:40:06.528+00', 8756978), ('2021-02-02 10:10:58.3968+00', 37865384),\n('2022-05-14 02:18:22.8672+00', 27792641))\n\n(1 row)\n\nyugabyte=>\n\nyugabyte=> select yb_get_range_split_clause('payments'::regclass);\nyb_get_range_split_clause\n-----------------------------------------------------------------------------------------\nSPLIT AT VALUES (('2001-01-01 00:00:00+00', MINVALUE), ('2002-01-01\n00:00:00+00', MINVALUE), ('2003-01-01 00:00:00+00', MINVALUE), ('2004-01-01\n00:00:00+00', MINVALUE), ('2005-07-24 14:37:18.5088+00', 2040738),\n('2006-12-29 17:30:45.9936+00', 13050457), ('2009-08-15 00:22:12.5472+00',\n15029518), ('2010-12-14 10:55:54.6816+00', 46169115), ('2011-12-30\n05:40:38.8704+00', 38646207), ('2014-04-03 01:05:37.4208+00', 5689338),\n('2015-10-23 17:18:36.1728+00', 16944332), ('2017-04-06 17:42:07.8624+00',\n14921933), ('2018-08-19 21:15:27.6768+00', 63227870), ('2019-10-15\n04:40:06.528+00', 8756978), ('2021-02-02 10:10:58.3968+00', 37865384),\n('2022-05-14 02:18:22.8672+00', 27792641)) (1 row) yugabyte=>\n\n    \n    \n    yugabyte=> select yb_get_range_split_clause('payments'::regclass); yb_get_range_split_clause ----------------------------------------------------------------------------------------- SPLIT AT VALUES (('2001-01-01 00:00:00+00', MINVALUE), ('2002-01-01 00:00:00+00', MINVALUE), ('2003-01-01 00:00:00+00', MINVALUE), ('2004-01-01 00:00:00+00', MINVALUE), ('2005-07-24 14:37:18.5088+00', 2040738), ('2006-12-29 17:30:45.9936+00', 13050457), ('2009-08-15 00:22:12.5472+00', 15029518), ('2010-12-14 10:55:54.6816+00', 46169115), ('2011-12-30 05:40:38.8704+00', 38646207), ('2014-04-03 01:05:37.4208+00', 5689338), ('2015-10-23 17:18:36.1728+00', 16944332), ('2017-04-06 17:42:07.8624+00', 14921933), ('2018-08-19 21:15:27.6768+00', 63227870), ('2019-10-15 04:40:06.528+00', 8756978), ('2021-02-02 10:10:58.3968+00', 37865384), ('2022-05-14 02:18:22.8672+00', 27792641)) (1 row) yugabyte=>\n\nFrom this, it\u2019s clear that range sharding considers the entire key. Therefore\nif a huge amount of data is loaded for the same date, it can be split further\nwithin the same date.\n\n## Query on a Range of Dates: 80000 Rows in 250 Milliseconds\n\nRemember, my primary goal when partitioning on the date was to query a range\nof dates.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, dist, costs off, summary on)\n\nselect * from payments\n\nwhere created between date '2023-12-25'::timestamptz\n\nand '2024-01-02'::timestamptz\n\norder by created\n\n;\n\nQUERY PLAN\n\n\\------------------------------------------------------------------------------------\n\nIndex Scan using payments_pkey on payments\n\n(actual time=3.568..246.471 rows=80142 loops=1)\n\nIndex Cond: ((created >= ('2023-12-25'::date)::timestamp with time zone) AND\n\n(created <= '2024-01-02 00:00:00+00'::timestamp with time zone))\n\nStorage Table Read Requests: 79\n\nStorage Table Read Execution Time: 202.721 ms\n\nPlanning Time: 0.065 ms\n\nExecution Time: 250.869 ms\n\nStorage Read Requests: 79\n\nStorage Read Execution Time: 202.721 ms\n\nStorage Execution Time: 202.721 ms\n\nPeak Memory Usage: 8 kB\n\n(14 rows)\n\nyugabyte=> explain (analyze, dist, costs off, summary on) select * from\npayments where created between date '2023-12-25'::timestamptz and\n'2024-01-02'::timestamptz order by created ; QUERY PLAN\n------------------------------------------------------------------------------------\nIndex Scan using payments_pkey on payments (actual time=3.568..246.471\nrows=80142 loops=1) Index Cond: ((created >= ('2023-12-25'::date)::timestamp\nwith time zone) AND (created <= '2024-01-02 00:00:00+00'::timestamp with time\nzone)) Storage Table Read Requests: 79 Storage Table Read Execution Time:\n202.721 ms Planning Time: 0.065 ms Execution Time: 250.869 ms Storage Read\nRequests: 79 Storage Read Execution Time: 202.721 ms Storage Execution Time:\n202.721 ms Peak Memory Usage: 8 kB (14 rows)\n\n    \n    \n    yugabyte=> explain (analyze, dist, costs off, summary on) select * from payments where created between date '2023-12-25'::timestamptz and '2024-01-02'::timestamptz order by created ; QUERY PLAN ------------------------------------------------------------------------------------ Index Scan using payments_pkey on payments (actual time=3.568..246.471 rows=80142 loops=1) Index Cond: ((created >= ('2023-12-25'::date)::timestamp with time zone) AND (created <= '2024-01-02 00:00:00+00'::timestamp with time zone)) Storage Table Read Requests: 79 Storage Table Read Execution Time: 202.721 ms Planning Time: 0.065 ms Execution Time: 250.869 ms Storage Read Requests: 79 Storage Read Execution Time: 202.721 ms Storage Execution Time: 202.721 ms Peak Memory Usage: 8 kB (14 rows)\n\nThis approach splits data into date ranges to keep the table size manageable\nand keeps the rows sorted in the LSM Tree. As a result, it eliminates the need\nfor an extra Sort operation for ORDER BY.\n\n## Query on a Global Unique Index in 2 milliseconds\n\nThe additional UNIQUE key on payment_id can be used to get fast access to the\ntable\u2019s business key because our primary key is now a surrogate key with a\ndifferent order:\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, dist, costs off, summary off )\n\nselect * from payments\n\nwhere payment_id = 42\n\norder by created\n\n;\n\nQUERY PLAN\n\n\\----------------------------------------------------------\n\nSort (actual time=4.105..4.105 rows=1 loops=1)\n\nSort Key: created\n\nSort Method: quicksort Memory: 25kB\n\n-> Index Scan using payments_payment_id_key on payments\n\n(actual time=4.094..4.097 rows=1 loops=1)\n\nIndex Cond: (payment_id = 42)\n\nStorage Table Read Requests: 1\n\nStorage Table Read Execution Time: 2.840 ms\n\nStorage Index Read Requests: 1\n\nStorage Index Read Execution Time: 1.080 ms\n\n(9 rows)\n\nyugabyte=> explain (analyze, dist, costs off, summary off ) select * from\npayments where payment_id = 42 order by created ; QUERY PLAN\n---------------------------------------------------------- Sort (actual\ntime=4.105..4.105 rows=1 loops=1) Sort Key: created Sort Method: quicksort\nMemory: 25kB -> Index Scan using payments_payment_id_key on payments (actual\ntime=4.094..4.097 rows=1 loops=1) Index Cond: (payment_id = 42) Storage Table\nRead Requests: 1 Storage Table Read Execution Time: 2.840 ms Storage Index\nRead Requests: 1 Storage Index Read Execution Time: 1.080 ms (9 rows)\n\n    \n    \n    yugabyte=> explain (analyze, dist, costs off, summary off ) select * from payments where payment_id = 42 order by created ; QUERY PLAN ---------------------------------------------------------- Sort (actual time=4.105..4.105 rows=1 loops=1) Sort Key: created Sort Method: quicksort Memory: 25kB -> Index Scan using payments_payment_id_key on payments (actual time=4.094..4.097 rows=1 loops=1) Index Cond: (payment_id = 42) Storage Table Read Requests: 1 Storage Table Read Execution Time: 2.840 ms Storage Index Read Requests: 1 Storage Index Read Execution Time: 1.080 ms (9 rows)\n\nSince the index being used is not the primary index, it is necessary to access\nthe table to retrieve values for the other columns, leading to a Table Read\nRequest and an Index Read Request. However, since it is a unique identifier\nqueried by value and sharded by hash, it will read only one row. The\nadditional \u201chop\u201d to the table is limited to one read request per query.\nDespite sounding counter-intuitive, declaring the business key with a unique\nconstraint and using the primary key for another purpose is the right way to\ngo. This is because the business key can be overloaded with a clustering key\nto store together that which is often queried together.\n\nNOTE: Data Modeling Tip In SQL applications, tables often have multiple\ncandidate keys. One is selected as the primary key for physical organization,\nwhile others are declared with unique constraints. In partitioned or sharded\nsystems like Microsoft Citus, Aurora Limitless, or Oracle Globally Distributed\nDatabase, indexes can only be local, and the partitioning or sharding keys\nmust belong to all unique or primary keys. However, distributed SQL databases\nlike YugabyteDB offer global, consistent secondary indexes, so you can match\nindexes to use cases. A recent article by Alex DeBrie details secondary\nindexes in distributed databases: How do distributed databases handle\nsecondary indexes?\n\n## Secondary Indexes for Additional Use Cases\n\nIn the previous blog, I created an index to access by \u201caccount_id\u201d.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\ncreate index payments_by_account on payments(account_id, amount desc)\n\n;\n\nyugabyte=> select num_tablets,\npg_size_pretty(pg_table_size('payments_by_account')) from\nyb_table_properties('payments_by_account'::regclass);\n\nnum_tablets | pg_size_pretty\n\n\\-------------+----------------\n\n9 | 3513 MB\n\n(1 row)\n\ncreate index payments_by_account on payments(account_id, amount desc) ; yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments_by_account')) from yb_table_properties('payments_by_account'::regclass); num_tablets | pg_size_pretty -------------+---------------- 9 | 3513 MB (1 row)\n    \n    \n    create index payments_by_account on payments(account_id, amount desc) ; yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments_by_account')) from yb_table_properties('payments_by_account'::regclass); num_tablets | pg_size_pretty -------------+---------------- 9 | 3513 MB (1 row)\n\nCreating more secondary indexes does introduce overhead during insertions,\ndeletions, or updates of the columns in the index. However, this overhead is\nminimal in YugabyteDB compared to traditional databases. Databases that use\nB-Tree, like Oracle, PostgreSQL, or SQL Server, require multiple reads and\nwrites to insert a new index entry\u2014finding the leaf block from root to\nbranches, updating it, and (when full) splitting it and updating the branches.\nYugabyteDB\u2019s LSM-Tree structure allows fast index entry inserts by appending\nthe new entry directly to the MemTable without having to read previous values.\n\n## #1: Additional bucket number prefix for fast ingest\n\nA key database principle is to store frequently accessed data together to\nminimize I/O and favor cache locality. A single access pattern determines your\nprimary key. If you have multiple access patterns, one is chosen for the\nprimary key, while the others define your secondary indexes, simplifying read\noperations as each index operates independently. However, during write\noperations such as data insertion, all indexes (except for partial ones\ncovering distinct values) are involved. It\u2019s crucial to adopt a strategy that\nprevents any index from becoming a bottleneck during data ingestion.\n\nIn the previous blog, inserts were distributed across tablets because the\nprimary key was on \u201c payment_id\u201d by hash. However, in this blog, starting the\nprimary key with the created date causes all inserts to target the same\ntablet. To achieve distribution and efficient row clustering, a partition key\n(for distribution) and a sort key (to cluster) are necessary. Defining the\nprimary key as (payment_id HASH, created ASC) would be ineffective due to the\nhigh cardinality of the partition key which would undermine the sort key.\nWithout a low cardinality column available, a modulo function can be used to\ncreate one as an additional \u201cbucket#\u201d column\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\ncreate table payments (\n\nprimary key (\"bucket#\" ASC, created ASC, payment_id)\n\n, unique(payment_id)\n\n, \"bucket#\" int default (random()*1e6)::int%8\n\n, payment_id bigint not null generated always as identity (cache 1000)\n\n, created timestamptz not null default now()\n\n, account_id bigint not null\n\n, amount decimal(10,2) not null\n\n) split at values ( (1),(2),(3),(4),(5),(6) )\n\n;\n\ncreate table payments ( primary key (\"bucket#\" ASC, created ASC, payment_id) ,\nunique(payment_id) , \"bucket#\" int default (random()*1e6)::int%8 , payment_id\nbigint not null generated always as identity (cache 1000) , created\ntimestamptz not null default now() , account_id bigint not null , amount\ndecimal(10,2) not null ) split at values ( (1),(2),(3),(4),(5),(6) ) ;\n\n    \n    \n    create table payments ( primary key (\"bucket#\" ASC, created ASC, payment_id) , unique(payment_id) , \"bucket#\" int default (random()*1e6)::int%8 , payment_id bigint not null generated always as identity (cache 1000) , created timestamptz not null default now() , account_id bigint not null , amount decimal(10,2) not null ) split at values ( (1),(2),(3),(4),(5),(6) ) ;\n\nIn this simple demonstration, I\u2019ve set a random \u201cbucket#\u201d between 0 and 7 to\ndistribute inserts across 8 tablets. I could have chosen an existing low\ncardinality column or used a modulo to create one from a high cardinality\ncolumn, utilizing a trigger or a generated column for calculation. If you have\na value that can be used for fast access, you can use it. You can also use\npg_backend_pid() if you want inserts from the same session to go into the same\ntablet. The goal with this technical column is to have the number of distinct\nvalues high enough to distribute the writes but low enough to keep rows\nclustered on the sort key.\n\nI have pre-split the tablets based on the number of distinct values (which\nwill be automatically split further). This process is transparent to the\napplication, allowing me to run the same INSERT and SELECT statements.\n\nYou may wonder how the query on a range of dates behaves now that those dates\ncan come from 8 ranges. With YugabyteDB, as long as the cardinality of the\nprefix is low, the index can still be efficient by doing an Index Skip Scan.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, dist, costs off, summary on)\n\nselect * from payments\n\nwhere created between date '2023-12-25'::timestamptz\n\nand '2024-01-02'::timestamptz\n\norder by created\n\n;\n\nQUERY PLAN\n\n\\----------------------------------------------------------------------------------------\n\nSort (actual time=264.625..270.116 rows=79619 loops=1)\n\nSort Key: created\n\nSort Method: external merge Disk: 3672kB\n\n-> Index Scan using payments_pkey on payments\n\n(actual time=5.348..243.203 rows=79619 loops=1)\n\nIndex Cond: ((created >= ('2023-12-25'::date)::timestamp with time zone) AND\n\n(created <= '2024-01-02 00:00:00+00'::timestamp with time zone))\n\nStorage Table Read Requests: 88\n\nStorage Table Read Execution Time: 192.481 ms\n\nPlanning Time: 0.405 ms\n\nExecution Time: 273.751 ms\n\nStorage Read Requests: 88\n\nStorage Read Execution Time: 192.481 ms\n\nStorage Execution Time: 192.481 ms\n\nPeak Memory Usage: 5339 kB\n\n(17 rows)\n\nyugabyte=> explain (analyze, dist, costs off, summary on) select * from\npayments where created between date '2023-12-25'::timestamptz and\n'2024-01-02'::timestamptz order by created ; QUERY PLAN\n----------------------------------------------------------------------------------------\nSort (actual time=264.625..270.116 rows=79619 loops=1) Sort Key: created Sort\nMethod: external merge Disk: 3672kB -> Index Scan using payments_pkey on\npayments (actual time=5.348..243.203 rows=79619 loops=1) Index Cond: ((created\n>= ('2023-12-25'::date)::timestamp with time zone) AND (created <= '2024-01-02\n00:00:00+00'::timestamp with time zone)) Storage Table Read Requests: 88\nStorage Table Read Execution Time: 192.481 ms Planning Time: 0.405 ms\nExecution Time: 273.751 ms Storage Read Requests: 88 Storage Read Execution\nTime: 192.481 ms Storage Execution Time: 192.481 ms Peak Memory Usage: 5339 kB\n(17 rows)\n\n    \n    \n    yugabyte=> explain (analyze, dist, costs off, summary on) select * from payments where created between date '2023-12-25'::timestamptz and '2024-01-02'::timestamptz order by created ; QUERY PLAN ---------------------------------------------------------------------------------------- Sort (actual time=264.625..270.116 rows=79619 loops=1) Sort Key: created Sort Method: external merge Disk: 3672kB -> Index Scan using payments_pkey on payments (actual time=5.348..243.203 rows=79619 loops=1) Index Cond: ((created >= ('2023-12-25'::date)::timestamp with time zone) AND (created <= '2024-01-02 00:00:00+00'::timestamp with time zone)) Storage Table Read Requests: 88 Storage Table Read Execution Time: 192.481 ms Planning Time: 0.405 ms Execution Time: 273.751 ms Storage Read Requests: 88 Storage Read Execution Time: 192.481 ms Storage Execution Time: 192.481 ms Peak Memory Usage: 5339 kB (17 rows)\n\nThe addition of the \u201cbucket#\u201d incurs only a 20-millisecond increase. This is\nprimarily due to sorting and merging ranges for ORDER BY rather than the Index\nScan itself, which just had to skip to eight ranges instead of one.\n\nAdding a bucket number proves to be a simpler and more scalable solution than\ndeclarative partitioning.\n\n## #2: Partition by date for lifecycle management\n\nGrouping date ranges facilitates quick data purging by allowing old partitions\nto be dropped, such as one partition per year using PostgreSQL\u2019s range\npartitioning. However, this limits indexing possibilities. For example, unique\nconstraints cannot be enforced on multiple fields. Before considering\noptimization, assess if the automatic sharding already meets performance\nneeds. A query on a range of dates is fast, which is crucial for purging jobs.\nThese jobs insert tombstones for row deletion in the LSM-Tree, with space\nbeing freed only after compaction. Compaction is conducted per tablet, and\nsplitting is done according to date, so any deletions and compactions will\nimpact specific tablets only. That\u2019s the advantage of auto-splitting: keep\neach LSM-Tree within a manageable size.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from\nyb_table_properties('payments'::regclass);\n\nnum_tablets | pg_size_pretty\n\n\\-------------+----------------\n\n16 | 6887 MB\n\n(1 row)\n\nyugabyte=> explain (analyze, dist, costs off, summary on)\n\ndelete from payments\n\nwhere created < date '2002-01-01'::timestamptz\n\n;\n\nQUERY PLAN\n\n\\-----------------------------------------------------------------------------------------\n\nDelete on payments (actual time=325267.951..325267.951 rows=0 loops=1)\n\n-> Index Scan using payments_pkey on payments\n\n(actual time=9.294..291988.065 rows=8243282 loops=1)\n\nIndex Cond: (created < ('2002-01-01'::date)::timestamp with time zone)\n\nStorage Table Read Requests: 8061\n\nStorage Table Read Execution Time: 681.241 ms\n\nStorage Table Write Requests: 8243282\n\nStorage Index Write Requests: 8243282\n\nStorage Flush Requests: 8053\n\nStorage Flush Execution Time: 278034.167 ms\n\nPlanning Time: 9.552 ms\n\nExecution Time: 325303.007 ms\n\nStorage Read Requests: 8061\n\nStorage Read Execution Time: 681.241 ms\n\nStorage Write Requests: 16486564\n\nCatalog Read Requests: 19\n\nCatalog Read Execution Time: 15.104 ms\n\nCatalog Write Requests: 0\n\nStorage Flush Requests: 8054\n\nStorage Flush Execution Time: 278068.526 ms\n\nStorage Execution Time: 278764.870 ms\n\nPeak Memory Usage: 173 kB\n\n(21 rows)\n\nyugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from\nyb_table_properties('payments'::regclass);\n\nnum_tablets | pg_size_pretty\n\n\\-------------+----------------\n\n16 | 6632 MB\n\n(1 row)\n\nyugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from yb_table_properties('payments'::regclass); num_tablets | pg_size_pretty -------------+---------------- 16 | 6887 MB (1 row) yugabyte=> explain (analyze, dist, costs off, summary on) delete from payments where created < date '2002-01-01'::timestamptz ; QUERY PLAN ----------------------------------------------------------------------------------------- Delete on payments (actual time=325267.951..325267.951 rows=0 loops=1) -> Index Scan using payments_pkey on payments (actual time=9.294..291988.065 rows=8243282 loops=1) Index Cond: (created < ('2002-01-01'::date)::timestamp with time zone) Storage Table Read Requests: 8061 Storage Table Read Execution Time: 681.241 ms Storage Table Write Requests: 8243282 Storage Index Write Requests: 8243282 Storage Flush Requests: 8053 Storage Flush Execution Time: 278034.167 ms Planning Time: 9.552 ms Execution Time: 325303.007 ms Storage Read Requests: 8061 Storage Read Execution Time: 681.241 ms Storage Write Requests: 16486564 Catalog Read Requests: 19 Catalog Read Execution Time: 15.104 ms Catalog Write Requests: 0 Storage Flush Requests: 8054 Storage Flush Execution Time: 278068.526 ms Storage Execution Time: 278764.870 ms Peak Memory Usage: 173 kB (21 rows) yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from yb_table_properties('payments'::regclass); num_tablets | pg_size_pretty -------------+---------------- 16 | 6632 MB (1 row)\n    \n    \n    yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from yb_table_properties('payments'::regclass); num_tablets | pg_size_pretty -------------+---------------- 16 | 6887 MB (1 row) yugabyte=> explain (analyze, dist, costs off, summary on) delete from payments where created < date '2002-01-01'::timestamptz ; QUERY PLAN ----------------------------------------------------------------------------------------- Delete on payments (actual time=325267.951..325267.951 rows=0 loops=1) -> Index Scan using payments_pkey on payments (actual time=9.294..291988.065 rows=8243282 loops=1) Index Cond: (created < ('2002-01-01'::date)::timestamp with time zone) Storage Table Read Requests: 8061 Storage Table Read Execution Time: 681.241 ms Storage Table Write Requests: 8243282 Storage Index Write Requests: 8243282 Storage Flush Requests: 8053 Storage Flush Execution Time: 278034.167 ms Planning Time: 9.552 ms Execution Time: 325303.007 ms Storage Read Requests: 8061 Storage Read Execution Time: 681.241 ms Storage Write Requests: 16486564 Catalog Read Requests: 19 Catalog Read Execution Time: 15.104 ms Catalog Write Requests: 0 Storage Flush Requests: 8054 Storage Flush Execution Time: 278068.526 ms Storage Execution Time: 278764.870 ms Peak Memory Usage: 173 kB (21 rows) yugabyte=> select num_tablets, pg_size_pretty(pg_table_size('payments')) from yb_table_properties('payments'::regclass); num_tablets | pg_size_pretty -------------+---------------- 16 | 6632 MB (1 row)\n\nThis delete is slow due to the fact that it updates the indexes with strong\nconsistency. The write requests are buffered and flushed by batches, which can\nrun in the background. Note that this solution is effective when deletions are\ndone daily for small amounts of data. . When purging a large percentage, the\nwhole tablet may become empty and remain unused because new rows go to higher\nranges. The empty tablets are not merged in the current version of YugabyteDB\n(see enhancement request #21816). For such scenarios, I would use declarative\npartitioning on top of it.\n\n## PostgreSQL Declarative Partitioning on Top of Sharding\n\nYugabyteDB\u2019s automatic sharding effectively distributes data without\nrestricting SQL capabilities, operating transparently and automatically.\nHowever, PostgreSQL\u2019s declarative partitioning can still be utilized, with\nsharding then applied to each partition. As the partitions are sharded and\ndistributed, their size can expand without scalability issues, helping to keep\nthe number of declarative partitions to a minimum.\n\nFor example, you can drop an old partition to eliminate the empty tablets when\nthere are too many, but you don\u2019t need to do that every year. In my example, I\ncan define three partitions, each covering a 10-year range. After 10 years,\nthe empty tablets left by the regular purge can be removed.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\ncreate table payments (\n\nprimary key (\"bucket#\" ASC, created ASC, payment_id)\n\n\\-- no global unique constraints -- , unique(payment_id)\n\n, \"bucket#\" int default (random()*1e6)::int%8\n\n, payment_id bigint not null generated always as identity (cache 1000)\n\n, created timestamptz not null default now()\n\n, account_id bigint not null\n\n, amount decimal(10,2) not null\n\n) partition by range ( created );\n\n;\n\ncreate table payments1 partition of payments\n\nfor values from ( minvalue ) to ('2009-12-31 23:59:59') ;\n\ncreate table payments2 partition of payments\n\nfor values from ('2010-01-01 00:00:00') to ('2019-12-31 23:59:59') ;\n\ncreate table payments3 partition of payments\n\nfor values from ('2020-01-01 00:00:00') to ('2029-12-31 23:59:59') ;\n\ncreate index payments_by_account on payments(account_id, amount desc);\n\nalter table payments1 add unique(payment_id);\n\nalter table payments2 add unique(payment_id);\n\nalter table payments3 add unique(payment_id);\n\ncreate table payments ( primary key (\"bucket#\" ASC, created ASC, payment_id)\n-- no global unique constraints -- , unique(payment_id) , \"bucket#\" int\ndefault (random()*1e6)::int%8 , payment_id bigint not null generated always as\nidentity (cache 1000) , created timestamptz not null default now() ,\naccount_id bigint not null , amount decimal(10,2) not null ) partition by\nrange ( created ); ; create table payments1 partition of payments for values\nfrom ( minvalue ) to ('2009-12-31 23:59:59') ; create table payments2\npartition of payments for values from ('2010-01-01 00:00:00') to ('2019-12-31\n23:59:59') ; create table payments3 partition of payments for values from\n('2020-01-01 00:00:00') to ('2029-12-31 23:59:59') ; create index\npayments_by_account on payments(account_id, amount desc); alter table\npayments1 add unique(payment_id); alter table payments2 add\nunique(payment_id); alter table payments3 add unique(payment_id);\n\n    \n    \n    create table payments ( primary key (\"bucket#\" ASC, created ASC, payment_id) -- no global unique constraints -- , unique(payment_id) , \"bucket#\" int default (random()*1e6)::int%8 , payment_id bigint not null generated always as identity (cache 1000) , created timestamptz not null default now() , account_id bigint not null , amount decimal(10,2) not null ) partition by range ( created ); ; create table payments1 partition of payments for values from ( minvalue ) to ('2009-12-31 23:59:59') ; create table payments2 partition of payments for values from ('2010-01-01 00:00:00') to ('2019-12-31 23:59:59') ; create table payments3 partition of payments for values from ('2020-01-01 00:00:00') to ('2029-12-31 23:59:59') ; create index payments_by_account on payments(account_id, amount desc); alter table payments1 add unique(payment_id); alter table payments2 add unique(payment_id); alter table payments3 add unique(payment_id);\n\nThere are two drawbacks stemming from PostgreSQL limitations with\npartitioning:\n\n  1. I cannot enforce the unique constraint across all partitions, although if a sequence generates it, this may be acceptable.\n  2. I can create only local indexes, so a query that doesn\u2019t contain the partition key (\u201ccreated\u201d) will have to read three indexes instead of one.\n\nDespite these limitations, performance remains acceptable with a minimal\nnumber of partitions. Running the same INSERT operation on a hundred million\nrows resulted in each partition being automatically split.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> select relname, pg_size_pretty(pg_table_size(inhrelid)),\nyb_get_range_split_clause(inhrelid)from pg_inherits natural join (select oid\ninhrelid, relname from pg_class) c where inhparent='payments'::regclass\n\n;\n\n-[ RECORD 1 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nrelname | payments1\n\npg_size_pretty | 2164 MB\n\nyb_get_range_split_clause | SPLIT AT VALUES ((1, '2002-06-01 19:24:31.9392+00', 46334341), (2, '2001-07-24 13:05:25.4976+00', 15121966), (4, '2000-08-11 21:09:32.7456+00', 20511537), (5, '2002-05-19 02:58:03.792+00', 48456133), (6, '2002-03-05 13:53:41.4528+00', 16138115))\n\n-[ RECORD 2 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nrelname | payments2\n\npg_size_pretty | 2335 MB\n\nyb_get_range_split_clause | SPLIT AT VALUES ((1, '2011-03-10 00:51:12.816+00', 59318232), (2, '2011-11-02 03:59:35.0592+00', 23581409), (4, '2010-07-30 00:37:46.3584+00', 20570203), (6, '2010-05-29 05:34:44.4576+00', 16023322))\n\n-[ RECORD 3 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nrelname | payments3\n\npg_size_pretty | 1094 MB\n\nyb_get_range_split_clause | SPLIT AT VALUES ((4, '2020-01-26 16:18:24.2208+00', 19416037))\n\nyugabyte=> select relname, pg_size_pretty(pg_table_size(inhrelid)), yb_get_range_split_clause(inhrelid)from pg_inherits natural join (select oid inhrelid, relname from pg_class) c where inhparent='payments'::regclass ; -[ RECORD 1 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ relname | payments1 pg_size_pretty | 2164 MB yb_get_range_split_clause | SPLIT AT VALUES ((1, '2002-06-01 19:24:31.9392+00', 46334341), (2, '2001-07-24 13:05:25.4976+00', 15121966), (4, '2000-08-11 21:09:32.7456+00', 20511537), (5, '2002-05-19 02:58:03.792+00', 48456133), (6, '2002-03-05 13:53:41.4528+00', 16138115)) -[ RECORD 2 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ relname | payments2 pg_size_pretty | 2335 MB yb_get_range_split_clause | SPLIT AT VALUES ((1, '2011-03-10 00:51:12.816+00', 59318232), (2, '2011-11-02 03:59:35.0592+00', 23581409), (4, '2010-07-30 00:37:46.3584+00', 20570203), (6, '2010-05-29 05:34:44.4576+00', 16023322)) -[ RECORD 3 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ relname | payments3 pg_size_pretty | 1094 MB yb_get_range_split_clause | SPLIT AT VALUES ((4, '2020-01-26 16:18:24.2208+00', 19416037))\n    \n    \n    yugabyte=> select relname, pg_size_pretty(pg_table_size(inhrelid)), yb_get_range_split_clause(inhrelid)from pg_inherits natural join (select oid inhrelid, relname from pg_class) c where inhparent='payments'::regclass ; -[ RECORD 1 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ relname | payments1 pg_size_pretty | 2164 MB yb_get_range_split_clause | SPLIT AT VALUES ((1, '2002-06-01 19:24:31.9392+00', 46334341), (2, '2001-07-24 13:05:25.4976+00', 15121966), (4, '2000-08-11 21:09:32.7456+00', 20511537), (5, '2002-05-19 02:58:03.792+00', 48456133), (6, '2002-03-05 13:53:41.4528+00', 16138115)) -[ RECORD 2 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ relname | payments2 pg_size_pretty | 2335 MB yb_get_range_split_clause | SPLIT AT VALUES ((1, '2011-03-10 00:51:12.816+00', 59318232), (2, '2011-11-02 03:59:35.0592+00', 23581409), (4, '2010-07-30 00:37:46.3584+00', 20570203), (6, '2010-05-29 05:34:44.4576+00', 16023322)) -[ RECORD 3 ]-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ relname | payments3 pg_size_pretty | 1094 MB yb_get_range_split_clause | SPLIT AT VALUES ((4, '2020-01-26 16:18:24.2208+00', 19416037))\n\nWith queries on a range of dates, partition pruning occurs so the performance\nis the same as without declarative partitioning.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, dist, costs off, summary off)\n\nselect * from payments\n\nwhere created between date '2023-12-25'::timestamptz\n\nand '2024-01-02'::timestamptz\n\norder by created\n\n;\n\nQUERY PLAN\n\n\\-----------------------------------------------------------------------------------------\n\nSort (actual time=242.162..247.673 rows=80237 loops=1)\n\nSort Key: payments3.created\n\nSort Method: external merge Disk: 3696kB\n\n-> Append (actual time=3.492..221.666 rows=80237 loops=1)\n\nSubplans Removed: 2\n\n-> Index Scan using payments3_pkey on payments3\n\n(actual time=3.491..215.714 rows=80237 loops=1)\n\nIndex Cond: ((created >= ('2023-12-25'::date)::timestamp with time zone) AND\n\n(created <= '2024-01-02 00:00:00+00'::timestamp with time zone))\n\nStorage Table Read Requests: 80\n\nStorage Table Read Execution Time: 169.034 ms\n\nyugabyte=> explain (analyze, dist, costs off, summary off) select * from\npayments where created between date '2023-12-25'::timestamptz and\n'2024-01-02'::timestamptz order by created ; QUERY PLAN\n-----------------------------------------------------------------------------------------\nSort (actual time=242.162..247.673 rows=80237 loops=1) Sort Key:\npayments3.created Sort Method: external merge Disk: 3696kB -> Append (actual\ntime=3.492..221.666 rows=80237 loops=1) Subplans Removed: 2 -> Index Scan\nusing payments3_pkey on payments3 (actual time=3.491..215.714 rows=80237\nloops=1) Index Cond: ((created >= ('2023-12-25'::date)::timestamp with time\nzone) AND (created <= '2024-01-02 00:00:00+00'::timestamp with time zone))\nStorage Table Read Requests: 80 Storage Table Read Execution Time: 169.034 ms\n\n    \n    \n    yugabyte=> explain (analyze, dist, costs off, summary off) select * from payments where created between date '2023-12-25'::timestamptz and '2024-01-02'::timestamptz order by created ; QUERY PLAN ----------------------------------------------------------------------------------------- Sort (actual time=242.162..247.673 rows=80237 loops=1) Sort Key: payments3.created Sort Method: external merge Disk: 3696kB -> Append (actual time=3.492..221.666 rows=80237 loops=1) Subplans Removed: 2 -> Index Scan using payments3_pkey on payments3 (actual time=3.491..215.714 rows=80237 loops=1) Index Cond: ((created >= ('2023-12-25'::date)::timestamp with time zone) AND (created <= '2024-01-02 00:00:00+00'::timestamp with time zone)) Storage Table Read Requests: 80 Storage Table Read Execution Time: 169.034 ms\n\nWith point queries on the business key, declared as unique on each partition,\nthere are three indexes to read. But that is still fast.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, dist, costs off, summary off )\n\nselect * from payments\n\nwhere payment_id = 42\n\norder by created\n\n;\n\nQUERY PLAN\n\n\\-----------------------------------------------------------------------------------------\n\nSort (actual time=5.643..5.644 rows=1 loops=1)\n\nSort Key: payments1.created\n\nSort Method: quicksort Memory: 25kB\n\n-> Append (actual time=5.632..5.634 rows=1 loops=1)\n\n-> Index Scan using payments1_payment_id_key on payments1\n\n(actual time=1.427..1.427 rows=0 loops=1)\n\nIndex Cond: (payment_id = 42)\n\nStorage Index Read Requests: 1\n\nStorage Index Read Execution Time: 1.321 ms\n\n-> Index Scan using payments2_payment_id_key on payments2\n\n(actual time=0.955..0.955 rows=0 loops=1)\n\nIndex Cond: (payment_id = 42)\n\nStorage Index Read Requests: 1\n\nStorage Index Read Execution Time: 0.887 ms\n\n-> Index Scan using payments3_payment_id_key on payments3\n\n(actual time=3.248..3.250 rows=1 loops=1)\n\nIndex Cond: (payment_id = 42)\n\nStorage Table Read Requests: 1\n\nStorage Table Read Execution Time: 1.646 ms\n\nStorage Index Read Requests: 1\n\nStorage Index Read Execution Time: 1.500 ms\n\nyugabyte=> explain (analyze, dist, costs off, summary off ) select * from\npayments where payment_id = 42 order by created ; QUERY PLAN\n-----------------------------------------------------------------------------------------\nSort (actual time=5.643..5.644 rows=1 loops=1) Sort Key: payments1.created\nSort Method: quicksort Memory: 25kB -> Append (actual time=5.632..5.634 rows=1\nloops=1) -> Index Scan using payments1_payment_id_key on payments1 (actual\ntime=1.427..1.427 rows=0 loops=1) Index Cond: (payment_id = 42) Storage Index\nRead Requests: 1 Storage Index Read Execution Time: 1.321 ms -> Index Scan\nusing payments2_payment_id_key on payments2 (actual time=0.955..0.955 rows=0\nloops=1) Index Cond: (payment_id = 42) Storage Index Read Requests: 1 Storage\nIndex Read Execution Time: 0.887 ms -> Index Scan using\npayments3_payment_id_key on payments3 (actual time=3.248..3.250 rows=1\nloops=1) Index Cond: (payment_id = 42) Storage Table Read Requests: 1 Storage\nTable Read Execution Time: 1.646 ms Storage Index Read Requests: 1 Storage\nIndex Read Execution Time: 1.500 ms\n\n    \n    \n    yugabyte=> explain (analyze, dist, costs off, summary off ) select * from payments where payment_id = 42 order by created ; QUERY PLAN ----------------------------------------------------------------------------------------- Sort (actual time=5.643..5.644 rows=1 loops=1) Sort Key: payments1.created Sort Method: quicksort Memory: 25kB -> Append (actual time=5.632..5.634 rows=1 loops=1) -> Index Scan using payments1_payment_id_key on payments1 (actual time=1.427..1.427 rows=0 loops=1) Index Cond: (payment_id = 42) Storage Index Read Requests: 1 Storage Index Read Execution Time: 1.321 ms -> Index Scan using payments2_payment_id_key on payments2 (actual time=0.955..0.955 rows=0 loops=1) Index Cond: (payment_id = 42) Storage Index Read Requests: 1 Storage Index Read Execution Time: 0.887 ms -> Index Scan using payments3_payment_id_key on payments3 (actual time=3.248..3.250 rows=1 loops=1) Index Cond: (payment_id = 42) Storage Table Read Requests: 1 Storage Table Read Execution Time: 1.646 ms Storage Index Read Requests: 1 Storage Index Read Execution Time: 1.500 ms\n\nWhen querying an indexed column without specifying partition keys, response\ntime increases by the number of partitions. However, with only three\npartitions, the impact on performance is still acceptable.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, buffers, costs off)\n\nselect * from payments\n\nwhere account_id = 42 and amount < 0.01\n\n;\n\nQUERY PLAN\n\n\\-----------------------------------------------------------------------------------------\n\nAppend (actual time=8.215..23.361 rows=494 loops=1)\n\n-> Index Scan using payments1_account_id_amount_idx on payments1\n\n(actual time=8.214..8.314 rows=192 loops=1)\n\nIndex Cond: ((account_id = 42) AND (amount < 0.01))\n\n-> Index Scan using payments2_account_id_amount_idx on payments2\n\n(actual time=9.812..9.928 rows=220 loops=1)\n\nIndex Cond: ((account_id = 42) AND (amount < 0.01))\n\n-> Index Scan using payments3_account_id_amount_idx on payments3\n\n(actual time=5.027..5.066 rows=82 loops=1)\n\nIndex Cond: ((account_id = 42) AND (amount < 0.01))\n\nPlanning Time: 9.587 ms\n\nExecution Time: 23.546 ms\n\nPeak Memory Usage: 56 kB\n\n(10 rows)\n\nyugabyte=> explain (analyze, buffers, costs off) select * from payments where\naccount_id = 42 and amount < 0.01 ; QUERY PLAN\n-----------------------------------------------------------------------------------------\nAppend (actual time=8.215..23.361 rows=494 loops=1) -> Index Scan using\npayments1_account_id_amount_idx on payments1 (actual time=8.214..8.314\nrows=192 loops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) -> Index\nScan using payments2_account_id_amount_idx on payments2 (actual\ntime=9.812..9.928 rows=220 loops=1) Index Cond: ((account_id = 42) AND (amount\n< 0.01)) -> Index Scan using payments3_account_id_amount_idx on payments3\n(actual time=5.027..5.066 rows=82 loops=1) Index Cond: ((account_id = 42) AND\n(amount < 0.01)) Planning Time: 9.587 ms Execution Time: 23.546 ms Peak Memory\nUsage: 56 kB (10 rows)\n\n    \n    \n    yugabyte=> explain (analyze, buffers, costs off) select * from payments where account_id = 42 and amount < 0.01 ; QUERY PLAN ----------------------------------------------------------------------------------------- Append (actual time=8.215..23.361 rows=494 loops=1) -> Index Scan using payments1_account_id_amount_idx on payments1 (actual time=8.214..8.314 rows=192 loops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) -> Index Scan using payments2_account_id_amount_idx on payments2 (actual time=9.812..9.928 rows=220 loops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) -> Index Scan using payments3_account_id_amount_idx on payments3 (actual time=5.027..5.066 rows=82 loops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) Planning Time: 9.587 ms Execution Time: 23.546 ms Peak Memory Usage: 56 kB (10 rows)\n\nIn practice, since partitions are created for operational reasons, you can\nhide them and provide users a view that shows only the time window they are\nallowed to query, such as the last five years.\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> create view visible_payments as\n\nselect * from payments\n\nwhere created between now() - interval '5 years' and now()\n\n;\n\nyugabyte=> create view visible_payments as select * from payments where\ncreated between now() - interval '5 years' and now() ;\n\n    \n    \n    yugabyte=> create view visible_payments as select * from payments where created between now() - interval '5 years' and now() ;\n\nNow, the additional partitions created for the future do not have to be read,\nand the query is faster:\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nyugabyte=> explain (analyze, buffers, costs off)\n\nselect * from visible_payments\n\nwhere account_id = 42 and amount < 0.01\n\n;\n\nQUERY PLAN\n\n\\-----------------------------------------------------------------------------------------\n\nAppend (actual time=5.063..8.702 rows=105 loops=1)\n\nSubplans Removed: 1\n\n-> Index Scan using payments2_account_id_amount_idx on payments2\n\n(actual time=5.063..5.168 rows=23 loops=1)\n\nIndex Cond: ((account_id = 42) AND (amount < 0.01))\n\nFilter: ((created <= now()) AND (created >= (now() - '5 years'::interval)))\n\nRows Removed by Filter: 197\n\n-> Index Scan using payments3_account_id_amount_idx on payments3\n\n(actual time=3.471..3.523 rows=82 loops=1)\n\nIndex Cond: ((account_id = 42) AND (amount < 0.01))\n\nFilter: ((created <= now()) AND (created >= (now() - '5 years'::interval)))\n\nPlanning Time: 0.181 ms\n\nExecution Time: 8.771 ms\n\nPeak Memory Usage: 56 kB\n\n(12 rows)\n\nyugabyte=> explain (analyze, buffers, costs off) select * from\nvisible_payments where account_id = 42 and amount < 0.01 ; QUERY PLAN\n-----------------------------------------------------------------------------------------\nAppend (actual time=5.063..8.702 rows=105 loops=1) Subplans Removed: 1 ->\nIndex Scan using payments2_account_id_amount_idx on payments2 (actual\ntime=5.063..5.168 rows=23 loops=1) Index Cond: ((account_id = 42) AND (amount\n< 0.01)) Filter: ((created <= now()) AND (created >= (now() - '5\nyears'::interval))) Rows Removed by Filter: 197 -> Index Scan using\npayments3_account_id_amount_idx on payments3 (actual time=3.471..3.523 rows=82\nloops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) Filter: ((created\n<= now()) AND (created >= (now() - '5 years'::interval))) Planning Time: 0.181\nms Execution Time: 8.771 ms Peak Memory Usage: 56 kB (12 rows)\n\n    \n    \n    yugabyte=> explain (analyze, buffers, costs off) select * from visible_payments where account_id = 42 and amount < 0.01 ; QUERY PLAN ----------------------------------------------------------------------------------------- Append (actual time=5.063..8.702 rows=105 loops=1) Subplans Removed: 1 -> Index Scan using payments2_account_id_amount_idx on payments2 (actual time=5.063..5.168 rows=23 loops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) Filter: ((created <= now()) AND (created >= (now() - '5 years'::interval))) Rows Removed by Filter: 197 -> Index Scan using payments3_account_id_amount_idx on payments3 (actual time=3.471..3.523 rows=82 loops=1) Index Cond: ((account_id = 42) AND (amount < 0.01)) Filter: ((created <= now()) AND (created >= (now() - '5 years'::interval))) Planning Time: 0.181 ms Execution Time: 8.771 ms Peak Memory Usage: 56 kB (12 rows)\n\nIt is a great strategy to create more partitions for the future to prevent\nthem from being missing later, while ensuring that the application accesses\nonly necessary partitions.\n\nYou may not need to do this when partitioning by date. Still, there are other\nreasons to use declarative partitioning in YugabyteDB, such as geo-\ndistribution, where each partition is assigned to a specific tablespace, maybe\nby list of \u201caccount_id\u201d to isolate some of them, or on a country code. The\nrule remains the same: limit the number of declarative partitions to whatever\nthe minimum is for lifecycle management or data placement, leveraging\nYugabyteDB\u2019s automatic sharding for scalability within each of those\npartitions.\n\n## In Conclusion: Automatic Interval Partitioning With Global Indexes\n\nAutomatic sharding facilitates a wide range of scaling and distribution\npossibilities in YugabyteDB\u2019s distributed storage. By defining primary keys\nand secondary indexes that serve your access patterns, the sharding key can\ndiffer for the table and the indexes. The result? You can optimize one schema\nfor various use cases. The keys can contain a partition key\u2014 to distribute\u2014\nand a sort key \u2014for clustering. You may also add a technical key to control\nthe cardinality, so you can balance between the distribution of inserts to\nincrease the write throughput and the clustering of rows or index entries to\nincrease the read response time.\n\nIn addition, you can use declarative partitioning to place some partitions in\nspecific locations for geo-distribution, and having only local indexes at that\nlevel makes sense. Because each partition benefits from YugabyteDB distributed\nstorage scalability, there\u2019s no need to create a large number of partitions,\navoiding the limitations that PostgreSQL encounters with hundreds of\npartitions.\n\nApril 16, 2024\n\nData ShardingDistributed PostgreSQLPartitioningPostgreSQL\nCompatibilitySecondary Indexes\n\nFranck Pachot\n\nApril 16, 2024\n\n#### Related Posts\n\n### Gain Lightning Fast Reads and Writes Without Changing Your PostgreSQL\nApplication\n\n2 weeks ago\n\n### Logistics Giant Optimizes for Low Latency and Resiliency At Scale\n\n2 weeks ago\n\n### Solving PostgreSQL Indexes, Partitioning, and LockManager Limitations\n\n3 weeks ago\n\nGet your free report to discover YugabyteDB and the latest in cloud database\ntechnology.\n\nGet Report\n\n## Popular Topics\n\n### PostgreSQL Compatibility\n\n### Database Migration\n\n### Database Sharding\n\n### Geo-Distribution\n\n### Customer Stories\n\n### Change Data Capture\n\n## Categories\n\nACID TransactionsAmazon AuroraAmazon DynamoDBAmazon Web ServicesApache\nCassandraCareersCloud ProvidersCockroachDBCommunity NewsCompany NewsCompare\nand contrastContainersCustomersDatabase ArchitectureDatabase\nMigrationDatabasesDistributed SQLDistributed SQL SummitDockerEcosystem\nIntegrationsGeo-DistributionGoogle Cloud PlatformGoogle SpannerGraphQLHow It\nWorksHow ToIntegrationsJepsen TestsKafkaKubernetesMicrosoft AzureMicrosoft\nAzure Cosmos DBMongoDBOn-PremisesOpen SourcePartnersPerformance\nBenchmarksPivotal Container Service (PKS)PostgreSQLRelease\nAnnouncementsRetailSecuritySpringStreaming IndustryUse CasesWeek in\nReviewYugabyteDBYugabyteDB AnywhereYugabyteDB ManagedYugabyteDB\nTrainingYugabyteDB Voyager\n\n## Explore Distributed SQL and YugabyteDB in Depth\n\nDiscover the future of data management.\n\nLearn at Yugabyte University\n\nGet Started\n\nBrowse Yugabyte Docs\n\nExplore docs\n\nPostgreSQL For Cloud Native World\n\nRead for Free\n\n  *     * Product\n\n      * YugabyteDB\n      * YugabyteDB Voyager\n      * Deployment Options\n      * Pricing\n    * Company\n\n      * About Yugabyte\n      * Press\n      * Careers\n      * Trust Center\n      * Contact\n      * Legal\n  *     * Solutions\n\n      * BY USE CASE\n\n        * Database Modernization\n        * Cloud Native Apps\n        * Edge and Streaming Apps\n      * BY INDUSTRY\n\n        * Financial Services\n        * Retail and eCommerce\n        * Telecommunications\n      * BY CLOUD\n\n        * AWS\n        * Google Cloud\n        * Microsoft Azure\n  *     * Community\n\n      * Get Involved\n      * Events\n      * YugabyteDB Friday Tech Talks\n      * Distributed SQL Summit\n      * Slack\n      * GitHub\n    * Resources\n\n      * Developer Hub\n      * Docs\n      * Yugabyte University\n      * Key Concepts\n      * Support\n      * Forum\n      * Success Stories\n      * Blog\n      * Content Library\n      * FAQ\n\n\u00a9 2024 YUGABYTE, INC. All rights reserved.\n\nTerms of Service Privacy Policy Cookie Policy Your California Privacy Choices\n\n", "frontpage": false}
