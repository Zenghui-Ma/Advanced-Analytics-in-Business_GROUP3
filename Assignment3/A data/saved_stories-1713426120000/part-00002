{"aid": "40069298", "title": "Cyc: History's Forgotten AI Project", "url": "https://outsiderart.substack.com/p/cyc-historys-forgotten-ai-project", "domain": "outsiderart.substack.com", "votes": 7, "user": "iafisher", "posted_at": "2024-04-17 19:46:46", "comments": 0, "source_title": "Cyc: history's forgotten AI project", "source_text": "Cyc: history's forgotten AI project - by I. A. Fisher\n\n# Outsider Art\n\nShare this post\n\n#### Cyc: history's forgotten AI project\n\noutsiderart.substack.com\n\n# Cyc: history's forgotten AI project\n\n### Since 1984 a secretive AI project has been building a massive knowledge\nbase to enable human-like reasoning. Will it work?\n\nI. A. Fisher\n\nApr 17, 2024\n\nShare this post\n\n#### Cyc: history's forgotten AI project\n\noutsiderart.substack.com\n\nShare\n\n> The Cyc group at MCC is attempting to build a single intelligent agent whose\n> knowledge base contains [...] tens of millions of entries. We believe such a\n> system will be a useful, perhaps necessary, platform on which to undertake\n> the next generation of work in expert systems, natural language\n> understanding, and machine learning.1\n\nSix miles north of downtown Austin, Texas, in an unassuming office park just\noff the Mopac Expressway, stands the headquarters of Cyc, one of the most\nambitious artificial intelligence projects in history \u2013 a four decade-long\neffort to codify the common-sense knowledge that is the foundation of human\nreasoning. Its researchers have produced a corpus of 1.5 million concepts and\n25 million rules that feed an inference engine with more than a thousand\nspecialized submodules. The system can use both common-sense knowledge and\ndeep domain expertise to make deductions from chains of reasonings that are\nthousands of steps long. Its users range from an Ohio research hospital to the\nNational Security Agency.\n\nYet despite its impressive achievements, Cyc has been largely forgotten, left\nbehind by a new generation of machine-learning algorithms that power the\nchatbots and self-driving cars of today. How did one of the grandest\nexperiments in AI end up as a historical footnote?\n\n##\n\nPrecursors\n\nIn 1983, a group of AI researchers met at Stanford to discuss a vexing issue\nin AI research: how to program machines with common sense.\n\nThe organizer of the meeting, Stanford professor Doug Lenat, had been thinking\nabout the problem for some time. In the 1970s, he had made a name for himself\nwith a series of programs that exhibited striking flashes of intelligence. The\nfirst, AM (short for 'Automated Mathematician'), was pre-programmed with some\nelementary mathematics and told to search for 'interesting' theorems. It found\nhundreds, many mundane but some of them remarkably creative; one discovery\nmirrored work done by the mathematical prodigy Srinivasa Ramanujan.\n\nAM's biggest shortcoming was the fact that its heuristics were hard-coded \u2013\nmeaning that it couldn't change tactics once it ran out of ideas. In Lenat's\nnext program, EURISKO, the heuristics themselves could be evaluated and\nmodified by the program. Lenat used EURISKO to compete against human opponents\nat a complicated table-top board game called Traveller Trillion Credit\nSquadron. Guided by Lenat, the system suggested a highly unorthodox strategy\nthat seemed unlikely to work. But the unconventional strategy paid off, and\nLenat\u2013EURISKO won the tournament.2\n\nStill, EURISKO eventually slowed down, too. Lenat wagered that a machine that\ncould draw on a large body of general knowledge \u2013 what humans call 'common\nsense' \u2013 when it got stuck would have a better chance of achieving genuine\nintelligence than clever but simple-minded programs like AM and EURISKO.\n\nAt the time, the cutting edge in artificial intelligence was so-called 'expert\nsystems'. Unlike traditional programs that proceeded mechanically along a\nhard-coded path (like a glorified flowchart), expert systems made inferences\nand deductions from a set of facts and rules written by domain experts in\nfields like medical diagnosis and organic chemistry. They were (in theory)\ncapable of performing a rudimentary kind of reasoning and dealing more\nflexibly with complex situations.\n\nHowever, each expert system had its own database of rules, which meant both\nwasteful duplication and the inability of different expert systems to talk to\none another. Lenat saw that a shared bank of common-sense knowledge could be\nthe foundation for a new generation of even more effective systems.\n\nAt the Stanford meeting, Lenat and the other researchers calculated that a\nmachine would need to know several million rules before it reached the\n'crossover point' when it could begin to learn on its own. Assembling such a\nknowledge base would take 2,000 person-years of effort \u2013 not unthinkable, but\nbeyond the resources of a busy professor and a few grad students.\n\n##\n\nCyc is born\n\nLenat soon got the chance to pursue his vision outside the confines of\nacademic research. The year after the Stanford meeting, ten US companies\nformed the Microelectronics and Computer Technology Corporation (MCC), a\nresearch consortium to counter an ambitious computing initiative launched by\nthe Japanese government. Lenat was considering a tenured position as a\nprofessor at Stanford, but the attraction of private-sector-scale resources\nproved too great. He signed on as MCC's chief scientist. Armed with a half-\nbillion dollar budget and hundreds of employees, he headed MCC's flagship\nproject: to produce the massive knowledge base that machines would need to\nreason like humans. They called it Cyc, from 'encyclopedia'.\n\nDespite its name, Cyc was not meant to be encyclopedic per se; it would cover\nan even more basic level of knowledge \u2013 propositions like 'A person is born\nonly once' and 'Animals can't talk except in fairy tales' that are so obvious\nthat no one bothers to write them down. Cyc would be the foundation for\nspecialized expert systems that would have domain knowledge about things like\nchemical compounds and human anatomy.\n\nCyc's knowledge base is a collection of frames (also called units), with slots\nfor properties and entries for their values. Concretely, the frame 'Texas' has\na 'capital' slot with the entry 'Austin'. Frames are organized into a global\nontology, meaning that each frame belongs to one or more categories, and\ncategories themselves belong to categories, all the way up to a root 'Thing'\ncategory that encompasses everything in the knowledge base.\n\nOn top of frames sits a constraint language that allows the system to express\nlogical concepts like quantification ('every X is Y') and disjunction ('X or Y\nbut not both'), and an inference engine to make deductions and answer queries.\nWhile there is a general-purpose reasoning engine, specialized inference\nengines are used for most queries for efficiency.\n\nCyc has 'microtheories' which allow it to reconcile seemingly contradictory\nfacts from different domains, for example classical physics and quantum\nmechanics. In general, Cyc does not have 'probability factors', but it does\nhave coarse notions of likelihood, as well as awareness that some facts (like\nthe population of a country) are estimates and others (like the fact that dogs\nhave four legs) are only true by default.\n\nThe 'ontological engineers' employed by Cyc originally entered the frames by\nhand. One technique they used was reading English text and looking for\nsentences with ambiguous pronouns: in a case where a pronoun like 'he' or\n'she' was syntactically ambiguous, what common-sense knowledge does a human\nuse to identify the referent? Consider these two sentences:\n\n> Tom was mad at Joe because he stole his lunch.\n>\n> Tom was mad at Joe so he stole his lunch.\n\nAs any speaker of English can deduce without conscious effort, the word 'he'\nrefers to Joe in the first sentence but Tom in the second, despite differing\nby only one word. We know this because of our understanding of human behavior\nand the concepts of anger and theft \u2013 it is logical that Tom would be mad at\nJoe if Joe stole Tom's lunch, but not if Tom stole Joe's lunch. But machines\ndo not know this and must be taught explicitly.\n\nAnother technique was looking at pairs of sentences and figuring out the\nsubtext that links them. For instance: \"Of the five schools that accepted her,\nMary decided to go to Harvard. She graduated with a degree in chemistry.\"\nBetween the two sentences, we infer that Mary probably left home and went to\nMassachusetts for a period of approximately four years; took a few dozen\ncourses, many but not all of which were in chemistry; met other students and\nprofessors at the university; and many other things that are left unstated. An\nintelligent system like Cyc ought to be able to make these inferences; if it\ncannot, the ontological engineers have to figure out what axioms to add to the\nknowledge base so that it can.\n\n##\n\nCycorp\n\nWork on Cyc progressed steadily through the ten years that MCC was funded. In\na 1989 book-length report on the project, the Cyc team projected optimism. The\nknowledge base had reached 1 million 'pieces of data', including 50,000\nindividual units and 6,000 collections. Many \"representational thorns\" \u2013\ndifficulties in representing real-world knowledge within the system, some of\nwhich were in fact ancient problems in philosophy3 \u2013 were encountered and\ndealt with. The guiding philosophy was pragmatism over elegance: age-old\nphilosophical problems were side-stepped with practical solutions. The\ninfamous problem of causation, for instance, was reduced to the idea that 'E1\ncauses E2' means 'if E1 is observed, predict that E2 will happen'.\n\nWhen MCC disbanded in 1994, Cyc was spun off under a new company called Cycorp\n(pronounced \"SIGH-core\"). Cycorp sustained itself financially through\ncontracts with the government and corporations. Much of what Cycorp did in\nthis period has not been publicly disclosed, but a few projects have come to\nlight through research papers and technical reports. Cyc was used by the\nCleveland Clinic for answering ad hoc questions from medical researchers; it\nreduced the time from as long as a month of manual back-and-forth between\nmedical and database experts, to less than an hour. Cycorp also partnered with\nthe US intelligence community to assist in building a 'terrorism knowledge\nbase' that analysts could query. Cyc's grasp of common-sense knowledge helped\nit 'fill in the blanks' in synthesizing information from different sources\nthat was often incomplete or contradictory.\n\nIn the 2000s, Cycorp released a subset of the knowledge base as OpenCyc, and\noffered researchers an expanded version called ResearchCyc. A few outside\nresearchers published papers based on the Cyc system. But the core product\nremained proprietary, and OpenCyc releases stopped in 2012.\n\nWhile Cyc was slowly but steadily growing its knowledge base, the field of\nartificial intelligence was radically changing. Most expert systems were long\ngone by the 2000s. Neural networks using deep learning, a type of statistical\nmachine learning based on generic, opaque algorithms trained on massive\namounts of data, were making huge breakthroughs. It was practically the\nantithesis of Cyc's logical reasoning and painstakingly handcrafting knowledge\nbase of explicit rules. But despite their lack of common-sense knowledge,\ndeep-learning algorithms proved to be fantastically successful at previously\nintractable problems. Beginning with AlexNet in 2012, neural nets\nrevolutionized the field of image recognition. Game-playing programs by\nGoogle's DeepMind lab trounced the previous strongest chess-playing program\nand beat one of the world's top go players. And neural nets were behind the\nastonishing success of large language models like ChatGPT and Gemini. In a\nfield now dominated by machine learning, Cyc's rule-based, symbolic approach\nincreasingly looked like an anachronism.\n\n##\n\nCyc in the age of LLMs\n\nYet, forty years after its inception, Cyc is still here. It has grown to a\nknowledge base of 25 million rules, 1.5 million concepts, and more than a\nthousand specialized inference engines. Cycorp employs 50 technical staff\nmembers and is completely funded by its commercial contracts. Nevertheless, to\nthe extent that Cyc is remembered at all in the AI community, it is as a\ncautionary tale of tremendous effort wasted on a misguided approach.\n\nThe verdict is harsh \u2013 but the expectations were high. In 1989, Lenat and co-\nauthor R. V. Guha wrote \"we hope that by 1999 no one would even think about\nhaving a computer that doesn't have Cyc running on it\". They have had to\nsettle for more modest victories. Surviving for forty years in an industry\nnotorious for its boom-and-bust cycles is a noteworthy achievement, but Cyc's\nimpact has failed to be revolutionary. While outsiders cannot assess the\ncapabilities of the proprietary system, it is fair to infer that if Cyc had\nachieved an epoch-making breakthrough, the wider world would have heard about\nit.\n\nStill, while overshadowed by flashier programs like ChatGPT, Cyc should not be\ncounted out. Lenat, who passed away in 2023, wrote his final paper about the\nopportunities for Cyc and LLMs to complement each other. LLMs are fluent and\nknowledgeable, but often inconsistent and inaccurate. Cyc is not as good at\nunderstanding and generating English text, but its conclusions are always\nsupported by a chain of reasoning that can be audited by a human. An\nintegrated Cyc\u2013LLM system could be a powerful synthesis.\n\nThe course of progress is unpredictable: fertile areas of research turn barren\nand methodologies that were left for dead suddenly come back to life. Neural\nnets were invented in the 1940s, then fell out of favor for decades. Rule-\nbased systems like Cyc were once the vanguard of AI. Perhaps their time will\ncome again.\n\n##\n\nAnnotated bibliography\n\n###\n\nAcademic\n\nDouglas B. Lenat and John Seely Brown. 1984. Why AM and EURISKO appear to\nwork. Artificial Intelligence 23, 3 (August 1984), 269\u2013294.\nhttps://doi.org/10.1016/0004-3702(84)90016-X\n\n> A description of Lenat's earlier work that partially inspired Cyc.\n\nDouglas B. Lenat and R. V. Guha. 1989. Building Large Knowledge-Based Systems:\nRepresentation and Inference in the Cyc Project. Addison-Wesley.\nhttps://dl.acm.org/doi/book/10.5555/575523\n\n> A book-length report on the Cyc project's progress after five years. Thirty\n> years out of date but still the most complete reference on the system.\n\nDouglas B. Lenat, R. V. Guha, Karen Pittman, Dexter Pratt, and Mary Shepherd.\n1990. Cyc: toward programs with common sense. Communications of the ACM 33, 8\n(Aug. 1990), 30\u201349. https://doi.org/10.1145/79173.79176\n\n> A shorter article covering much of the same ground as the 1989 book.\n\nDouglas B. Lenat and Chris Deaton. 2008. Terrorism Knowledge Base. Government\ntechnical report (April 2008).\nhttps://www.researchgate.net/publication/235042082_Terrorism_Knowledge_Base_TKB\n\n> A report on Cycorp's partnership with the US intelligence community to build\n> a database on global terrorism.\n\nDouglas Lenat, Michael Witbrock, David Baxter, Eugene Blackstone, Chris\nDeaton, Dave Schneider, Jerry Scott, and Blake Shepard. 2010. Harnessing Cyc\nto answer clinical researchers' ad hoc queries. AI Magazine 31, 3 (Fall 2010),\n13\u201332. https://doi.org/10.1609/aimag.v31i3.2299\n\n> A report on Cycorp's partnership with the Cleveland Clinic for medical\n> research.\n\nDouglas Lenat. 2022. Creating a 30-million-rule system: MCC and Cycorp. IEEE\nAnnals of the History of Computing 44, 1 (Jan.\u2013Mar. 2022), 44\u201356.\nhttps://muse.jhu.edu/pub/87/article/853382/pdf\n\n> A history of the Cyc project, from its origins in the AI research of the\n> 1970s to the present day.\n\nDoug Lenat and Gary Marcus. 2023. Getting from generative AI to trustworthy\nAI: what LLMs might learn from Cyc. arXiv preprint (July 2023).\nhttps://arxiv.org/abs/2308.04445\n\n> Lenat's final paper. Compares the strengths of weaknesses of Cyc with LLMs.\n\nCynthia Matuszek, John Cabral, Michael Witbrock, and John DeOliveira. 2006. An\nintroduction to the syntax and content of Cyc. AAAI Spring Symposium (2006).\nhttps://www.researchgate.net/publication/221250660_An_Introduction_to_the_Syntax_and_Content_of_Cyc\n\n> An account of CycL, the representation language used for the knowledge base,\n> as of the mid 2000s.\n\n###\n\nNon-academic\n\nThe Software With Good Sense by George Harrar in The New York Times (April 1,\n1990, p. 7)\n\n> An early newspaper article on the Cyc project.\n\nDueling Brainscapes In Artificial Intelligence in Bloomberg (June 23, 1997)\n\n> A comparison of Cyc's \"top-down\" directed approach with a robotics company's\n> \"bottom-up\" learning-based approach.\n\nOne Genius\u2019 Lonely Crusade to Teach a Computer Common Sense by Cade Metz in\nWired (2016)\n\n> Fairly recent detailed account in the popular press of the current state of\n> the Cyc project.\n\nCyc on Hacker News (2019)\n\n> An online discussion in which a couple former Cycorp employees chimed in.\n\nCyc Technology Overview published by Cycorp (2021)\n\n> A description of Cyc's commercial uses and comparison to machine learning.\n\nDouglas Lenat: Cyc and the Quest to Solve Common Sense Reasoning in AI on the\nLex Fridman Podcast (2021)\n\n> Recent in-depth interview with Doug Lenat on the Cyc project and its future.\n\nDoug Lenat, 1950\u20132023 by Gary Marcus on Substack (2023)\n\n> An obituary of Doug Lenat by a fellow researcher who knew him personally.\n\n1\n\nLenat & Guha (1989), p. 4\n\n2\n\nThe next year, the organizers changed the rules to forbid EURISKO's winning\nstrategy, but the program adapted and won again. The chagrined organizers\nbanned EURISKO from future tournaments.\n\n3\n\nIncluding such issues as distinguishing objects from substances, extrinsic and\nintrinsic properties, causality, and probability. The reader is directed to\nchapter 6 of Lenat & Guha (1989) for details.\n\n### Subscribe to Outsider Art\n\nBy I. A. Fisher \u00b7 Launched 7 months ago\n\nDeep dives on linguistics, literature, and technology\n\n1 Like\n\nShare this post\n\n#### Cyc: history's forgotten AI project\n\noutsiderart.substack.com\n\nShare\n\nComments\n\nWriting systems\n\nA taxonomy of writing; the invention of writing; phonetic writing systems;\noptimality\n\nMar 10 \u2022\n\nI. A. Fisher\n\n2\n\nShare this post\n\n#### Writing systems\n\noutsiderart.substack.com\n\n\"Steppenwolf\" (Hermann Hesse)\n\n'not the eccentricity of a single individual, but the sickness of the times\nthemselves'\n\nOct 30, 2023 \u2022\n\nI. A. Fisher\n\n1\n\nShare this post\n\n#### \"Steppenwolf\" (Hermann Hesse)\n\noutsiderart.substack.com\n\n\"The Painted Veil\" (W. Somerset Maugham)\n\nLove, betrayal, and redemption in post-imperial China\n\nOct 2, 2023 \u2022\n\nI. A. Fisher\n\n1\n\nShare this post\n\n#### \"The Painted Veil\" (W. Somerset Maugham)\n\noutsiderart.substack.com\n\nReady for more?\n\n\u00a9 2024 outsider\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": true}
