{"aid": "40052980", "title": "AI now beats humans at basic tasks \u2013 new benchmarks are needed", "url": "https://www.nature.com/articles/d41586-024-01087-4", "domain": "nature.com", "votes": 2, "user": "gmays", "posted_at": "2024-04-16 15:09:53", "comments": 0, "source_title": "AI now beats humans at basic tasks \u2014 new benchmarks are needed, says major report", "source_text": "AI now beats humans at basic tasks \u2014 new benchmarks are needed, says major\nreport\n\nSkip to main content\n\nThank you for visiting nature.com. You are using a browser version with\nlimited support for CSS. To obtain the best experience, we recommend you use a\nmore up to date browser (or turn off compatibility mode in Internet Explorer).\nIn the meantime, to ensure continued support, we are displaying the site\nwithout styles and JavaScript.\n\nAdvertisement\n\n  * View all journals\n  * Search\n\n## Search\n\nAdvanced search\n\n### Quick links\n\n    * Explore articles by subject\n    * Find a job\n    * Guide to authors\n    * Editorial policies\n\n  * Log in\n\n  * Explore content\n  * About the journal\n  * Publish with us\n  * Subscribe\n\n  * Sign up for alerts\n  * RSS feed\n\n  * NEWS\n  * 15 April 2024\n\n# AI now beats humans at basic tasks \u2014 new benchmarks are needed, says major\nreport\n\nStanford University\u2019s 2024 AI Index charts the meteoric rise of artificial-\nintelligence tools.\n\nBy\n\n  * Nicola Jones\n\n  1. Nicola Jones\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  * Twitter\n  * Facebook\n  * Email\n\nA woman plays Go with an AI-powered robot developed by the firm SenseTime,\nbased in Hong Kong. Credit: Joan Cros/NurPhoto via Getty\n\nArtificial intelligence (AI) systems, such as the chatbot ChatGPT, have become\nso advanced that they now very nearly match or exceed human performance in\ntasks including reading comprehension, image classification and competition-\nlevel mathematics, according to a new report (see \u2018Speedy advances\u2019). Rapid\nprogress in the development of these systems also means that many common\nbenchmarks and tests for assessing them are quickly becoming obsolete.\n\nThese are just a few of the top-line findings from the Artificial Intelligence\nIndex Report 2024, which was published on 15 April by the Institute for Human-\nCentered Artificial Intelligence at Stanford University in California. The\nreport charts the meteoric progress in machine-learning systems over the past\ndecade.\n\nIn particular, the report says, new ways of assessing AI \u2014 for example,\nevaluating their performance on complex tasks, such as abstraction and\nreasoning \u2014 are more and more necessary. \u201cA decade ago, benchmarks would serve\nthe community for 5\u201310 years\u201d whereas now they often become irrelevant in just\na few years, says Nestor Maslej, a social scientist at Stanford and editor-in-\nchief of the AI Index. \u201cThe pace of gain has been startlingly rapid.\u201d\n\nStanford\u2019s annual AI Index, first published in 2017, is compiled by a group of\nacademic and industry specialists to assess the field\u2019s technical\ncapabilities, costs, ethics and more \u2014 with an eye towards informing\nresearchers, policymakers and the public. This year\u2019s report, which is more\nthan 400 pages long and was copy-edited and tightened with the aid of AI\ntools, notes that AI-related regulation in the United States is sharply\nrising. But the lack of standardized assessments for responsible use of AI\nmakes it difficult to compare systems in terms of the risks that they pose.\n\nThe rising use of AI in science is also highlighted in this year\u2019s edition:\nfor the first time, it dedicates an entire chapter to science applications,\nhighlighting projects including Graph Networks for Materials Exploration\n(GNoME), a project from Google DeepMind that aims to help chemists discover\nmaterials, and GraphCast, another DeepMind tool, which does rapid weather\nforecasting.\n\n## Growing up\n\nThe current AI boom \u2014 built on neural networks and machine-learning algorithms\n\u2014 dates back to the early 2010s. The field has since rapidly expanded. For\nexample, the number of AI coding projects on GitHub, a common platform for\nsharing code, increased from about 800 in 2011 to 1.8 million last year. And\njournal publications about AI roughly tripled over this period, the report\nsays.\n\nChatGPT broke the Turing test \u2014 the race is on for new ways to assess AI\n\nMuch of the cutting-edge work on AI is being done in industry: that sector\nproduced 51 notable machine-learning systems last year, whereas academic\nresearchers contributed 15. \u201cAcademic work is shifting to analysing the models\ncoming out of companies \u2014 doing a deeper dive into their weaknesses,\u201d says\nRaymond Mooney, director of the AI Lab at the University of Texas at Austin,\nwho wasn\u2019t involved in the report.\n\nThat includes developing tougher tests to assess the visual, mathematical and\neven moral-reasoning capabilities of large language models (LLMs), which power\nchatbots. One of the latest tests is the Graduate-Level Google-Proof Q&A\nBenchmark (GPQA)^1, developed last year by a team including machine-learning\nresearcher David Rein at New York University.\n\nThe GPQA, consisting of more than 400 multiple-choice questions, is tough:\nPhD-level scholars could correctly answer questions in their field 65% of the\ntime. The same scholars, when attempting to answer questions outside their\nfield, scored only 34%, despite having access to the Internet during the test\n(randomly selecting answers would yield a score of 25%). As of last year, AI\nsystems scored about 30\u201340%. This year, Rein says, Claude 3 \u2014 the latest\nchatbot released by AI company Anthropic, based in San Francisco, California \u2014\nscored about 60%. \u201cThe rate of progress is pretty shocking to a lot of people,\nme included,\u201d Rein adds. \u201cIt\u2019s quite difficult to make a benchmark that\nsurvives for more than a few years.\u201d\n\n## Cost of business\n\nAs performance is skyrocketing, so are costs. GPT-4 \u2014 the LLM that powers\nChatGPT and that was released in March 2023 by San Francisco-based firm OpenAI\n\u2014 reportedly cost US$78 million to train. Google\u2019s chatbot Gemini Ultra,\nlaunched in December, cost $191 million. Many people are concerned about the\nenergy use of these systems, as well as the amount of water needed to cool the\ndata centres that help to run them^2. \u201cThese systems are impressive, but\nthey\u2019re also very inefficient,\u201d Maslej says.\n\nCosts and energy use for AI models are high in large part because one of the\nmain ways to make current systems better is to make them bigger. This means\ntraining them on ever-larger stocks of text and images. The AI Index notes\nthat some researchers now worry about running out of training data. Last year,\naccording to the report, the non-profit research institute Epoch projected\nthat we might exhaust supplies of high-quality language data as soon as this\nyear. (However, the institute\u2019s most recent analysis suggests that 2028 is a\nbetter estimate.)\n\nAI \u2018breakthrough\u2019: neural net has human-like ability to generalize language\n\nEthical concerns about how AI is built and used are also mounting. \u201cPeople are\nway more nervous about AI than ever before, both in the United States and\nacross the globe,\u201d says Maslej, who sees signs of a growing international\ndivide. \u201cThere are now some countries very excited about AI, and others that\nare very pessimistic.\u201d\n\nIn the United States, the report notes a steep rise in regulatory interest. In\n2016, there was just one US regulation that mentioned AI; last year, there\nwere 25. \u201cAfter 2022, there\u2019s a massive spike in the number of AI-related\nbills that have been proposed\u201d by policymakers, Maslej says.\n\nRegulatory action is increasingly focused on promoting responsible AI use.\nAlthough benchmarks are emerging that can score metrics such as an AI tool\u2019s\ntruthfulness, bias and even likability, not everyone is using the same models,\nMaslej says, which makes cross-comparisons hard. \u201cThis is a really important\ntopic,\u201d he says. \u201cWe need to bring the community together on this.\u201d\n\ndoi: https://doi.org/10.1038/d41586-024-01087-4\n\n## References\n\n  1. Rein, D. et al. Preprint at arXiv https://doi.org/10.48550/arXiv.2311.12022 (2023).\n\n  2. Li, P., Yang, J., Islam, M. A. & Ren, S. Preprint at arXiv https://doi.org/10.48550/arXiv.2304.03271 (2023).\n\nDownload references\n\nReprints and permissions\n\n## Related Articles\n\n  * ChatGPT broke the Turing test \u2014 the race is on for new ways to assess AI\n\n  * AI \u2018breakthrough\u2019: neural net has human-like ability to generalize language\n\n  * Google AI has better bedside manner than human doctors \u2014 and makes better diagnoses\n\n  * Abstracts written by ChatGPT fool scientists\n\n  * What ChatGPT and generative AI mean for science\n\n## Subjects\n\n  * Machine learning\n  * Computer science\n  * Industry\n\n## Latest on:\n\nIs ChatGPT corrupting peer review? Telltale words hint at AI use\n\nNews 10 APR 24\n\nHow to break big tech\u2019s stranglehold on AI in academia\n\nCorrespondence 09 APR 24\n\nAI can help to tailor drugs for Africa \u2014 but Africans should lead the way\n\nComment 09 APR 24\n\nHigh-threshold and low-overhead fault-tolerant quantum memory\n\nArticle 27 MAR 24\n\nThree reasons why AI doesn\u2019t model human language\n\nCorrespondence 19 MAR 24\n\nSo ... you\u2019ve been hacked\n\nTechnology Feature 19 MAR 24\n\nThe beauty of what science can do when urgently needed\n\nCareer Q&A 26 MAR 24\n\nMore than 4,000 plastic chemicals are hazardous, report finds\n\nNews 14 MAR 24\n\n\u2018This is my calling\u2019: building point-of-care diagnostic tools to fight\ntuberculosis\n\nCareer Q&A 01 MAR 24\n\nIs ChatGPT corrupting peer review? Telltale words hint at AI use\n\nNews 10 APR 24\n\nHow to break big tech\u2019s stranglehold on AI in academia\n\nCorrespondence 09 APR 24\n\nAI can help to tailor drugs for Africa \u2014 but Africans should lead the way\n\nComment 09 APR 24\n\n### Jobs\n\n  * #### Computational Postdoctoral Fellow with a Strong Background in Bioinformatics\n\nHouston, Texas (US)\n\nThe University of Texas MD Anderson Cancer Center\n\n  * #### Locum Associate or Senior Editor (Immunology), Nature Communications\n\nThe Editor in Immunology at Nature Communications will handle original\nresearch papers and work on all aspects of the editorial process.\n\nLondon, Beijing or Shanghai - Hybrid working model\n\nSpringer Nature Ltd\n\n  * #### Assistant Professor - Cell Physiology & Molecular Biophysics\n\nOpportunity in the Department of Cell Physiology and Molecular Biophysics\n(CPMB) at Texas Tech University Health Sciences Center (TTUHSC)\n\nLubbock, Texas\n\nTexas Tech University Health Sciences Center, School of Medicine\n\n  * #### Postdoctoral Associate- Curing Brain Tumors\n\nHouston, Texas (US)\n\nBaylor College of Medicine (BCM)\n\n  * #### Professor\n\nEnergy AI / Grid Modernization / Hydrogen Energy / Power Semiconductor\nConcentration / KENTECH College\n\n21, Kentech-gil, Naju-si, Jeollanam-do, Republic of Korea(KR)\n\nKorea Institute of Energy Technology\n\n## Related Articles\n\n  * ChatGPT broke the Turing test \u2014 the race is on for new ways to assess AI\n\n  * AI \u2018breakthrough\u2019: neural net has human-like ability to generalize language\n\n  * Google AI has better bedside manner than human doctors \u2014 and makes better diagnoses\n\n  * Abstracts written by ChatGPT fool scientists\n\n  * What ChatGPT and generative AI mean for science\n\n## Subjects\n\n  * Machine learning\n  * Computer science\n  * Industry\n\n## Sign up to Nature Briefing\n\nAn essential round-up of science news, opinion and analysis, delivered to your\ninbox every weekday.\n\nSign up for the Nature Briefing newsletter \u2014 what matters in science, free to\nyour inbox daily.\n\nGet the most important science stories of the day, free in your inbox. Sign up\nfor Nature Briefing\n\nNature (Nature) ISSN 1476-4687 (online) ISSN 0028-0836 (print)\n\n## nature.com sitemap\n\n### About Nature Portfolio\n\n  * About us\n  * Press releases\n  * Press office\n  * Contact us\n\n### Discover content\n\n  * Journals A-Z\n  * Articles by subject\n  * protocols.io\n  * Nature Index\n\n### Publishing policies\n\n  * Nature portfolio policies\n  * Open access\n\n### Author & Researcher services\n\n  * Reprints & permissions\n  * Research data\n  * Language editing\n  * Scientific editing\n  * Nature Masterclasses\n  * Research Solutions\n\n### Libraries & institutions\n\n  * Librarian service & tools\n  * Librarian portal\n  * Open research\n  * Recommend to library\n\n### Advertising & partnerships\n\n  * Advertising\n  * Partnerships & Services\n  * Media kits\n  * Branded content\n\n### Professional development\n\n  * Nature Careers\n  * Nature Conferences\n\n### Regional websites\n\n  * Nature Africa\n  * Nature China\n  * Nature India\n  * Nature Italy\n  * Nature Japan\n  * Nature Middle East\n\n  * Privacy Policy\n  * Use of cookies\n  * Legal notice\n  * Accessibility statement\n  * Terms & Conditions\n  * Your US state privacy rights\n  * Cancel contracts here\n\n\u00a9 2024 Springer Nature Limited\n\n", "frontpage": false}
