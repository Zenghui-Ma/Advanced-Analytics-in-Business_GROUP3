{"aid": "40073942", "title": "AutoRAG \u2013 AutoML Tool for RAG", "url": "https://github.com/Marker-Inc-Korea/AutoRAG", "domain": "github.com/marker-inc-korea", "votes": 1, "user": "vkehfdl1", "posted_at": "2024-04-18 07:51:45", "comments": 0, "source_title": "GitHub - Marker-Inc-Korea/AutoRAG: RAG AutoML Tool - Find optimal RAG pipeline for your own data.", "source_text": "GitHub - Marker-Inc-Korea/AutoRAG: RAG AutoML Tool - Find optimal RAG pipeline\nfor your own data.\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nMarker-Inc-Korea / AutoRAG Public\n\n  * Notifications\n  * Fork 30\n  * Star 531\n\nRAG AutoML Tool - Find optimal RAG pipeline for your own data.\n\n### License\n\nApache-2.0 license\n\n531 stars 30 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# Marker-Inc-Korea/AutoRAG\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n11 Branches\n\n17 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nbwook00Merge pull request #350 from Marker-Inc-Korea/Feature/#346Apr 18,\n20246b79f60 \u00b7 Apr 18, 2024Apr 18, 2024\n\n## History\n\n507 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Mock openai chat completion calls for preventing tons of openai usage. (|\nApr 18, 2024  \n  \n### autorag\n\n|\n\n### autorag\n\n| Merge branch 'main' into Feature/#346| Apr 18, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| generate sitemap.xml automatically for SEO (#351)| Apr 18, 2024  \n  \n### sample_config\n\n|\n\n### sample_config\n\n| Merge branch 'main' into Feature/#321| Apr 14, 2024  \n  \n### sample_dataset\n\n|\n\n### sample_dataset\n\n| fix file name trivia, fix tree summarize annotaion link| Feb 6, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Mock openai chat completion calls for preventing tons of openai usage. (|\nApr 18, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Make brief structure for RAGround (#4)| Jan 10, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit| Jan 10, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| move supporting nodes & modules to Notion Page| Apr 10, 2024  \n  \n### dev_requirements.txt\n\n|\n\n### dev_requirements.txt\n\n| Mock openai chat completion calls for preventing tons of openai usage. (|\nApr 18, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| move cli test and change pyproject.toml entry point| Feb 15, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Add RAGAS test set data creation wrapper for AutoRAG (#302)| Apr 12, 2024  \n  \n## Repository files navigation\n\n# AutoRAG\n\nRAG AutoML tool for automatically finds an optimal RAG pipeline for your data.\n\nExplore our \ud83d\udcd6 Document!!\n\nPlus, join our \ud83d\udcde Discord Community.\n\n\ud83d\udccc Colab Tutorial\n\n  * Step 1: Basic of AutoRAG | Optimizing your RAG pipeline\n  * Step 2: Create evaluation dataset\n\n\ud83d\udea8 YouTube Tutorial\n\nMuted by default, enable sound for voice-over\n\nYou can see on YouTube\n\n# \ud83d\udcd1 Index\n\n  * Introduction\n  * Quick Install\n  * Index\n  * Strengths\n  * QuickStart\n\n    * 1\\. Prepare your evaluation data\n    * 2\\. Evaluate your data to various RAG modules\n    * 3\\. Use a found optimal RAG pipeline\n    * 4\\. Share your RAG pipeline\n    * \\+ Config yaml file\n  * Supporting RAG modules\n  * Roadmap\n  * Contribution\n\n# Introduction\n\nThere are many RAG pipelines and modules out there, but you don\u2019t know what\npipeline is great for \u201cyour own data\u201d and \"your own use-case.\" Making and\nevaluating all RAG modules is very time-consuming and hard to do. But without\nit, you will never know which RAG pipeline is the best for your own use-case.\n\nAutoRAG is a tool for finding optimal RAG pipeline for \u201cyour data.\u201d You can\nevaluate various RAG modules automatically with your own evaluation data, and\nfind the best RAG pipeline for your own use-case.\n\nAutoRAG supports a simple way to evaluate many RAG module combinations. Try\nnow and find the best RAG pipeline for your own use-case.\n\n# \u26a1 Quick Install\n\n    \n    \n    pip install AutoRAG\n\n# \ud83d\udcaa Strengths\n\n### 1\\. Find your RAG baseline\n\nBenchmark RAG pipelines with few lines of code. You can quickly get a high-\nperformance RAG pipeline just for your data. Don\u2019t waste time dealing with\ncomplex RAG modules and academic paper. Focus on your data.\n\n### 2\\. Analyze where is wrong\n\nSometimes it is hard to keep tracking where is the major problem within your\nRAG pipeline. AutoRAG gives you the data of it, so you can analyze and focus\nwhere is the major problem and where you to focus on.\n\n### 3\\. Quick Starter Pack for your new RAG product\n\nGet the most effective RAG workflow among many pipelines, and start from\nthere. Don\u2019t start at toy-project level, start from advanced level.\n\n### 4\\. Share your experiment to others\n\nIt's really easy to share your experiment to others. Share your config yaml\nfile and summary csv files. Plus, check out others result and adapt to your\nuse-case.\n\n# \u26a1 QuickStart\n\n### 1\\. Prepare your evaluation data\n\nFor evaluation, you need to prepare just three files.\n\n  * QA dataset file (qa.parquet)\n  * Corpus dataset file (corpus.parquet)\n  * Config yaml file (config.yaml)\n\nThere is a template for your evaluation data for using AutoRAG.\n\n  * Check out how to make evaluation data at here.\n  * Check out the evaluation data rule at here.\n  * Plus, you can get example datasets for testing AutoRAG at here.\n\n### 2\\. Evaluate your data to various RAG modules\n\nYou can get various config yaml files at here. We highly recommend using pre-\nmade config yaml files for starter.\n\nIf you want to make your own config yaml files, check out the Config yaml file\nsection.\n\nYou can evaluate your RAG pipeline with just a few lines of code.\n\n    \n    \n    from autorag.evaluator import Evaluator evaluator = Evaluator(qa_data_path='your/path/to/qa.parquet', corpus_data_path='your/path/to/corpus.parquet') evaluator.start_trial('your/path/to/config.yaml')\n\nor you can use command line interface\n\n    \n    \n    autorag evaluate --config your/path/to/default_config.yaml --qa_data_path your/path/to/qa.parquet --corpus_data_path your/path/to/corpus.parquet\n\nOnce it is done, you can see several files and folders created at your current\ndirectory. At the trial folder named to numbers (like 0), you can check\nsummary.csv file that summarizes the evaluation results and the best RAG\npipeline for your data.\n\nFor more details, you can check out how the folder structure looks like at\nhere.\n\n### 3\\. Use a found optimal RAG pipeline\n\nYou can use a found optimal RAG pipeline right away. It needs just a few lines\nof code, and you are ready to use!\n\nFirst, you need to build pipeline yaml file from your evaluated trial folder.\nYou can find the trial folder in your current directory. Just looking folder\nlike '0' or other numbers.\n\n    \n    \n    from autorag.deploy import Runner runner = Runner.from_trial_folder('your/path/to/trial_folder') runner.run('your question')\n\nOr, you can run this pipeline as api server. You can use python code or CLI\ncommand. Check out API endpoint at here.\n\n    \n    \n    from autorag.deploy import Runner runner = Runner.from_trial_folder('your/path/to/trial_folder') runner.run_api_server()\n\nYou can run api server with CLI command.\n\n    \n    \n    autorag run_api --config_path your/path/to/pipeline.yaml --host 0.0.0.0 --port 8000\n\n### 4\\. Share your RAG pipeline\n\nYou can use your RAG pipeline from extracted pipeline yaml file. This\nextracted pipeline is great for sharing your RAG pipeline to others.\n\nYou must run this at project folder, which contains datas in data folder, and\ningested corpus for retrieval at resources folder.\n\n    \n    \n    from autorag.deploy import extract_best_config pipeline_dict = extract_best_config(trial_path='your/path/to/trial_folder', output_path='your/path/to/pipeline.yaml')\n\n### \u2795 Create your own Config yaml file\n\nYou can build your own evaluation process with config yaml file. You can check\ndetailed explanation how to configure each module and node at here.\n\nThere is a simple yaml file example.\n\nIt evaluates two retrieval modules which are BM25 and Vector Retriever, and\nthree reranking modules. Lastly, it generates prompt and makes generation with\ntwo other LLM models and three temperatures.\n\n    \n    \n    node_lines: - node_line_name: retrieve_node_line nodes: - node_type: retrieval strategy: metric: retrieval_f1 top_k: 50 modules: - module_type: bm25 - module_type: vector embedding_model: [ openai, openai_embed_3_large ] - module_type: hybrid_rrf target_modules: ('bm25', 'vectordb') rrf_k: [ 3, 5, 10 ] - node_type: reranker strategy: metric: retrieval_precision speed_threshold: 5 top_k: 3 modules: - module_type: upr - module_type: tart prompt: Arrange the following sentences in the correct order. - module_type: monoT5 - node_line_name: generate_node_line nodes: - node_type: prompt_maker modules: - module_type: fstring prompt: \"This is a news dataset, crawled from finance news site. You need to make detailed question about finance news. Do not make questions that not relevant to economy or finance domain.\\n{retrieved_contents}\\n\\nQ: {query}\\nA:\" - node_type: generator strategy: metric: - metric_name: meteor - metric_name: rouge - metric_name: sem_score embedding_model: openai - metric_name: g_eval model: gpt-3.5-turbo modules: - module_type: llama_index_llm llm: openai model: [ gpt-3.5-turbo-16k, gpt-3.5-turbo-1106 ] temperature: [ 0.5, 1.0, 1.5 ]\n\n# \u2757Supporting Nodes & modules\n\nYou can check our all supporting Nodes & modules at here\n\n# \ud83d\udee3Roadmap\n\n  * Policy Module for modular RAG pipeline\n  * Visualize evaluation result\n  * Visualize config yaml file\n  * More RAG modules support\n  * Token usage strategy\n  * Multi-modal support\n  * More evaluation metrics\n  * Answer Filtering Module\n  * Restart optimization from previous trial\n\n# Contribution\n\nWe are developing AutoRAG as open-source.\n\nSo this project welcomes contributions and suggestions. Feel free to\ncontribute to this project.\n\nPlus, check out our detailed documentation at here.\n\n## About\n\nRAG AutoML Tool - Find optimal RAG pipeline for your own data.\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n531 stars\n\n### Watchers\n\n8 watching\n\n### Forks\n\n30 forks\n\nReport repository\n\n## Releases 17\n\nv0.1.3 Latest\n\nApr 14, 2024\n\n\\+ 16 releases\n\n## Packages 0\n\nNo packages published\n\n## Contributors 3\n\n  * bwook00 Bwook (Byoungwook) Kim\n  * vkehfdl1 Jeffrey (Dongkyu) Kim\n  * Eastsidegunn\n\n## Languages\n\n  * Python 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
