{"aid": "40047642", "title": "Hopfield Network", "url": "https://en.wikipedia.org/wiki/Hopfield_network", "domain": "wikipedia.org", "votes": 1, "user": "teleforce", "posted_at": "2024-04-16 01:51:27", "comments": 0, "source_title": "Hopfield network", "source_text": "Hopfield network - Wikipedia\n\nJump to content\n\nSearch\n\n# Hopfield network\n\n  * \u0627\u0644\u0639\u0631\u0628\u064a\u0629\n  * Catal\u00e0\n  * \u010ce\u0161tina\n  * Deutsch\n  * Espa\u00f1ol\n  * \u0641\u0627\u0631\u0633\u06cc\n  * Fran\u00e7ais\n  * \ud55c\uad6d\uc5b4\n  * Italiano\n  * \u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8\n  * Latvie\u0161u\n  * \u0d2e\u0d32\u0d2f\u0d3e\u0d33\u0d02\n  * Nederlands\n  * \u65e5\u672c\u8a9e\n  * Polski\n  * Portugu\u00eas\n  * \u0420\u0443\u0441\u0441\u043a\u0438\u0439\n  * Svenska\n  * \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430\n  * Ti\u1ebfng Vi\u1ec7t\n  * \u7cb5\u8a9e\n  * \u4e2d\u6587\n\nEdit links\n\nFrom Wikipedia, the free encyclopedia\n\nForm of artificial neural network\n\nA Hopfield network (Ising model of a neural network or Ising\u2013Lenz\u2013Little model\nor Amari-Little-Hopfield network) is a spin glass system used to model neural\nnetworks, based on Ernst Ising's work with Wilhelm Lenz on the Ising model of\nmagnetic materials.^[1] Hopfield networks were first described with respect to\nrecurrent neural networks by Shun'ichi Amari in 1972^[2]^[3] and with respect\nto biological neural networks by William Little in 1974,^[4] and were\npopularised by John Hopfield in 1982.^[5] Hopfield networks serve as content-\naddressable (\"associative\") memory systems with binary threshold nodes, or\nwith continuous variables.^[6] Hopfield networks also provide a model for\nunderstanding human memory.^[7]^[8]\n\n## Origins[edit]\n\nThe Ising model itself was published in 1920s as a model of magnetism, however\nit studied at the thermal equilibrium, which does not change with time.\nGlauber in 1963 studied the Ising model evolving in time, as a process towards\nthermal equilibrium (Glauber dynamics).^[9]\n\nThe Ising model learning memory model was first proposed by Shun'ichi Amari in\n1972^[2] and then by William A. Little [de] in 1974,^[4] who was acknowledged\nby Hopfield in his 1982 paper. The Sherrington\u2013Kirkpatrick model of spin\nglass, published in 1975, is the Hopfield network with random initialization.\nSherrington and Kirkpatrick found that it is highly likely for the energy\nfunction of the SK model to have many local minima.^[5]\n\nNetworks with continuous dynamics were developed by Hopfield in his 1984\npaper.^[6] A major advance in memory storage capacity was developed by Krotov\nand Hopfield in 2016^[10] through a change in network dynamics and energy\nfunction. This idea was further extended by Demircigil and collaborators in\n2017.^[11] The continuous dynamics of large memory capacity models was\ndeveloped in a series of papers between 2016 and 2020.^[10]^[12]^[13] Large\nmemory storage capacity Hopfield Networks are now called Dense Associative\nMemories or modern Hopfield networks.\n\n## Structure[edit]\n\nA Hopfield net with four units\n\nThe units in Hopfield nets are binary threshold units, i.e. the units only\ntake on two different values for their states, and the value is determined by\nwhether or not the unit's input exceeds its threshold . Discrete Hopfield nets\ndescribe relationships between binary (firing or not-firing) neurons .^[5] At\na certain time, the state of the neural net is described by a vector , which\nrecords which neurons are firing in a binary word of bits.\n\nThe interactions between neurons have units that usually take on values of 1\nor \u22121, and this convention will be used throughout this article. However,\nother literature might use units that take values of 0 and 1. These\ninteractions are \"learned\" via Hebb's law of association, such that, for a\ncertain state and distinct nodes\n\nbut .\n\n(Note that the Hebbian learning rule takes the form when the units assume\nvalues in .)\n\nOnce the network is trained, no longer evolve. If a new state of neurons is\nintroduced to the neural network, the net acts on neurons such that\n\n  * if\n  * if\n\nwhere is the threshold value of the i'th neuron (often taken to be 0).^[14] In\nthis way, Hopfield networks have the ability to \"remember\" states stored in\nthe interaction matrix, because if a new state is subjected to the interaction\nmatrix, each neuron will change until it matches the original state (see the\nUpdates section below).\n\nThe connections in a Hopfield net typically have the following restrictions:\n\n  * (no unit has a connection with itself)\n  * (connections are symmetric)\n\nThe constraint that weights are symmetric guarantees that the energy function\ndecreases monotonically while following the activation rules.^[15] A network\nwith asymmetric weights may exhibit some periodic or chaotic behaviour;\nhowever, Hopfield found that this behavior is confined to relatively small\nparts of the phase space and does not impair the network's ability to act as a\ncontent-addressable associative memory system.\n\nHopfield also modeled neural nets for continuous values, in which the electric\noutput of each neuron is not binary but some value between 0 and 1.^[6] He\nfound that this type of network was also able to store and reproduce memorized\nstates.\n\nNotice that every pair of units i and j in a Hopfield network has a connection\nthat is described by the connectivity weight . In this sense, the Hopfield\nnetwork can be formally described as a complete undirected graph , where is a\nset of McCulloch\u2013Pitts neurons and is a function that links pairs of units to\na real value, the connectivity weight.\n\n## Updating[edit]\n\nUpdating one unit (node in the graph simulating the artificial neuron) in the\nHopfield network is performed using the following rule:\n\nwhere:\n\n  * is the strength of the connection weight from unit j to unit i (the weight of the connection).\n  * is the state of unit i.\n  * is the threshold of unit i.\n\nUpdates in the Hopfield network can be performed in two different ways:\n\n  * Asynchronous: Only one unit is updated at a time. This unit can be picked at random, or a pre-defined order can be imposed from the very beginning.\n  * Synchronous: All units are updated at the same time. This requires a central clock to the system in order to maintain synchronization. This method is viewed by some as less realistic, based on an absence of observed global clock influencing analogous biological or physical systems of interest.\n\n### Neurons \"attract or repel each other\" in state space[edit]\n\nThe weight between two units has a powerful impact upon the values of the\nneurons. Consider the connection weight between two neurons i and j. If , the\nupdating rule implies that:\n\n  * when , the contribution of j in the weighted sum is positive. Thus, is pulled by j towards its value\n  * when , the contribution of j in the weighted sum is negative. Then again, is pushed by j towards its value\n\nThus, the values of neurons i and j will converge if the weight between them\nis positive. Similarly, they will diverge if the weight is negative.\n\n## Working principles of discrete and continuous Hopfield networks[edit]\n\nBruck shed light on the behavior of a neuron in the discrete Hopfield network\nwhen proving its convergence in his paper in 1990.^[16] A subsequent\npaper^[17] further investigated the behavior of any neuron in both discrete-\ntime and continuous-time Hopfield networks when the corresponding energy\nfunction is minimized during an optimization process. Bruck shows^[16] that\nneuron j changes its state if and only if it further decreases the following\nbiased pseudo-cut. The discrete Hopfield network minimizes the following\nbiased pseudo-cut^[17] for the synaptic weight matrix of the Hopfield net.\n\nwhere and represents the set of neurons which are \u22121 and +1, respectively, at\ntime . For further details, see the recent paper.^[17]\n\nThe discrete-time Hopfield Network always minimizes exactly the following\npseudo-cut^[16]^[17]\n\nThe continuous-time Hopfield network always minimizes an upper bound to the\nfollowing weighted cut^[17]\n\nwhere is a zero-centered sigmoid function.\n\nThe complex Hopfield network, on the other hand, generally tends to minimize\nthe so-called shadow-cut of the complex weight matrix of the net.^[18]\n\n## Energy[edit]\n\nEnergy Landscape of a Hopfield Network, highlighting the current state of the\nnetwork (up the hill), an attractor state to which it will eventually\nconverge, a minimum energy level and a basin of attraction shaded in green.\nNote how the update of the Hopfield Network is always going down in Energy.\n\nHopfield nets have a scalar value associated with each state of the network,\nreferred to as the \"energy\", E, of the network, where:\n\nThis quantity is called \"energy\" because it either decreases or stays the same\nupon network units being updated. Furthermore, under repeated updating the\nnetwork will eventually converge to a state which is a local minimum in the\nenergy function (which is considered to be a Lyapunov function).^[5] Thus, if\na state is a local minimum in the energy function it is a stable state for the\nnetwork. Note that this energy function belongs to a general class of models\nin physics under the name of Ising models; these in turn are a special case of\nMarkov networks, since the associated probability measure, the Gibbs measure,\nhas the Markov property.\n\n## Hopfield network in optimization[edit]\n\nHopfield and Tank presented the Hopfield network application in solving the\nclassical traveling-salesman problem in 1985.^[19] Since then, the Hopfield\nnetwork has been widely used for optimization. The idea of using the Hopfield\nnetwork in optimization problems is straightforward: If a\nconstrained/unconstrained cost function can be written in the form of the\nHopfield energy function E, then there exists a Hopfield network whose\nequilibrium points represent solutions to the constrained/unconstrained\noptimization problem. Minimizing the Hopfield energy function both minimizes\nthe objective function and satisfies the constraints also as the constraints\nare \u201cembedded\u201d into the synaptic weights of the network. Although including\nthe optimization constraints into the synaptic weights in the best possible\nway is a challenging task, many difficult optimization problems with\nconstraints in different disciplines have been converted to the Hopfield\nenergy function: Associative memory systems, Analog-to-Digital conversion,\njob-shop scheduling problem, quadratic assignment and other related NP-\ncomplete problems, channel allocation problem in wireless networks, mobile ad-\nhoc network routing problem, image restoration, system identification,\ncombinatorial optimization, etc, just to name a few. Further details can be\nfound in e.g. the paper.^[17]\n\n## Initialization and running[edit]\n\nInitialization of the Hopfield networks is done by setting the values of the\nunits to the desired start pattern. Repeated updates are then performed until\nthe network converges to an attractor pattern. Convergence is generally\nassured, as Hopfield proved that the attractors of this nonlinear dynamical\nsystem are stable, not periodic or chaotic as in some other systems^[citation\nneeded]. Therefore, in the context of Hopfield networks, an attractor pattern\nis a final stable state, a pattern that cannot change any value within it\nunder updating^[citation needed].\n\n## Training[edit]\n\nTraining a Hopfield net involves lowering the energy of states that the net\nshould \"remember\". This allows the net to serve as a content addressable\nmemory system, that is to say, the network will converge to a \"remembered\"\nstate if it is given only part of the state. The net can be used to recover\nfrom a distorted input to the trained state that is most similar to that\ninput. This is called associative memory because it recovers memories on the\nbasis of similarity. For example, if we train a Hopfield net with five units\nso that the state (1, \u22121, 1, \u22121, 1) is an energy minimum, and we give the\nnetwork the state (1, \u22121, \u22121, \u22121, 1) it will converge to (1, \u22121, 1, \u22121, 1).\nThus, the network is properly trained when the energy of states which the\nnetwork should remember are local minima. Note that, in contrast to Perceptron\ntraining, the thresholds of the neurons are never updated.\n\n### Learning rules[edit]\n\nThere are various different learning rules that can be used to store\ninformation in the memory of the Hopfield network. It is desirable for a\nlearning rule to have both of the following two properties:\n\n  * Local: A learning rule is local if each weight is updated using information available to neurons on either side of the connection that is associated with that particular weight.\n  * Incremental: New patterns can be learned without using information from the old patterns that have been also used for training. That is, when a new pattern is used for training, the new values for the weights only depend on the old values and on the new pattern.^[20]\n\nThese properties are desirable, since a learning rule satisfying them is more\nbiologically plausible. For example, since the human brain is always learning\nnew concepts, one can reason that human learning is incremental. A learning\nsystem that was not incremental would generally be trained only once, with a\nhuge batch of training data.\n\n### Hebbian learning rule for Hopfield networks[edit]\n\nHebbian theory was introduced by Donald Hebb in 1949 in order to explain\n\"associative learning,\" in which simultaneous activation of neuron cells leads\nto pronounced increases in synaptic strength between those cells.^[21] It is\noften summarized as \"Neurons that fire together wire together. Neurons that\nfire out of sync fail to link\".\n\nThe Hebbian rule is both local and incremental. For the Hopfield networks, it\nis implemented in the following manner when learning binary patterns:\n\nwhere represents bit i from pattern .\n\nIf the bits corresponding to neurons i and j are equal in pattern , then the\nproduct will be positive. This would, in turn, have a positive effect on the\nweight and the values of i and j will tend to become equal. The opposite\nhappens if the bits corresponding to neurons i and j are different.\n\n### Storkey learning rule[edit]\n\nThis rule was introduced by Amos Storkey in 1997 and is both local and\nincremental. Storkey also showed that a Hopfield network trained using this\nrule has a greater capacity than a corresponding network trained using the\nHebbian rule.^[22] The weight matrix of an attractor neural\nnetwork^[clarification needed] is said to follow the Storkey learning rule if\nit obeys:\n\nwhere is a form of local field^[20] at neuron i.\n\nThis learning rule is local, since the synapses take into account only neurons\nat their sides. The rule makes use of more information from the patterns and\nweights than the generalized Hebbian rule, due to the effect of the local\nfield.\n\n## Spurious patterns[edit]\n\nPatterns that the network uses for training (called retrieval states) become\nattractors of the system. Repeated updates would eventually lead to\nconvergence to one of the retrieval states. However, sometimes the network\nwill converge to spurious patterns (different from the training\npatterns).^[23] The energy in these spurious patterns is also a local minimum.\nFor each stored pattern x, the negation -x is also a spurious pattern.\n\nA spurious state can also be a linear combination of an odd number of\nretrieval states. For example, when using 3 patterns , one can get the\nfollowing spurious state:\n\nSpurious patterns that have an even number of states cannot exist, since they\nmight sum up to zero^[23]\n\n## Capacity[edit]\n\nThe Network capacity of the Hopfield network model is determined by neuron\namounts and connections within a given network. Therefore, the number of\nmemories that are able to be stored is dependent on neurons and connections.\nFurthermore, it was shown that the recall accuracy between vectors and nodes\nwas 0.138 (approximately 138 vectors can be recalled from storage for every\n1000 nodes) (Hertz et al., 1991). Therefore, it is evident that many mistakes\nwill occur if one tries to store a large number of vectors. When the Hopfield\nmodel does not recall the right pattern, it is possible that an intrusion has\ntaken place, since semantically related items tend to confuse the individual,\nand recollection of the wrong pattern occurs. Therefore, the Hopfield network\nmodel is shown to confuse one stored item with that of another upon retrieval.\nPerfect recalls and high capacity, >0.14, can be loaded in the network by\nStorkey learning method; ETAM,^[24]^[25] ETAM experiments also in.^[26]\nUlterior models inspired by the Hopfield network were later devised to raise\nthe storage limit and reduce the retrieval error rate, with some being capable\nof one-shot learning.^[27]\n\nThe storage capacity can be given as where is the number of neurons in the\nnet.\n\n## Human memory[edit]\n\nThe Hopfield model accounts for associative memory through the incorporation\nof memory vectors. Memory vectors can be slightly used, and this would spark\nthe retrieval of the most similar vector in the network. However, we will find\nout that due to this process, intrusions can occur. In associative memory for\nthe Hopfield network, there are two types of operations: auto-association and\nhetero-association. The first being when a vector is associated with itself,\nand the latter being when two different vectors are associated in storage.\nFurthermore, both types of operations are possible to store within a single\nmemory matrix, but only if that given representation matrix is not one or the\nother of the operations, but rather the combination (auto-associative and\nhetero-associative) of the two. It is important to note that Hopfield's\nnetwork model utilizes the same learning rule as Hebb's (1949) learning rule,\nwhich characterised learning as being a result of the strengthening of the\nweights in cases of neuronal activity.\n\nRizzuto and Kahana (2001) were able to show that the neural network model can\naccount for repetition on recall accuracy by incorporating a probabilistic-\nlearning algorithm. During the retrieval process, no learning occurs. As a\nresult, the weights of the network remain fixed, showing that the model is\nable to switch from a learning stage to a recall stage. By adding contextual\ndrift they were able to show the rapid forgetting that occurs in a Hopfield\nmodel during a cued-recall task. The entire network contributes to the change\nin the activation of any single node.\n\nMcCulloch and Pitts' (1943) dynamical rule, which describes the behavior of\nneurons, does so in a way that shows how the activations of multiple neurons\nmap onto the activation of a new neuron's firing rate, and how the weights of\nthe neurons strengthen the synaptic connections between the new activated\nneuron (and those that activated it). Hopfield would use McCulloch\u2013Pitts's\ndynamical rule in order to show how retrieval is possible in the Hopfield\nnetwork. However, it is important to note that Hopfield would do so in a\nrepetitious fashion. Hopfield would use a nonlinear activation function,\ninstead of using a linear function. This would therefore create the Hopfield\ndynamical rule and with this, Hopfield was able to show that with the\nnonlinear activation function, the dynamical rule will always modify the\nvalues of the state vector in the direction of one of the stored patterns.\n\n## Dense associative memory or modern Hopfield network[edit]\n\nHopfield networks^[5]^[6] are recurrent neural networks with dynamical\ntrajectories converging to fixed point attractor states and described by an\nenergy function. The state of each model neuron is defined by a time-dependent\nvariable , which can be chosen to be either discrete or continuous. A complete\nmodel describes the mathematics of how the future state of activity of each\nneuron depends on the known present or previous activity of all the neurons.\n\nIn the original Hopfield model of associative memory,^[5] the variables were\nbinary, and the dynamics were described by a one-at-a-time update of the state\nof the neurons. An energy function quadratic in the was defined, and the\ndynamics consisted of changing the activity of each single neuron only if\ndoing so would lower the total energy of the system. This same idea was\nextended to the case of being a continuous variable representing the output of\nneuron , and being a monotonic function of an input current. The dynamics\nbecame expressed as a set of first-order differential equations for which the\n\"energy\" of the system always decreased.^[6] The energy in the continuous case\nhas one term which is quadratic in the (as in the binary model), and a second\nterm which depends on the gain function (neuron's activation function). While\nhaving many desirable properties of associative memory, both of these\nclassical systems suffer from a small memory storage capacity, which scales\nlinearly with the number of input features.^[5]\n\nDense Associative Memories^[10] (also known as the modern Hopfield\nnetworks^[12]) are generalizations of the classical Hopfield Networks that\nbreak the linear scaling relationship between the number of input features and\nthe number of stored memories. This is achieved by introducing stronger non-\nlinearities (either in the energy function or neurons\u2019 activation functions)\nleading to super-linear^[10] (even an exponential^[11]) memory storage\ncapacity as a function of the number of feature neurons. The network still\nrequires a sufficient number of hidden neurons.^[13]\n\nThe key theoretical idea behind the modern Hopfield networks is to use an\nenergy function and an update rule that is more sharply peaked around the\nstored memories in the space of neuron\u2019s configurations compared to the\nclassical Hopfield Network.^[10]\n\n### Discrete variables[edit]\n\nA simple example^[10] of the modern Hopfield network can be written in terms\nof binary variables that represent the active and inactive state of the model\nneuron .\n\nIn this formula the weights represent the matrix of memory vectors (index\nenumerates different memories, and index enumerates the content of each memory\ncorresponding to the -th feature neuron), and the function is a rapidly\ngrowing non-linear function. The update rule for individual neurons (in the\nasynchronous case) can be written in the following form\n\nwhich states that in order to calculate the updated state of the -th neuron\nthe network compares two energies: the energy of the network with the -th\nneuron in the ON state and the energy of the network with the -th neuron in\nthe OFF state, given the states of the remaining neuron. The updated state of\nthe -th neuron selects the state that has the lowest of the two energies.^[10]\n\nIn the limiting case when the non-linear energy function is quadratic these\nequations reduce to the familiar energy function and the update rule for the\nclassical binary Hopfield Network.^[5]\n\nThe memory storage capacity of these networks can be calculated for random\nbinary patterns. For the power energy function the maximal number of memories\nthat can be stored and retrieved from this network without errors is given\nby^[10]\n\nFor an exponential energy function the memory storage capacity is exponential\nin the number of feature neurons^[11]\n\nFig. 1: An example of a continuous modern Hopfield network with feature\nneurons and memory (hidden) neurons with symmetric synaptic connections\nbetween them.\n\n### Continuous variables[edit]\n\nModern Hopfield networks or dense associative memories can be best understood\nin continuous variables and continuous time.^[12]^[13] Consider the network\narchitecture, shown in Fig.1, and the equations for neuron's states\nevolution^[13]\n\n    (1)  \n---  \n  \nwhere the currents of the feature neurons are denoted by , and the currents of\nthe memory neurons are denoted by ( stands for hidden neurons). There are no\nsynaptic connections among the feature neurons or the memory neurons. A matrix\ndenotes the strength of synapses from a feature neuron to the memory neuron .\nThe synapses are assumed to be symmetric, so that the same value characterizes\na different physical synapse from the memory neuron to the feature neuron .\nThe outputs of the memory neurons and the feature neurons are denoted by and ,\nwhich are non-linear functions of the corresponding currents. In general these\noutputs can depend on the currents of all the neurons in that layer so that\nand . It is convenient to define these activation functions as derivatives of\nthe Lagrangian functions for the two groups of neurons\n\n    (2)  \n---  \n  \nThis way the specific form of the equations for neuron's states is completely\ndefined once the Lagrangian functions are specified. Finally, the time\nconstants for the two groups of neurons are denoted by and , is the input\ncurrent to the network that can be driven by the presented data.\n\nFig. 2: Effective theory on the feature neurons for various common choices of\nthe Lagrangian functions. Model A reduces to the models studied in^[10]^[11]\ndepending on the choice of the activation function, model B reduces to the\nmodel studied in,^[12] model C reduces to the model of.^[13] F is a \"smooth\nenough\" function.^[10]\n\nGeneral systems of non-linear differential equations can have many complicated\nbehaviors that can depend on the choice of the non-linearities and the initial\nconditions. For Hopfield Networks, however, this is not the case - the\ndynamical trajectories always converge to a fixed point attractor state. This\nproperty is achieved because these equations are specifically engineered so\nthat they have an underlying energy function^[13]\n\n    (3)  \n---  \n  \nThe terms grouped into square brackets represent a Legendre transform of the\nLagrangian function with respect to the states of the neurons. If the Hessian\nmatrices of the Lagrangian functions are positive semi-definite, the energy\nfunction is guaranteed to decrease on the dynamical trajectory^[13]\n\n    (4)  \n---  \n  \nThis property makes it possible to prove that the system of dynamical\nequations describing temporal evolution of neurons' activities will eventually\nreach a fixed point attractor state.\n\nIn certain situations one can assume that the dynamics of hidden neurons\nequilibrates at a much faster time scale compared to the feature neurons, . In\nthis case the steady state solution of the second equation in the system (1)\ncan be used to express the currents of the hidden units through the outputs of\nthe feature neurons. This makes it possible to reduce the general theory (1)\nto an effective theory for feature neurons only. The resulting effective\nupdate rules and the energies for various common choices of the Lagrangian\nfunctions are shown in Fig.2. In the case of log-sum-exponential Lagrangian\nfunction the update rule (if applied once) for the states of the feature\nneurons is the attention mechanism^[12] commonly used in many modern AI\nsystems (see Ref.^[13] for the derivation of this result from the continuous\ntime formulation).\n\n### Relationship to classical Hopfield network with continuous variables[edit]\n\nClassical formulation of continuous Hopfield Networks^[6] can be\nunderstood^[13] as a special limiting case of the modern Hopfield networks\nwith one hidden layer. Continuous Hopfield Networks for neurons with graded\nresponse are typically described^[6] by the dynamical equations\n\n    (5)  \n---  \n  \nand the energy function\n\n    (6)  \n---  \n  \nwhere , and is the inverse of the activation function . This model is a\nspecial limit of the class of models that is called models A,^[13] with the\nfollowing choice of the Lagrangian functions\n\n    (7)  \n---  \n  \nthat, according to the definition (2), leads to the activation functions\n\n    (8)  \n---  \n  \nIf we integrate out the hidden neurons the system of equations (1) reduces to\nthe equations on the feature neurons (5) with , and the general expression for\nthe energy (3) reduces to the effective energy\n\n    (9)  \n---  \n  \nWhile the first two terms in equation (6) are the same as those in equation\n(9), the third terms look superficially different. In equation (9) it is a\nLegendre transform of the Lagrangian for the feature neurons, while in (6) the\nthird term is an integral of the inverse activation function. Nevertheless,\nthese two expressions are in fact equivalent, since the derivatives of a\nfunction and its Legendre transform are inverse functions of each other. The\neasiest way to see that these two terms are equal explicitly is to\ndifferentiate each one with respect to . The results of these differentiations\nfor both expressions are equal to . Thus, the two expressions are equal up to\nan additive constant. This completes the proof^[13] that the classical\nHopfield Network with continuous states^[6] is a special limiting case of the\nmodern Hopfield network (1) with energy (3).\n\n### General formulation of the modern Hopfield network[edit]\n\nFig. 3: The connectivity diagram of the fully-connected modern Hopfield\nnetwork consisting of five neurons. The synaptic weights are described by a\nsymmetric matrix .\n\nBiological neural networks have a large degree of heterogeneity in terms of\ndifferent cell types. This section describes a mathematical model of a fully\nconnected modern Hopfield network assuming the extreme degree of\nheterogeneity: every single neuron is different.^[28] Specifically, an energy\nfunction and the corresponding dynamical equations are described assuming that\neach neuron has its own activation function and kinetic time scale. The\nnetwork is assumed to be fully connected, so that every neuron is connected to\nevery other neuron using a symmetric matrix of weights , indices and enumerate\ndifferent neurons in the network, see Fig.3. The easiest way to mathematically\nformulate this problem is to define the architecture through a Lagrangian\nfunction that depends on the activities of all the neurons in the network. The\nactivation function for each neuron is defined as a partial derivative of the\nLagrangian with respect to that neuron's activity\n\n    (10)  \n---  \n  \nFrom the biological perspective one can think about as an axonal output of the\nneuron . In the simplest case, when the Lagrangian is additive for different\nneurons, this definition results in the activation that is a non-linear\nfunction of that neuron's activity. For non-additive Lagrangians this\nactivation function can depend on the activities of a group of neurons. For\ninstance, it can contain contrastive (softmax) or divisive normalization. The\ndynamical equations describing temporal evolution of a given neuron are given\nby^[28]\n\n    (11)  \n---  \n  \nThis equation belongs to the class of models called firing rate models in\nneuroscience. Each neuron collects the axonal outputs from all the neurons,\nweights them with the synaptic coefficients and produces its own time-\ndependent activity . The temporal evolution has a time constant , which in\ngeneral can be different for every neuron. This network has a global energy\nfunction^[28]\n\n    (12)  \n---  \n  \nwhere the first two terms represent the Legendre transform of the Lagrangian\nfunction with respect to the neurons' currents . The temporal derivative of\nthis energy function can be computed on the dynamical trajectories leading to\n(see ^[28] for details)\n\n    (13)  \n---  \n  \nThe last inequality sign holds provided that the matrix (or its symmetric\npart) is positive semi-definite. If, in addition to this, the energy function\nis bounded from below the non-linear dynamical equations are guaranteed to\nconverge to a fixed point attractor state. The advantage of formulating this\nnetwork in terms of the Lagrangian functions is that it makes it possible to\neasily experiment with different choices of the activation functions and\ndifferent architectural arrangements of neurons. For all those flexible\nchoices the conditions of convergence are determined by the properties of the\nmatrix and the existence of the lower bound on the energy function.\n\nFig. 4: The connectivity diagram of the layered Hierarchical Associative\nMemory network.^[28] Each layer can have different number of neurons,\ndifferent activation function, and different time scales. The feedforward\nweights and feedback weights are equal.\n\n### Hierarchical associative memory network[edit]\n\nThe neurons can be organized in layers so that every neuron in a given layer\nhas the same activation function and the same dynamic time scale. If we assume\nthat there are no horizontal connections between the neurons within the layer\n(lateral connections) and there are no skip-layer connections, the general\nfully connected network (11), (12) reduces to the architecture shown in Fig.4.\nIt has layers of recurrently connected neurons with the states described by\ncontinuous variables and the activation functions , index enumerates the\nlayers of the network, and index enumerates individual neurons in that layer.\nThe activation functions can depend on the activities of all the neurons in\nthe layer. Every layer can have a different number of neurons . These neurons\nare recurrently connected with the neurons in the preceding and the subsequent\nlayers. The matrices of weights that connect neurons in layers and are denoted\nby (the order of the upper indices for weights is the same as the order of the\nlower indices, in the example above this means that the index enumerates\nneurons in the layer , and index enumerates neurons in the layer ). The\nfeedforward weights and the feedback weights are equal. The dynamical\nequations for the neurons' states can be written as^[28]\n\n    (14)  \n---  \n  \nwith boundary conditions\n\n    (15)  \n---  \n  \nThe main difference between these equations and those from the conventional\nfeedforward networks is the presence of the second term, which is responsible\nfor the feedback from higher layers. These top-down signals help neurons in\nlower layers to decide on their response to the presented stimuli. Following\nthe general recipe it is convenient to introduce a Lagrangian function for the\n-th hidden layer, which depends on the activities of all the neurons in that\nlayer.^[28] The activation functions in that layer can be defined as partial\nderivatives of the Lagrangian\n\n    (16)  \n---  \n  \nWith these definitions the energy (Lyapunov) function is given by^[28]\n\n    (17)  \n---  \n  \nIf the Lagrangian functions, or equivalently the activation functions, are\nchosen in such a way that the Hessians for each layer are positive semi-\ndefinite and the overall energy is bounded from below, this system is\nguaranteed to converge to a fixed point attractor state. The temporal\nderivative of this energy function is given by^[28]\n\n    (18)  \n---  \n  \nThus, the hierarchical layered network is indeed an attractor network with the\nglobal energy function. This network is described by a hierarchical set of\nsynaptic weights that can be learned for each specific problem.\n\n## See also[edit]\n\n  * Associative memory (disambiguation)\n  * Autoassociative memory\n  * Boltzmann machine \u2013 like a Hopfield net but uses annealed Gibbs sampling instead of gradient descent\n  * Dynamical systems model of cognition\n  * Ising model\n  * Hebbian theory\n\n## References[edit]\n\n  1. ^ Brush, Stephen G. (1967). \"History of the Lenz-Ising Model\". Reviews of Modern Physics. 39 (4): 883\u2013893. Bibcode:1967RvMP...39..883B. doi:10.1103/RevModPhys.39.883.\n  2. ^ Jump up to: ^a ^b Amari, Shun-Ichi (1972). \"Learning patterns and pattern sequences by self-organizing nets of threshold elements\". IEEE Transactions. C (21): 1197\u20131206.\n  3. ^ Schmidhuber, Juergen (2022). \"Annotated History of Modern AI and Deep Learning\". arXiv:2212.11279 [cs.NE].\n  4. ^ Jump up to: ^a ^b Little, W. A. (1974). \"The Existence of Persistent States in the Brain\". Mathematical Biosciences. 19 (1\u20132): 101\u2013120. doi:10.1016/0025-5564(74)90031-5.\n  5. ^ Jump up to: ^a ^b ^c ^d ^e ^f ^g ^h Hopfield, J. J. (1982). \"Neural networks and physical systems with emergent collective computational abilities\". Proceedings of the National Academy of Sciences. 79 (8): 2554\u20132558. Bibcode:1982PNAS...79.2554H. doi:10.1073/pnas.79.8.2554. PMC 346238. PMID 6953413.\n  6. ^ Jump up to: ^a ^b ^c ^d ^e ^f ^g ^h Hopfield, J. J. (1984). \"Neurons with graded response have collective computational properties like those of two-state neurons\". Proceedings of the National Academy of Sciences. 81 (10): 3088\u20133092. Bibcode:1984PNAS...81.3088H. doi:10.1073/pnas.81.10.3088. PMC 345226. PMID 6587342.\n  7. ^ Amit, D.J. (1992). Modeling Brain Function: The World of Attractor Neural Networks. Cambridge University Press. ISBN 978-0-521-42124-9.\n  8. ^ Rolls, Edmund T. (2016). Cerebral Cortex: Principles of Operation. Oxford University Press. ISBN 978-0-19-878485-2.\n  9. ^ Glauber, Roy J. (February 1963). \"Roy J. Glauber \"Time\u2010Dependent Statistics of the Ising Model\"\". Journal of Mathematical Physics. 4 (2): 294\u2013307. doi:10.1063/1.1703954. Retrieved 2021-03-21.\n  10. ^ Jump up to: ^a ^b ^c ^d ^e ^f ^g ^h ^i ^j Krotov, Dmitry; Hopfield, John (2016). \"Dense Associative Memory for Pattern Recognition\". Neural Information Processing Systems. 29: 1172\u20131180. arXiv:1606.01164.\n  11. ^ Jump up to: ^a ^b ^c ^d Mete, Demircigil; et al. (2017). \"On a model of associative memory with huge storage capacity\". Journal of Statistical Physics. 168 (2): 288\u2013299. arXiv:1702.01929. Bibcode:2017JSP...168..288D. doi:10.1007/s10955-017-1806-y. S2CID 119317128.\n  12. ^ Jump up to: ^a ^b ^c ^d ^e Ramsauer, Hubert; et al. (2021). \"Hopfield Networks is All You Need\". International Conference on Learning Representations. arXiv:2008.02217.\n  13. ^ Jump up to: ^a ^b ^c ^d ^e ^f ^g ^h ^i ^j ^k Krotov, Dmitry; Hopfield, John (2021). \"Large associative memory problem in neurobiology and machine learning\". International Conference on Learning Representations. arXiv:2008.06996.\n  14. ^ Hopfield, J. J. (1982). \"Neural networks and physical systems with emergent collective computational abilities\". Proceedings of the National Academy of Sciences. 79 (8): 2554\u20132558. Bibcode:1982PNAS...79.2554H. doi:10.1073/pnas.79.8.2554. PMC 346238. PMID 6953413.\n  15. ^ MacKay, David J. C. (2003). \"42. Hopfield Networks\". Information Theory, Inference and Learning Algorithms. Cambridge University Press. p. 508. ISBN 978-0521642989. \"This convergence proof depends crucially on the fact that the Hopfield network's connections are symmetric. It also depends on the updates being made asynchronously.\"\n  16. ^ Jump up to: ^a ^b ^c Bruck, J. (October 1990). \"On the convergence properties of the Hopfield model\". Proc. IEEE. 78 (10): 1579\u201385. doi:10.1109/5.58341.\n  17. ^ Jump up to: ^a ^b ^c ^d ^e ^f Uykan, Z. (September 2020). \"On the Working Principle of the Hopfield Neural Networks and its Equivalence to the GADIA in Optimization\". IEEE Transactions on Neural Networks and Learning Systems. 31 (9): 3294\u20133304. doi:10.1109/TNNLS.2019.2940920. PMID 31603804. S2CID 204331533.\n  18. ^ Uykan, Z. (March 2021). \"Shadow-Cuts Minimization/Maximization and Complex Hopfield Neural Networks\". IEEE Transactions on Neural Networks and Learning Systems. 32 (3): 1096\u20131109. doi:10.1109/TNNLS.2020.2980237. PMID 32310787. S2CID 216047831.\n  19. ^ Hopfield, J.J.; Tank, D.W. (1985). \"Neural computation of decisions in optimization problems\". Biological Cybernetics. 52 (3): 141\u20136. doi:10.1007/BF00339943. PMID 4027280. S2CID 36483354.\n  20. ^ Jump up to: ^a ^b Storkey, A.J.; Valabregue, R. (1999). \"The basins of attraction of a new Hopfield learning rule\". Neural Networks. 12 (6): 869\u2013876. CiteSeerX 10.1.1.19.4681. doi:10.1016/S0893-6080(99)00038-6. PMID 12662662.\n  21. ^ Hebb 1949\n  22. ^ Storkey, Amos (1997). \"Increasing the capacity of a Hopfield network without sacrificing functionality\". Artificial Neural Networks \u2013 ICANN'97. Lecture Notes in Computer Science. Vol. 1327. Springer. pp. 451\u20136. CiteSeerX 10.1.1.33.103. doi:10.1007/BFb0020196. ISBN 978-3-540-69620-9.\n  23. ^ Jump up to: ^a ^b Hertz 1991\n  24. ^ Liou, C.-Y.; Lin, S.-L. (2006). \"Finite memory loading in hairy neurons\" (PDF). Natural Computing. 5 (1): 15\u201342. doi:10.1007/s11047-004-5490-x. S2CID 35025761.\n  25. ^ Liou, C.-Y.; Yuan, S.-K. (1999). \"Error Tolerant Associative Memory\". Biological Cybernetics. 81 (4): 331\u2013342. doi:10.1007/s004220050566. PMID 10541936. S2CID 6168346.\n  26. ^ Yuan, S.-K. (June 1997). Expanding basins of attraction of the associative memory (Master thesis). National Taiwan University. 991010725609704786.\n  27. ^ ABOUDIB, Ala; GRIPON, Vincent; JIANG, Xiaoran (2014). \"A study of retrieval algorithms of sparse messages in networks of neural cliques\". COGNITIVE 2014 : The 6th International Conference on Advanced Cognitive Technologies and Applications. pp. 140\u20136. arXiv:1308.4506. Bibcode:2013arXiv1308.4506A.\n  28. ^ Jump up to: ^a ^b ^c ^d ^e ^f ^g ^h ^i Krotov, Dmitry (2021). \"Hierarchical Associative Memory\". arXiv:2107.06446 [cs.NE].\n\n  * Hebb, D.O. (2005) [1949]. The Organization of Behavior: A Neuropsychological Theory. Psychology Press. ISBN 978-1-135-63190-1.\n  * Hertz, John A. (2018) [1991]. Introduction To The Theory Of Neural Computation. CRC Press. ISBN 978-0-429-96821-1.\n  * McCulloch, W.S.; Pitts, W.H. (1943). \"A logical calculus of the ideas immanent in nervous activity\". Bulletin of Mathematical Biophysics. 5 (4): 115\u2013133. doi:10.1007/BF02478259.\n  * Polyn, S.M.; Kahana, M.J. (2008). \"Memory search and the neural representation of context\". Trends in Cognitive Sciences. 12 (1): 24\u201330. doi:10.1016/j.tics.2007.10.010. PMC 2839453. PMID 18069046.\n  * Rizzuto, D.S.; Kahana, M.J. (2001). \"An autoassociative neural network model of paired-associate learning\". Neural Computation. 13 (9): 2075\u20132092. CiteSeerX 10.1.1.45.7929. doi:10.1162/089976601750399317. PMID 11516358. S2CID 7675117.\n  * Kruse, Rudolf; Borgelt, Christian; Klawonn, Frank; Moewes, Christian; Steinbrecher, Matthias; Held, Pascal (2013). Computational Intelligence: A Methodological Introduction. Springer. ISBN 978-1-4471-5013-8.\n\n## External links[edit]\n\nWikimedia Commons has media related to Hopfield net.\n\n  * Rojas, Raul (12 July 1996). \"13. The Hopfield model\" (PDF). Neural Networks \u2013 A Systematic Introduction. Springer. ISBN 978-3-540-60505-8.\n  * Hopfield Network Javascript\n  * The Travelling Salesman Problem Archived 2015-05-30 at the Wayback Machine \u2013 Hopfield Neural Network JAVA Applet\n  * Hopfield, John (2007). \"Hopfield network\". Scholarpedia. 2 (5): 1977. Bibcode:2007SchpJ...2.1977H. doi:10.4249/scholarpedia.1977.\n  * Fletcher, Tristan. \"Hopfield Network Learning Using Deterministic Latent Variables\" (PDF) (Tutorial). Archived from the original (PDF) on 2011-10-05.\n\n  * v\n  * t\n  * e\n\nDifferentiable computing  \n---  \nGeneral|\n\n  * Differentiable programming\n  * Information geometry\n  * Statistical manifold\n  * Automatic differentiation\n  * Neuromorphic engineering\n  * Pattern recognition\n  * Tensor calculus\n  * Computational learning theory\n  * Inductive bias\n\n  \nConcepts|\n\n  * Gradient descent\n    * SGD\n  * Clustering\n  * Regression\n    * Overfitting\n  * Hallucination\n  * Adversary\n  * Attention\n  * Convolution\n  * Loss functions\n  * Backpropagation\n  * Batchnorm\n  * Activation\n    * Softmax\n    * Sigmoid\n    * Rectifier\n  * Regularization\n  * Datasets\n    * Augmentation\n  * Diffusion\n  * Autoregression\n\n  \nApplications|\n\n  * Machine learning\n    * In-context learning\n  * Artificial neural network\n    * Deep learning\n  * Scientific computing\n  * Artificial Intelligence\n  * Language model\n    * Large language model\n\n  \nHardware|\n\n  * IPU\n  * TPU\n  * VPU\n  * Memristor\n  * SpiNNaker\n\n  \nSoftware libraries|\n\n  * TensorFlow\n  * PyTorch\n  * Keras\n  * Theano\n  * JAX\n  * Flux.jl\n  * MindSpore\n\n  \nImplementations| | Audio\u2013visual| \n\n  * AlexNet\n  * WaveNet\n  * Human image synthesis\n  * HWR\n  * OCR\n  * Speech synthesis\n  * Speech recognition\n  * Facial recognition\n  * AlphaFold\n  * Text-to-image models\n    * DALL-E\n    * Midjourney\n    * Stable Diffusion\n  * Text-to-video models\n    * Sora\n    * VideoPoet\n  * Whisper\n\n  \n---|---  \nVerbal|\n\n  * Word2vec\n  * Seq2seq\n  * BERT\n  * Gemini\n  * LaMDA\n    * Bard\n  * NMT\n  * Project Debater\n  * IBM Watson\n  * IBM Watsonx\n  * Granite\n  * GPT-1\n  * GPT-2\n  * GPT-3\n  * GPT-4\n  * ChatGPT\n  * GPT-J\n  * Chinchilla AI\n  * PaLM\n  * BLOOM\n  * LLaMA\n  * PanGu-\u03a3\n\n  \nDecisional|\n\n  * AlphaGo\n  * AlphaZero\n  * Q-learning\n  * SARSA\n  * OpenAI Five\n  * Self-driving car\n  * MuZero\n  * Action selection\n    * Auto-GPT\n  * Robot control\n\n  \nPeople|\n\n  * Yoshua Bengio\n  * Alex Graves\n  * Ian Goodfellow\n  * Stephen Grossberg\n  * Demis Hassabis\n  * Geoffrey Hinton\n  * Yann LeCun\n  * Fei-Fei Li\n  * Andrew Ng\n  * J\u00fcrgen Schmidhuber\n  * David Silver\n  * Ilya Sutskever\n\n  \nOrganizations|\n\n  * Anthropic\n  * EleutherAI\n  * Google DeepMind\n  * Hugging Face\n  * OpenAI\n  * Meta AI\n  * Mila\n  * MIT CSAIL\n  * Huawei\n\n  \nArchitectures|\n\n  * Neural Turing machine\n  * Differentiable neural computer\n  * Transformer\n  * Recurrent neural network (RNN)\n  * Long short-term memory (LSTM)\n  * Gated recurrent unit (GRU)\n  * Echo state network\n  * Multilayer perceptron (MLP)\n  * Convolutional neural network\n  * Residual neural network\n  * Mamba\n  * Autoencoder\n  * Variational autoencoder (VAE)\n  * Generative adversarial network (GAN)\n  * Graph neural network\n\n  \n  \n  * Portals\n    * Computer programming\n    * Technology\n  * Categories\n    * Artificial neural networks\n    * Machine learning\n\n  \n  \n  * v\n  * t\n  * e\n\nStochastic processes  \n---  \nDiscrete time|\n\n  * Bernoulli process\n  * Branching process\n  * Chinese restaurant process\n  * Galton\u2013Watson process\n  * Independent and identically distributed random variables\n  * Markov chain\n  * Moran process\n  * Random walk\n    * Loop-erased\n    * Self-avoiding\n    * Biased\n    * Maximal entropy\n\n  \nContinuous time|\n\n  * Additive process\n  * Bessel process\n  * Birth\u2013death process\n    * pure birth\n  * Brownian motion\n    * Bridge\n    * Excursion\n    * Fractional\n    * Geometric\n    * Meander\n  * Cauchy process\n  * Contact process\n  * Continuous-time random walk\n  * Cox process\n  * Diffusion process\n  * Dyson Brownian motion\n  * Empirical process\n  * Feller process\n  * Fleming\u2013Viot process\n  * Gamma process\n  * Geometric process\n  * Hawkes process\n  * Hunt process\n  * Interacting particle systems\n  * It\u00f4 diffusion\n  * It\u00f4 process\n  * Jump diffusion\n  * Jump process\n  * L\u00e9vy process\n  * Local time\n  * Markov additive process\n  * McKean\u2013Vlasov process\n  * Ornstein\u2013Uhlenbeck process\n  * Poisson process\n    * Compound\n    * Non-homogeneous\n  * Schramm\u2013Loewner evolution\n  * Semimartingale\n  * Sigma-martingale\n  * Stable process\n  * Superprocess\n  * Telegraph process\n  * Variance gamma process\n  * Wiener process\n  * Wiener sausage\n\n  \nBoth|\n\n  * Branching process\n  * Galves\u2013L\u00f6cherbach model\n  * Gaussian process\n  * Hidden Markov model (HMM)\n  * Markov process\n  * Martingale\n    * Differences\n    * Local\n    * Sub-\n    * Super-\n  * Random dynamical system\n  * Regenerative process\n  * Renewal process\n  * Stochastic chains with memory of variable length\n  * White noise\n\n  \nFields and other|\n\n  * Dirichlet process\n  * Gaussian random field\n  * Gibbs measure\n  * Hopfield model\n  * Ising model\n    * Potts model\n    * Boolean network\n  * Markov random field\n  * Percolation\n  * Pitman\u2013Yor process\n  * Point process\n    * Cox\n    * Poisson\n  * Random field\n  * Random graph\n\n  \nTime series models|\n\n  * Autoregressive conditional heteroskedasticity (ARCH) model\n  * Autoregressive integrated moving average (ARIMA) model\n  * Autoregressive (AR) model\n  * Autoregressive\u2013moving-average (ARMA) model\n  * Generalized autoregressive conditional heteroskedasticity (GARCH) model\n  * Moving-average (MA) model\n\n  \nFinancial models|\n\n  * Binomial options pricing model\n  * Black\u2013Derman\u2013Toy\n  * Black\u2013Karasinski\n  * Black\u2013Scholes\n  * Chan\u2013Karolyi\u2013Longstaff\u2013Sanders (CKLS)\n  * Chen\n  * Constant elasticity of variance (CEV)\n  * Cox\u2013Ingersoll\u2013Ross (CIR)\n  * Garman\u2013Kohlhagen\n  * Heath\u2013Jarrow\u2013Morton (HJM)\n  * Heston\n  * Ho\u2013Lee\n  * Hull\u2013White\n  * Korn-Kreer-Lenssen\n  * LIBOR market\n  * Rendleman\u2013Bartter\n  * SABR volatility\n  * Va\u0161\u00ed\u010dek\n  * Wilkie\n\n  \nActuarial models|\n\n  * B\u00fchlmann\n  * Cram\u00e9r\u2013Lundberg\n  * Risk process\n  * Sparre\u2013Anderson\n\n  \nQueueing models|\n\n  * Bulk\n  * Fluid\n  * Generalized queueing network\n  * M/G/1\n  * M/M/1\n  * M/M/c\n\n  \nProperties|\n\n  * C\u00e0dl\u00e0g paths\n  * Continuous\n  * Continuous paths\n  * Ergodic\n  * Exchangeable\n  * Feller-continuous\n  * Gauss\u2013Markov\n  * Markov\n  * Mixing\n  * Piecewise-deterministic\n  * Predictable\n  * Progressively measurable\n  * Self-similar\n  * Stationary\n  * Time-reversible\n\n  \nLimit theorems|\n\n  * Central limit theorem\n  * Donsker's theorem\n  * Doob's martingale convergence theorems\n  * Ergodic theorem\n  * Fisher\u2013Tippett\u2013Gnedenko theorem\n  * Large deviation principle\n  * Law of large numbers (weak/strong)\n  * Law of the iterated logarithm\n  * Maximal ergodic theorem\n  * Sanov's theorem\n  * Zero\u2013one laws (Blumenthal, Borel\u2013Cantelli, Engelbert\u2013Schmidt, Hewitt\u2013Savage, Kolmogorov, L\u00e9vy)\n\n  \nInequalities|\n\n  * Burkholder\u2013Davis\u2013Gundy\n  * Doob's martingale\n  * Doob's upcrossing\n  * Kunita\u2013Watanabe\n  * Marcinkiewicz\u2013Zygmund\n\n  \nTools|\n\n  * Cameron\u2013Martin formula\n  * Convergence of random variables\n  * Dol\u00e9ans-Dade exponential\n  * Doob decomposition theorem\n  * Doob\u2013Meyer decomposition theorem\n  * Doob's optional stopping theorem\n  * Dynkin's formula\n  * Feynman\u2013Kac formula\n  * Filtration\n  * Girsanov theorem\n  * Infinitesimal generator\n  * It\u00f4 integral\n  * It\u00f4's lemma\n  * Karhunen\u2013Lo\u00e8ve theorem\n  * Kolmogorov continuity theorem\n  * Kolmogorov extension theorem\n  * L\u00e9vy\u2013Prokhorov metric\n  * Malliavin calculus\n  * Martingale representation theorem\n  * Optional stopping theorem\n  * Prokhorov's theorem\n  * Quadratic variation\n  * Reflection principle\n  * Skorokhod integral\n  * Skorokhod's representation theorem\n  * Skorokhod space\n  * Snell envelope\n  * Stochastic differential equation\n    * Tanaka\n  * Stopping time\n  * Stratonovich integral\n  * Uniform integrability\n  * Usual hypotheses\n  * Wiener space\n    * Classical\n    * Abstract\n\n  \nDisciplines|\n\n  * Actuarial mathematics\n  * Control theory\n  * Econometrics\n  * Ergodic theory\n  * Extreme value theory (EVT)\n  * Large deviations theory\n  * Mathematical finance\n  * Mathematical statistics\n  * Probability theory\n  * Queueing theory\n  * Renewal theory\n  * Ruin theory\n  * Signal processing\n  * Statistics\n  * Stochastic analysis\n  * Time series analysis\n  * Machine learning\n\n  \n  \n  * List of topics\n  * Category\n\n  \n  \nRetrieved from\n\"https://en.wikipedia.org/w/index.php?title=Hopfield_network&oldid=1215466482\"\n\nCategory:\n\n  * Neural network architectures\n\nHidden categories:\n\n  * Articles with short description\n  * Short description is different from Wikidata\n  * All articles with unsourced statements\n  * Articles with unsourced statements from July 2019\n  * Wikipedia articles needing clarification from July 2019\n  * Commons link is on Wikidata\n  * Webarchive template wayback links\n\n  * This page was last edited on 25 March 2024, at 09:02 (UTC).\n  * Text is available under the Creative Commons Attribution-ShareAlike License 4.0; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia\u00ae is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n\n  * Privacy policy\n  * About Wikipedia\n  * Disclaimers\n  * Contact Wikipedia\n  * Code of Conduct\n  * Developers\n  * Statistics\n  * Cookie statement\n  * Mobile view\n  * Edit preview settings\n\n", "frontpage": false}
