{"aid": "40047664", "title": "Trying Out Cloudflare's `Foundations` Library for Rust", "url": "https://cprimozic.net/blog/trying-out-cloudflare-foundations-library/", "domain": "cprimozic.net", "votes": 3, "user": "todsacerdoti", "posted_at": "2024-04-16 01:57:54", "comments": 0, "source_title": "Trying Out Cloudflare's `foundations` Library for Rust - Casey Primozic's Homepage", "source_text": "Trying Out Cloudflare's `foundations` Library for Rust - Casey Primozic's\nHomepage\n\ncprimozic.net\n\n|\n\n@ameobea10\n\ncprimozic.net\n\n@ameobea10\u2022Portfolio\u2022Contact\u2022Blog\u2022Professional Experience\n\n# Trying Out Cloudflare's `foundations` Library for Rust\n\nSubscribe to Blog via RSS\n\n  * Background + Overview\n\n  * Initial Impressions + Observations\n\n  * Settings + CLI\n\n  * Telemetry\n\n    * Logging\n\n    * Metrics\n\n      * Advanced Tokio Metrics\n    * Tracing\n\n  * jemalloc\n\n  * Other Features\n\n  * Conclusion\n\n    * The Future\n\nA couple of months ago, I happened across the announcement blog post from\nCloudflare for their newly released foundations library for Rust. It looked\nlike something I'd definitely be interested in using, and I mentally marked it\ndown as something to check out when a good opportunity came up.\n\nWell, that opportunity recently came around - so I went ahead and tried it\nout!\n\nI set up a small, self-contained, greenfield Rust project from scratch built\nwith foundations from the very beginning. That service is now running in\nproduction, and I feel like I can give some informed thoughts about\nfoundations and what it's like to use it in practice.\n\n## Background + Overview\n\nAt a high level, foundations is a modular set of tools and utilities for\nbuilding networked services/microservices in Rust.\n\nThe idea is to provide a re-usable and common toolkit containing the common\npieces of functionality you'll need again and again when building server-side\napplications in Rust. These include features like logging, metrics, tracing,\nsecurity, settings, and more - a full list is available in their well-written\ndocs. There are a few modules that have some support for working on the client\nside, but largely the focus is on server-side applications.\n\nHere's the list they give in their own docs:\n\n  * logging\n  * distributed tracing\n  * metrics\n  * memory profiling and jemalloc allocator\n  * security features, such as seccomp-based syscall sandboxing\n  * service configuration with documentation\n  * CLI helper that takes care of the configuration loading\n\nRather than providing a monolithic application platform or protocol-specific\nframework, its features are mostly independent and are set up individually by\nthe programmer. There's nothing in foundations for things like HTTP servers or\ngRPC endpoints; it's all a bit more generic than that.\n\n## Initial Impressions + Observations\n\nOne of the first things I noticed while using this library was that\n\nfoundations really is extremely modular and doesn't lie about being\nincrementally adoptable in existing codebases.\n\nEvery individual piece of functionality in the library is neatly split up and\nexposed behind a variety of well-documented feature flags. I opted to disable\nall the default features and explicitly opt-in to all the functionality I\nwanted one by one. While doing this, I was impressed by how I ran into no\ncompilation issues or other problems while setting it up.\n\nI've worked with feature-flagged code in Rust in the past, and it's very easy\nto introduce compilation failures or incompatibilities with certain\ncombinations of flags. foundations has theirs set up very well, though, and I\nexperienced no such issues at all.\n\nAnother thing I noticed is that foundations seems somewhat slanted towards\nenterprise use-cases compared to standalone applications or side projects.\n\nSome of the features like tracing, syscall sandboxing, and others are mostly\nuseful for larger dev teams maintaining dozens-hundreds of services. This\nisn't that surprising since it's built by Cloudflare, originally for use in\ntheir Oxy proxy service.\n\nThat being said, I think foundations is still very useful for smaller projects\nor solo developers (like I was for my project). The previously mentioned\nmodularity means you if one of the features isn't useful to you, you can\neasily choose to just not use it.\n\n## Settings + CLI\n\nOne of the first things I set up with foundations was its settings file\nsupport. This is for runtime parameters and application-specific config\nvalues. foundations handles auto-generating a YAML file from your settings\nspec that will be loaded at runtime.\n\nThe code for setting that up for my application looks like this:\n\n    \n    \n    use foundations::{settings::settings, telemetry::settings::TelemetrySettings}; #[settings] pub(crate) struct ServerSettings { /// Telemetry settings. pub(crate) telemetry: TelemetrySettings, /// Port that the HTTP server will listen on. #[serde(default = \"default_u16::<4510>\")] pub port: u16, /// Osu! OAuth client ID pub osu_client_id: u32, /// Osu! OAuth client secret pub osu_client_secret: String, }\n\nThat generates a YAML file that looks like this:\n\n    \n    \n    --- # Telemetry settings. telemetry: # <... many auto-generated settings for `foundations` telemetry ...> # Port that the HTTP server will listen on. port: 4510 # Osu! OAuth client ID osu_client_id: 0 # Osu! OAuth client secret osu_client_secret: \"\"\n\nOverall, it all made sense and setting it up was straightforward. As you can\nsee, I had quite minimal needs for settings for my application, and it all\nworked as expected out of the box.\n\nIt makes use of serde, so all of the settings must be de/serializable. This\nalso leads to my main complaint about the settings module:\n\nSetting default values for settings is pretty clunky and not supported out of\nthe box.\n\nFor many settings, I ended up pulling in a helper crate called\nserde_default_utils to accomplish that. Another option is to manually\nimplement Default for your settings struct and provide defaults for all fields\nexplicitly.\n\nThe only other complaint I had is that\n\nSettings can't be set/overridden by environment variable\n\nThis is more of an opinion, and I know there are people out there that dislike\nthe use of environment variables for application config, but I personally find\nthat it's often a very useful feature to have.\n\nThere's an open issue suggesting adding support for environment variable\nsupport in settings, and the library authors seem open to adding it, so\nthere's a decent chance this support will come in the future.\n\n## Telemetry\n\nThis is where things get kind of messy, but it's not really the fault of\nfoundations.\n\n### Logging\n\nInternally, foundations uses slog to manage its logging. Calls to\nfoundations::telemetry::log::info!() and similar functions emit calls to the\nslog logger that foundations maintains under the hood.\n\nslog has a lot of fancy features like expanded logging macros, support for\nforkable loggers, and a bunch of other complex features I don't fully\nunderstand. It seems very well thought out and comprehensive.\n\nOut of the box, the logging built in to foundations works quite well on its\nown.\n\nHowever, slog is not the only logging facade available in the Rust ecosystem.\nThe main alternatives that I'm familiar are log and tracing from the Tokio\necosystem.\n\nThese different libraries are not compatible with each other by default.\nLibraries that are set up to log with log (also called stdlog) will have their\nlog messages go into the void if a project has been configured with a\ndifferent logger.\n\nThere are various adaptor crates available like tracing-slog for\nslog->tracing, slog-stdlog for log<->slog, tracing-log for log->tracing, etc.\n\nAnyway, the whole Rust logging ecosystem seems to be very messy, fragmented,\nand confusing.\n\nFor my project, my logging needs were very simple. I had an extremely minimal\naxum webserver with a single route that I wanted to log requests/responses\nfor. The idiomatic way to do that seems to be to add a TraceLayer, which logs\nusing tracing.\n\nI spent a bunch of time trying to tweak the TraceLayer to work with the slog\nlogger from foundations without luck. I then tried to set up a shim to send\nlogs from tracing::info!() etc. to foundations, but couldn't get that to work\neither.\n\nI'm sure there's some arcane adapter library and config option that could make\nthis work, but it was such a massive waste of time for this project that I\ndecided to just drop foundations logging support and do all the logging myself\nwith tracing and tracing-subscriber to get it to print to the console.\n\nAlthough this part of the project was very annoying, I blame the pain on the\nfragmentation of the logging ecosystem rather than on some design flaw of\nfoundations. And at the end of the day, it was very easy to just turn off the\nlogging features of foundations and handle that myself.\n\nIt looks like there are future plans to add support for funneling events from\ntracing into foundations, but those aren't implemented yet. If that support\nlands, I expect it will greatly improve this situation.\n\n### Metrics\n\nI didn't expect it, but setting up metrics was my favorite part of using\nfoundations.\n\nI'd never set up a proper metrics collection system in any of my projects\npreviously, but I felt it was a good time to do it for this one in order to\ntry out as much of foundations as possible.\n\nThe metrics functionality in foundations is focused around providing data in\nthe format ingested by Prometheus - the most popular and commonly used open\nsource metrics + monitoring solution out there right now.\n\nI actually went ahead and set up a self-hosted Prometheus and Grafana instance\nmyself running inside Docker. To my surprise, that process was actually much\neasier than I expected, and it only took a few hours.\n\nTo start, foundations provides a nice macro to define a set of metrics\ncollectors for your application. These can be things like event counters,\nlatency histograms, or gauges to track values over time.\n\nDefining a new metric is as easy as this:\n\n    \n    \n    #[metrics] pub(crate) mod http_server { /// Number of HTTP requests. pub fn requests_total(endpoint_name: &'static str) -> Counter; }\n\nRecording values is very easy as well:\n\n    \n    \n    http_server::requests_total(\"get_hiscores\").inc();\n\nI defined a variety of metrics for my application, mostly to track HTTP\nresponse times and request counts of the API I was proxying requests to.\n\nfoundations handles all the bookkeeping for the various metrics, collating\nthem into the format Prometheus understands, and exposing that on a HTTP\nserver so they can be collected. The docs were all excellent and made setting\nthis up quite easy.\n\nOverall, the metrics collection features of foundations are excellent and easy\nto set up.\n\n#### Advanced Tokio Metrics\n\nIn addition to manually-defined metrics for specific applications, foundations\nalso provides support for exposing internal metrics for Tokio. You currently\nhave to set some special RUSTFLAGS and use the nightly Rust compiler, but\nsetting it up wasn't too much of a hassle overall.\n\nIn return, you get really deep and interesting insights into the Tokio runtime\nitself. I created graphs of some of these in Grafana and added them to the\ndashboard:\n\nSince my API bridge is so simple, there's not a lot of deep info to be gleaned\nfrom these currently. But for applications with more complex use-cases which\nmake use of more advanced Tokio features, I could easily see these metrics\nbeing invaluable for diagnosing performance issues or spotting issues.\n\n### Tracing\n\nIn addition to logging, foundations also has support for tracing that works\nwith Jaeger. This includes advanced features like cross-service trace\nstitching, forked tracing, and other fancy stuff like that.\n\nI took a brief look into setting up Jaeger, but I quickly came to realize\nsomething:\n\nFor a simple, mostly standalone application like mine, it doesn't make any\nsense at all to set up full-featured tracing like this.\n\nThis is something that I could see being extremely useful for an enterprise\nrunning dozens of interconnected services across multiple teams, but it's way\noverkill here. Because of that, I didn't try out the tracing features of\nfoundations myself.\n\n## jemalloc\n\njemalloc is a powerful memory allocator which has many benefits compared to\nthe system allocator. It used to be included in Rust by default, but was\neventually removed to lighten the binary size among other reasons.\n\nBesides being a highly performant allocator, jemalloc is notable for its\nefficiency in long-running services. It's one of the best allocators are\nreducing memory fragmentation, and I've anecdotally found that it's much\nbetter at other at returning unused memory to the operating system over time.\nI've run into issues in the past where the system allocator would hold onto\nunused pages indefinitely after a temporary burst in usage, while jemalloc\nseems to do a good job at releasing them.\n\nI often end up adding jemalloc manually to my projects for these reasons, so\nit's great that foundations offers out-of-the-box support for it.\n\n## Other Features\n\nThere were a few other components of foundations that I didn't try out myself.\n\nThe main one is syscall sandboxing for security. Although this is obviously a\nvery powerful tool for applications with strict security needs, there's just\nno need for that for mine.\n\nI also didn't try out the advanced memory profiling support through jemalloc.\nThat's something I could see myself using down the road, though.\n\n## Conclusion\n\nOverall, I'm very happy with foundations. I plan to include it by default in\nall new Rust services I create in the future.\n\nSince starting this blog post, I've set up foundations in two additional Rust\nservices - one new and one old. The process was largely very smooth, although\nI did run into similar issues with logging via the tracing crate as I\nmentioned.\n\nI found that foundations delivers on all of its claims an promises for\nfunctionality, modularity, and its ability to be incrementally adopted in\nexisting codebases without undue effort.\n\nAs an added bonus, it gave me the push I needed to go ahead and set up a real\nmodern metrics + analytics system with Prometheus and Grafana for my services.\n\n### The Future\n\nOne other big plus that foundations has going for it is that it's actively\nused at Cloudflare in some of their core services.\n\nAs a result, it gets regular updates and active maintenance by their world-\nclass engineering team.\n\nCompared to other libraries out there, I feel much more confident that\nfoundations won't just vanish or randomly go unmaintained one day.\n\n", "frontpage": false}
