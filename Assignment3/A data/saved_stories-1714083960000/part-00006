{"aid": "40159178", "title": "Updating large language models by directly editing network layers", "url": "https://www.amazon.science/blog/updating-large-language-models-by-directly-editing-network-layers", "domain": "amazon.science", "votes": 2, "user": "jonbaer", "posted_at": "2024-04-25 16:01:34", "comments": 0, "source_title": "Updating large language models by directly editing network layers", "source_text": "Updating large language models by directly editing network layers - Amazon\nScience\n\nSubscribe\n\nFollow Us\n\n  * twitter\n  * instagram\n  * youtube\n  * facebook\n  * linkedin\n  * github\n  * rss\n\n  * Research areas\n\n    * Automated reasoning\n    * Cloud and systems\n    * Computer vision\n    * Conversational AI\n    * Economics\n    * Information and knowledge management\n    * Machine learning\n    * Operations research and optimization\n    * Quantum technologies\n    * Robotics\n    * Search and information retrieval\n    * Security, privacy, and abuse prevention\n    * Sustainability\n    * Automated reasoning\n    * Cloud and systems\n    * Computer vision\n    * Conversational AI\n    * Economics\n    * Information and knowledge management\n    * Machine learning\n    * Operations research and optimization\n    * Quantum technologies\n    * Robotics\n    * Search and information retrieval\n    * Security, privacy, and abuse prevention\n    * Sustainability\n\n  * Blog\n\n  * Publications\n\n  * Conferences\n\n  * Code and datasets\n\n  * Academia\n\n    * Alexa Prize\n    * Academics at Amazon\n    * Amazon Research Awards\n    * Research collaborations\n    * Alexa Prize\n    * Academics at Amazon\n    * Amazon Research Awards\n    * Research collaborations\n\n  * Careers\n\nSubscribe\n\nMachine learning\n\n# Updating large language models by directly editing network layers\n\n## Automated method that uses gradients to identify salient layers prevents\nregression on previously seen data.\n\nBy Tamer Soliman\n\nMarch 25, 2024\n\nShare\n\nShare\n\n  * Copy link\n  * Email\n  * Twitter\n  * LinkedIn\n  * Facebook\n  * Line\n  * Reddit\n  * QZone\n  * Sina Weibo\n  * WeChat\n  * WhatsApp\n\n\u5206\u4eab\u5230\u5fae\u4fe1\n\n### Conference\n\n  * EACL 2024\n\n### Related publications\n\n  * Correcting language model outputs by editing salient layers\n\nOne of the great attractions of large language models (LLMs) is that they\nencode information about the real world. But the world is constantly changing,\nand an LLM\u2019s information is only as fresh as the data it was trained on.\n\nTraining an LLM can take months, even when the task is parallelized across\n1,000 servers, so AI researchers have sought alternate ways to update LLMs\u2019\nknowledge. One of these is to directly edit targeted layers of an LLM, to\nimprove its performance on a particular knowledge-based task. This is a task-\nspecific solution, not a general solution, but it takes hours to implement\nrather than months.\n\nRelated content\n\nContinual learning in the federated-learning context\n\nUsing gradient diversity to optimize selection of past samples for retention\nimproves performance while combatting catastrophic forgetting.\n\nExisting techniques for direct layer editing generally require either manual\nselection of layers to be edited or a time-consuming procedure to determine\nthe layers where editing will do the most good. Last week, at the 2024 meeting\nof the European Chapter of the Association for Computational Linguistics, we\npresented a new method for automatically selecting layers to be edited, which\nyields more-accurate updates than previous automated methods.\n\nCompared to the prior method for manual layer selection, it also limits\nregression, or post-update backsliding on data that the model previously\nhandled correctly. On some datasets, our method, which we call SaLEM (for\nsalient-layers editing model), reduced regression by an order of magnitude,\nwhile offering equivalent accuracy on new data.\n\n##\n\nIdentifying layers\n\nWe consider the case in which an LLM has been fine-tuned on a specific task,\nsuch as determining whether one input sentence logically entails or counts as\nevidence for or against another. In such cases, the model input is typically a\npair of texts, and the output is a decision such as \u201centailed\u201d or \u201csupported\u201d.\n\nRelated content\n\nBuilding geospatial foundation models via continual pretraining\n\nNew approach enables sustainable machine learning for remote-sensing\napplications.\n\nIn the prior approach to manual layer selection, known as causal tracing, the\nfirst token of each training example is fed to the model, then the first and\nsecond, then the first, second, and third, and so on. Then the process is\nrepeated with one of the model layers masked. This two-step analysis, in turn,\nmust be repeated for each layer of the network, a time-consuming procedure.\n\nIn our case, we instead prepare an \u201cedit dataset\u201d, consisting of input-output\npairs drawn from three groups: (1) the pass samples, for which the existing\nmodel outputs the correct answers; (2) the fail samples, for which the\nexisting model outputs the wrong answers; and (3) the adapt samples, which are\nsemantically equivalent to the fail samples but differently phrased.\n\nFor each sample, we compute the loss between the existing model\u2019s output and\nthe target output and the corresponding gradients \u2014 the modifications of model\nweights that make correct outputs more likely. Then we average the gradients\nacross each layer of the model and across all training samples. The layer with\nhighest average gradient \u2014 the layer that requires the largest modification to\naccommodate new facts about the world \u2014 is the one we edit.\n\nAn example of SaLEM in action. The inputs to the model are the two phrases\n\"The high-minded dismissal\" and \"A dismissal of a higher mind\". Before layer\nediting, the model incorrectly labels the phrases as contradictory; after\nlayer editing, it correctly labels their relationship as one of entailment.\n\n##\n\nLayer editing\n\nTo edit the selected layer, we use the MEND method proposed by Stanford\nUniversity researchers in 2022. With MEND, a second machine learning model,\nthe editor model, is trained to, essentially, take gradients as inputs and\noutput parameter edits.\n\nBut rather than the raw gradients, the model\u2019s inputs are a low-rank\napproximation of the gradients, which reduces the dimension of the data by\nidentifying the axes along which most of the variance occurs. This is\nsomething like teasing out the underlying causes of the larger gradients,\nwhich helps the model generalize better. We also guard against overfitting by\naggregating gradients in batches of 10 before computing their low-rank\napproximation.\n\nRelated content\n\nData-efficient continual learning in Alexa\n\nEMNLP papers examine constrained generation of rewrite candidates and\nautomatic selection of information-rich training data.\n\nWe use two training objectives to train the editor, one that maximizes the\nlikelihood of correct answers on inputs from the fail and adapt sets and one\nthat minimizes output divergence on inputs from the pass set. This helps\nprevent regression.\n\nIn the original MEND paper, the Stanford researchers used this approach to\nedit the top three layers of a fine-tuned LLM, a reasonable heuristic for\ntrading off editing efficiency, correction of outputs, and prevention of\nregression. Because SaLEM identifies the one layer most implicated in the new\nmodel update, it can match MEND\u2019s performance on new data. But because it\nmodifies parameters in one layer rather than three, it reduces regression.\n\n##\n\nExperiments\n\nWe evaluated SaLEM on six datasets used to fine-tune LLMs on natural-language-\nprocessing tasks. Four of the datasets had to do with natural-language\ninference, one was a question-answering dataset, and one was a dataset for the\nstandard LLM task of next-token prediction. For the question-answering and\ngeneration tasks, we compared SaLEM and the baselines on four different LLM\narchitectures. We measured performance using both edit accuracy, or post-\nediting accuracy on the new data, and drawdown, which measures regression on\nthe old data.\n\nRelated content\n\nTeaching speech recognizers new words \u2014 without retraining\n\nUsing lists of rare or out-of-vocabulary words to bias connectionist temporal\nclassification models enables personalization.\n\nOn the inference tasks, SaLEM matched the edit accuracy of the top performers\nbut had significantly better drawdown \u2014 four and ten times better than the\nsecond-best performer on two of the datasets. On the other two tasks, SaLEM\nfinished second on both measures to an approach called editable neural\nnetworks (ENN). But ENN requires two copies of an LLM to run simultaneously,\nwhich is resource intensive. Indeed, for two of the four LLM architectures we\ntested, we were unable to run ENN because of its computational demands.\n\nIn ongoing work, we are investigating (1) enriching the editing dataset with\nbetter failed samples and their semantic and counterfactual equivalents, (2) a\nbetter weight update mechanism to inform the editor about the extent of\nupdates for borderline instances, and (3) a method of performing edits without\nloading the full model into memory, as we currently do.\n\nResearch areas\n\n  * Machine learning\n  * Conversational AI\n\nTags\n\n  * Large language models (LLMs)\n  * Continual learning\n\n### Conference\n\n  * EACL 2024\n\n### Related publications\n\n  * Correcting language model outputs by editing salient layers\n\nAbout the Author\n\nTamer Soliman\n\nTamer Soliman is an applied scientist with Amazon Web Services.\n\n## Related content\n\n  * Continual learning in the federated-learning context\n\nJimit Majmudar, Charith Peris\n\nDecember 07, 2023\n\nUsing gradient diversity to optimize selection of past samples for retention\nimproves performance while combatting catastrophic forgetting.\n\nMachine learning\n\n  * Vision-language models that can handle multi-image inputs\n\nWenyi Wu, Qi Li\n\nJanuary 19, 2024\n\nAttention-based representation of multi-image inputs improves performance on\ndownstream vision-language tasks.\n\nComputer vision\n\n  * Beyond boundaries: A human-like approach for question answering over structured and unstructured information sources\n\nJens Lehmann, Dhananjay Bhandiwad, Preetam Gattogi, Sahar Vahdati\n\n2024\n\nAnswering factual questions from heterogenous sources, such as graphs... Read\nmore\n\nRelated: Teaching LLMs to use heterogenous information sources\n\nConversational AI\n\nDownload\n\n## Work with us\n\nSee more jobs See more jobs\n\nSenior Economist, Economic Decision Science\n\nGB, London\n\nEconomic Decision Science is a central science team working across a variety\nof topics in the EU Stores business and... Read more\n\nIntern - Economics, JP Retail\n\nUS, WA, Seattle\n\nThe JP Economics and Decision Science Team is looking for an Intern Economist\nwith experience in empirical... Read more\n\nSenior Applied Scientist, Fulfillment by Amazon\n\nUS, WA, Bellevue\n\nThe Fulfillment by Amazon (FBA) team is looking for a passionate, curious, and\ncreative Senior Applied Scientist, with... Read more\n\nApplied Scientist, FBA Science\n\nUS, WA, Bellevue\n\nThe Fulfillment by Amazon (FBA) team is looking for a passionate, curious, and\ncreative Applied Scientist, with expertise... Read more\n\nApplied Scientist, Outbound Communications, Traffic and Marketing Tech\n\nUS, WA, Seattle\n\nOutbound Communications own the worldwide charter for delighting our customers\nwith timely, relevant notifications (... Read more\n\nApplied Scientist, Artificial General Intelligence\n\nUS, WA, Seattle\n\nThe Artificial General Intelligence (AGI) team is looking for a passionate,\ntalented, and inventive Applied... Read more\n\nApplied Scientist*, Japan Store Tech\n\nCN, 11, Beijing\n\nAmazon Search JP builds features powering product search on the Amazon JP\nshopping site and expands the innovations... Read more\n\nApplied Scientist, Automated Reasoning Group\n\nUS, WA, Seattle\n\nThe Automated Reasoning Group in AWS Platform is looking for an Applied\nScientist with experience in building... Read more\n\nApplied Scientist, Alexa Shopping\n\nUS, WA, Seattle\n\nWe\u2019re working to improve shopping on Amazon using the conversational\ncapabilities of LLMs, and are searching for... Read more\n\nSenior Applied Scientist, CreST\n\nUS, WA, Seattle\n\nWe are looking for an Applied Scientist to join our Seattle team. As an\nApplied Scientist, you are able to use a range of science... Read more\n\nGet more from Amazon Science\n\nSubscribe to our monthly newsletter\n\nAmazon.com | Conditions of Use | Privacy | \u00a9 1996-2024 Amazon.com, Inc. or its affiliates\n\nFollow Us\n\n  * twitter\n  * instagram\n  * youtube\n  * facebook\n  * linkedin\n  * github\n  * rss\n\n", "frontpage": false}
