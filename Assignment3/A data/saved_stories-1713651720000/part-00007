{"aid": "40097681", "title": "Coroutines and Effects", "url": "https://without.boats/blog/coroutines-and-effects/", "domain": "without.boats", "votes": 3, "user": "todsacerdoti", "posted_at": "2024-04-20 14:39:30", "comments": 0, "source_title": "Coroutines and effects", "source_text": "Coroutines and effects\n\nWithout boats, dreams dry up\n\n# Coroutines and effects\n\nApril 20, 2024\n\nFor the past few months I\u2019ve been mulling over some things that Russell\nJohnston made me realize about the relationship between effect systems and\ncoroutines. You can read more of his thoughts on this subject here, but he\nmade me realize that effect systems (like that found in Koka) and coroutines\n(like Rust\u2019s async functions or generators) are in some ways isomorphic to one\nanother. I\u2019ve been pondering the differences between them, trying to figuring\nout the advantages and disadvantages of each.\n\nA few weeks ago, Will Crichton posted something on Twitter that helped bring\nthe contrast into sharper focus for me:\n\n> The entire field of PL right now: what if it was dynamically scoped.... but\n> statically typed..............? (effects, capabilities, contexts,\n> metavariables...)\n\nI\u2019m just a humble language designer (and not a theorist of anything,\nespecially not PL), so my focus is the difference in user experience and\naffordance. But this seems like a cutting insight and this property of effect\nhandlers - static typing but dynamic scoping - seems to me to be a good\njumping off point for understanding the difference between effect handlers and\ncoroutines from a user perspective.\n\n# Background\n\n## What is a coroutine?\n\nA coroutine is a function which can yield control back to its caller before\nfinishing. The caller then has a reference to the state of the coroutine when\nit yielded, so it can resume the coroutine again if it so chooses. It\u2019s\npossible to model many meaningful \u201ceffects\u201d using coroutines by having the\ncoroutine yield. For example:\n\n  * A coroutine can perform IO \u201casynchronously,\u201d by yielding a value like Pending when IO is being performed.\n  * A coroutine can be iterable by yielding values as it traverses some collection.\n  * A coroutine can model exceptions by yielding an exception value (in this case, resuming the coroutine would have no effect).\n\nRust, for example, models both asynchrony and iteration using coroutines. On\nthe other hand, exceptions are not modeled this way; instead they are modeled\nwith the Result type. Specifically, Rust uses \u201cstackless\u201d coroutines, but this\ndistinction is not very important to the concepts in this post.\n\n## What is an effect handler?\n\nI need to be clear, because terminology has become muddied in the Rust\ncommunity: this post has nothing in particular to do with \u201ceffects generics\u201d\nas conceptualized by the Rust project, which is a different set semantic\nfeatures related to how Rust handles effects from \u201ceffects systems\u201d as they\nappear in the literature. In this post, I am focused on effect systems as\nproposed in languages like Koka and Effekt. And my understanding of these\nsystems may be imperfect or wrong, but this is how they operate as I\nunderstand them.\n\nIn an effect system, in addition to a type, an expression will have an effect.\nAn effect is an additional \u201ckind\u201d in the formal, type system sense of the word\n(in the same way that lifetimes are another \u201ckind\u201d in Rust). In general,\nexpressions inherit the effects of other expressions they contain. Functions\ninherit the effects of their body.\n\nFor example, Koka has a \u201cdiverging\u201d effect, which means that an expression may\ndiverge (that is to say, it may not finish evaluating). An expression\ncontaining a diverging expression is also diverging. So you can distinguish in\nthe type system between a function that is guaranteed to finish and a function\nthat may not finish (this is imperfect, of course, because of the\nundecidability of the halting problem; some functions that do not diverge will\nbe marked diverging).\n\nHowever, these languages also have a concept of effect handlers, which take an\nexpression with an effect and \u201chandle\u201d it, producing an expression without\nthat effect. Not all effects can be handled (for example, as far as I\nunderstand it is not possible to meaningfully handle the diverging effect),\nbut some can. The semantics of what it means to handle an effect are where\neffect systems become similar to coroutines.\n\nWhen a handleable effect occurs, an effectful expression yields control to the\nnearest-most handler of that effect, which may or may not yield control back.\nThis can be used to model all of the same sorts of effects as coroutines. For\nexample:\n\n  * An IO effect can yield control to the IO handler, which will yield back to the expression when IO is complete.\n  * An iterable effect can yield control to the loop consumer for each value, which yields back to the iterable to continue iteration.\n  * An exception effect can yield control to an exception handler, which will not yield control back.\n\n# The difference is between static and dynamic scope\n\nThe key difference between coroutines and effect handlers is that coroutines\nyield control to their caller, but effectful expressions yield control to\ntheir handler. The difference of affordance this implies is the materially\nsignificant advantage of coroutines over effect handlers.\n\nLet\u2019s imagine a programming language in which every function is a coroutine\nwhich can yield Pending or an exception (to model both IO and exceptions) and\nthere are multiple kind of call operators that \u201chandle effects\u201d differently:\n\n  * There is an ordinary call operator that can only be used on coroutines that never yield (these coroutines are effectively pure functions)\n  * There is an asynchronous ().await call operator that can be called on coroutines that yield Pending, which yields Pending and then calls them again (so it can only be called from within another coroutine that yields Pending)\n  * There is an exception-throwing ()? call operator that can be called on coroutines that yield an exception, which yields the exception outward.\n  * There is a combined ().await? call operator that can be called on coroutines that yield Pending and exceptions, to forward both effects.\n\nLet\u2019s suppose you wanted to do an HTTP request in this language (which\nperforms IO and can also raise an exception representing some sort of IO\nerror):\n\n    \n    \n    fn get_blog() -> HttpResponse yields (Pending | Exception) { http::get(\"https://without.boats\").await? }\n\nNow, let\u2019s contrast this to a similar language which models IO and exceptions\nusing effects. In this language, there is no need for special call operators:\na function which has an IO or exception effect can call functions which also\nhave IO or exception effects:\n\n    \n    \n    fn get_blog() -> HttpResponse effect (IO | Exception) { http::get(\"https://without.boats\") }\n\nThe difference between these features is that the call to http::get must be\nannotated with the await and ? syntax to forward its effects, whereas with\neffect handlers the forwarding of effects by a callee is implicit.\n\nI want to take one more step back and then I promise I will reach a\nconclusion. There are definitions of coroutines other than the one I gave,\nespecially older ones. If you were to closely read Wikipedia, you would find a\nslightly different definition, and what I\u2019ve called coroutines are addressed\ninstead as \u201cgenerators\u201d or \u201csemicoroutines.\u201d In the older definition, a\ncoroutine can specify where it yields control. This is actually based on a\nmodel of program execution in which there is no program stack: instead, every\ncoroutine is a global singleton, and yielding control to it means continuing\nit wherever it last left off. For semicoroutines, in contrast, calling a\ncoroutine produces a new stack frame which can only be resumed by code with a\nreference to that stack frame.\n\nThe program stack is such a universal model of program execution today that we\ntreat it as inevitable, but like everything else it had to be invented. It was\ninvented to support recursive function definition, but it has other advantages\nin the way that it enables local reasoning: from the body of a function, there\nis exactly one dynamic jump point - wherever it returns to. From the point of\nview of the caller, this is now statically known: the function will jump back\nto the point at which it is called.\n\nThis rule can only be violated when a language introduces new features that\nallow additional dynamic jump points. One that has long been popular is the\nnotion of exceptions, which unwind the call stack to the point at which they\nare being handled. There are two kinds of exceptions: unchecked exceptions,\nwhich are totally untyped, and checked exceptions, which require an\nannotations on any function which could throw them.\n\nEffect handlers are a generalization of checked exceptions, with all of the\npros and cons of that feature. They require you to annotate functions that\nhave an effect, but they do not require you to annotate calls at which the\neffect can occur. Therefore, when examining the body of a function, to\nunderstand when the effect occurs requires examining the type signature of\nevery function that is called. Since this is meaningful control flow, it seems\nvery valuable to be able to identify points at which an error occurs without\nexamining the signatures of each function call. This is why Rust features\nResult and the ? operator instead of checked exceptions.\n\nThere\u2019s an axis of evaluation here with three points: a language could model\nan effect in a way which is totally unchecked at compile time: both\ndynamically typed and dynamically scoped. Unchecked exceptions (including\npanics) are an example of this; so is blocking IO. And a language could model\nthe effect in the type system, but with a dynamic scope. Checked exceptions\nand effect handlers are both examples of this. And a language could model the\neffect in a way which is both statically typed and lexically scoped. This is\nwhat Rust does for these effects with both Result and async/await.\n\n    \n    \n    \u2502 EXCEPTIONS \u2502 IO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 \u2502 DYNAMICALLY TYPED & DYNAMICALLY SCOPED \u2502 panicking \u2502 blocking \u2502 \u2502 STATICALLY TYPED & DYNAMICALLY SCOPED \u2502 checked exceptions \u2502 IO effect \u2502 \u2502 STATICALLY TYPED & LEXICALLY SCOPED \u2502 Result \u2502 async/await \u2502 \u2502\n\nThese are not the only language features that can be used to model effects,\nand other features also fall into one of these buckets. For example, monads\nare also statically typed and lexically scoped. However, a major objection to\nmonads is that they model effects in a specifically layered way, so that for\nexample there is a distinction between an IO<Result<T, E>> and a Result<IO<T>,\nE>. Coroutines on the other hand are order-independent: all coroutine that\nyield Pending and Exception have the same type, there is no distinction of\norder. The same is true of effect handlers.\n\nThis has appeared in Rust for example with the debate about the design of\nasync iterators. Designs based on async fn next introduce an arbitrary\nordering by introducing multiple coroutines, whereas designed based on a\nsingle coroutine do not make a distinction; the coroutine just yields items as\nwell as Pending. This was the crux of Russell Johnston\u2019s argument in the post\nI linked earlier: this unlayered property is shared by coroutines and effect\nhandlers, and is an advantage of these features.\n\nOn the other hand, by modeling errors with Result instead of some sort of\ncoroutine, Rust does introduce an ordering. This is mostly fine because of the\nfact that a function which \u201cthrows an exception\u201d (by evaluating to an Err) is\nnot supposed to be resumed, though it introduces some quirks where for example\nthere\u2019s no way to distinguish between an iterator of Results (which may\ncontinue after one is an Err) and an iterator which throws an error (which\nwill not continue). If instead a generator could \u201cyield an exception,\u201d it\nwould be a different type from a generator that yields a sequence of Results.\nBut I don\u2019t find this inadequacy to come up in practice that often, so I\u2019m\ncontent to leave it as theoretical work for a future language to solve.\n\nOverall, coroutines strike me as the most promising way to handle many kinds\nof effectful functions because they seem to be in the design sweet spot: They\nare statically typed, lexically scoped, and unlayered. This is why my starting\npoint for handling effects in any language would be a coroutine feature\n(though if the language were not under Rust\u2019s constraints, I would prefer if\nit were a stackful coroutine feature so they could be recursive).\n\n|| saoirse@without.boats | RSS | Black Lives Matter\n\n", "frontpage": false}
