{"aid": "40145456", "title": "Correlated Alerting. How to optimize for high signal alerts", "url": "https://blog.runreveal.com/introducing-correlated-alerting-a-new-method-of-detection-that-optimizes-for-high-signal-alerts/", "domain": "runreveal.com", "votes": 1, "user": "ejcx", "posted_at": "2024-04-24 15:22:27", "comments": 0, "source_title": "Introducing Correlated Alerting. A new method of detection that optimizes for high signal alerts", "source_text": "Introducing Correlated Alerting. A new method of detection that optimizes for\nhigh signal alerts\n\nAnnouncing our open beta! Read about it here\nhttps://blog.runreveal.com/runreveal-open-beta/\n\nSign in Subscribe\n\nApr 24, 2024 7 min read News\n\n# Introducing Correlated Alerting. A new method of detection that optimizes\nfor high signal alerts\n\nToday RunReveal is announcing the beta release of correlated alerting, a new\nsecurity alerting technique that is running for all customers today and is\ndesigned to deliver significantly higher signal for cloud detection and SIEM\nuse cases.\n\nCurrent stream processing techniques and log query languages are really bad at\nsearching for threat actors. No single indicator or log can reliably indicate\na compromise, yet all the log processing and search tools we have available to\nus today are built to look for one set of conditions at a time. The fact that\nmost security teams struggle with alert fatigue is a direct result of this old\nparadigm, and the current set of vendors repeating this same old mistake.\n\nThe out of the box detections you get with RunReveal already use this\ntechnique. However, with this release we're also providing a framework for you\nto easily build your own correlated alerts! There's no magic when it comes to\nhard data problems however, so let's look at the details of how this works.\n\n# Eliminate false positives with \"The swiss cheese model\"\n\nIf you look at the baseline detections that your average SIEM comes with, they\nmight have a few hundred that look something like this:\n\n    \n    \n    my_log_source | where eventName==\"SuperSensitiveThing\"\n\nThis seems great at first glance. Your security team probably worries about\nSuperSensitiveThing so why not get a notification whenever that happens? Makes\na lot of sense, right?\n\nWell...maybe. If this isn't something that fits your organization's practices\nthen it's likely to cause a false positive every time SuperSensitiveThing\nhappens. After adding another 50 similar alerts you're bound to add detections\nthat don't fit your practices, and the false positives will add up. The result\nis usually a lot of unhappy incident responders and security engineers. Your\norganizations detections, when alerting on individual events, need to closely\nmatch your company's security controls in order to be effective so most\nsecurity teams slowly add detections one at a time to avoid creating noise.\n\nBut what if we could take a lot of relatively simple alerts and have them work\ntogether in order to make better alerts and reduce false positives? There are\nlots of other fields that have this kind of problem that we can borrow from.\nWhat would an abstraction like that look like?\n\nThe swiss cheese model is usually used for accident prevention. But it works\nwell for false positive prevention too!\n\nThe swiss cheese model is usually referenced in the context of accident\nprevention in fields like Aviation, where having multiple layers can prevent\naccidents if any one layer fails. Could we apply this same strategy when\nwriting alerts too? Instead of alerting on single events that match your\ndetection, why not alert when a set of bad conditions all occur at once?\n\nHow would you express this kind of thing in a query language or within an\nevent stream? Good luck! The syntax of doing this in a programming language\nlike python, or a query language will be nightmarish and unmaintainable.\nSupporting this type of detection strategy requires a system designed to do\nit.\n\n# An abstraction for correlating detections\n\nWhen RunReveal first built our detection engine, prior to thinking about\ncorrelation or false positives, we made the decision to log the results of\nevery detection query that ran. We store the results of these detections in a\ntable called detections, along with a bunch of metadata like the detection\nname, user-defined categories, mitreAttack classifications, riskScore, etc.\n\nThis ended up being a good choice.\n\nAfter gaining some experience building detections on our platform, we realized\nthat we could greatly reduce the false positive rate for alerts by stacking\ndetections upon one another. We decided to classify these two distinct types\nof detections as Signals and Alerts. We also added views for the detections to\nmake them easy to utilize:\n\n  * signals - Signals are detections that extract information from your logs but don't send an alert on a notification channel.\n  * alerts - Alerts are detections where a notification was sent to at least one notification channel.\n\nHere I am querying my signals and you can see that I logged in from a new\ncountry.\n\n    \n    \n    rr> select * from signals LIMIT 1;\\G Row 0 id | 2d5iQuQmIopGZWLrZBlqHOL9BMf scheduledRunID | 2d5iQbq8niSdzk0rjjbcegp6yk3 workspaceID | 2KUOdhvRreF5RZfQX8ILneT4fSd detectionID | 2c9D7GZIJsyVrgYVSERAQJXVHs4 detectionName | new_country_login recordsReturned | 1 runTime | 1.13707854e+08 query | ... params | map[from:2024-02-09 table:logs to:2024-02-10] columnNames | [workspaceID sourceID ... columnTypes | [String String ...] results | [\"2KUOdhvRReF5RZf\", \"2SO1VPGVFtF5bp\" ...] severity | medium actor | map[email:evan@runreveal.com] resources | [] srcIP | 1.2.3.4 dstIP | categories | ['okta', 'signal'] mitreAttacks | ['initial-access'] riskScore | 50 error | createdAt | 2024-03-01T14:45:24Z eventTime | 2024-03-01T14:13:33Z receivedAt | 2024-03-01T14:32:51Z Ran Query: select * from signals LIMIT 1 Retrieved 1 rows in 810.770875ms\n\nThis intermediate signals table is a critical staging-area required to build\nmore advanced alerts. Let's look at an example to show why that is.\n\nLet's say we wanted to alert when a single user did a lot of risky activity in\na short window of time. We could collect all of the risky activity in the\nsignals table, sum the riskScore for each actor within that timeframe, and set\na threshold.\n\n    \n    \n    with all_risk_scores as ( SELECT actor['email'] as email, sum(riskScore) as riskTotal FROM signals WHERE email != '' AND eventTime > {from:DateTime} AND eventTime < {to:DateTime} GROUP BY email ) SELECT * from all_risk_scores where riskTotal > 100\n\nThis is a pretty basic example but we think it illustrates the idea well. To\nrecap, an individual event might be enough information to know whether or not\nan alert should be raised but that isn't always the case, and matching one\nevent at a time will never be enough to find malicious patterns in otherwise\nnormal behavior.\n\n# Easily writing correlated alerts\n\nThe example above isn't the most advanced SQL query or the most difficult to\nread, but subqueries are not ideal and can quickly become tedious. We wanted\ncorrelated alerts to be incredibly simple to write so our customers could\nbuild their own even if they weren't SQL experts or had never heard of a sub-\nquery.\n\nTo make it simpler we had to first understand that the correlated alert above\nis really doing two things:\n\n  * Grouping relevant information by the user in that time-span\n  * The conditions you want to alert on, in this case where riskTotal > 100\n\nKnowing that most correlated alerts are going to be using the detection\nmetadata we can make writing an alert simpler by doing all of the grouping and\naggregation by identity by creating more helpful views on top of the original\ndetections table. This will allow our customers just to need to worry about\nwriting conditions, and we worry about the complexity.\n\n    \n    \n    SELECT * FROM signals_grouped(from={from:DateTime}, to={to:DateTime}, window={window:Int64}) WHERE length(mitreAttacks) > 3\n\nWOW! That's finally really simple. But, what's this magic signals_grouped\ndoing? It's a view that is aggregating information from the signals table by\nidentities, associated bits of metadata, and handling windowing by time \u2013\neverything up to the WHERE clause is boiler-plate (for now). The output of\nthis query (in this case expressed in JSON for readability) is much higher\nsignal and much more useful for making decisions about when to alert, and\nwhere to start an investigation than the raw data would otherwise have been.\nNotice the ids field which contains the original event identifiers to easily\npivot to the raw data that was alerted on.\n\n    \n    \n    { \"workspaceID\": \"2KUOdhvRReF5RZfQX8ILneT4fSd\", \"email\": \"evan@runreveal.com\", \"userIDs\": [ \"deadbeefdeadbeefdeadbeefdeadbeef\" ], \"srcIPs\": [ \"34.227.127.165\", \"2607:fb90:87e3:4c35:e066:a6d8:6856:4eaf\", \"70.122.134.143\", \"77.211.4.216\" ], \"srcASOrganizations\": [ \"AMAZON-AES\", \"T-Mobile USA Inc.\", \"TWC-11427-TEXAS\", \"VODAFONE_ES\" ], \"srcASCountryCodes\": [ \"US\", \"ES\" ], \"detectionNames\": [ \"impossible-travel\", \"service-account-created\", \"okta-user-session-impersonation\" ], \"totalRiskScore\": 155, \"mitreAttacks\": [ \"initial-access\", \"persistence\", \"lateral-movement\" ], \"categories\": [ \"signal\", \"gcp\", \"okta\" ], \"ids\": [ \"2fWEjgIRxPfksdwmqjFYQMGUqUs\", \"2fWEjezcji2uRZE5MCY7joFk2Yt\", \"2fWEjZMiaxtlHtjLfXZjdpA7fWH\" ], \"severities\": [ \"Medium\", \"High\" ] },\n\nThis is some heavy duty data management but luckily you don't need to worry\nabout how it works if you don't want to. We give this to our customers so they\ncan read the documentation and write similar queries that utilize\nsignals_grouped.\n\nThe amazing thing about this is signals_grouped is a view, so as we add more\nenrichments, expand the capabilities of the view, and even update information\nto keep the context of your signal up to date.\n\n# What's next\n\nSIEM vendors have been giving their customers \"out of the box\" detections for\ndecades that are designed to create noise and not alert on meaningful threat\nscenarios. Now the industry is collectively complaining about false positives,\nalert fatigue, and burned-out SOCs. As an industry we need to reckon with this\ntruth.\n\nWhether you're building your own SIEM, or spending millions each year on a\ncommercial tool, you need to transition away from alerting on individual logs.\nRunReveal is giving this capability to all of customers from the free tier to\nthe enterprise. The highest performing detection and response teams rely on\nthe right abstractions that collect the signal and filter out the noise, and\nthat signal usually isn't in the raw telemetry.\n\nRunReveal is here to help and our aim is to build a SIEM that is truly loved,\nwhich means innovating on each individual aspect of detection and response. To\naccomplish this we peeled back the curtain on detection and response programs\nout in the industry and read a lot that had been written on this topic before\nbuilding this ourselves. Some blogs we read:\n\n  * https://posts.specterops.io/introducing-the-funnel-of-fidelity-b1bb59b04036\n  * https://medium.com/starting-up-security/lessons-learned-in-detection-engineering-304aec709856\n  * https://medium.com/brexeng/building-the-threat-detection-ecosystem-at-brex-215e98b2f1bc\n\nWe have a few other big releases planned for the next few weeks. If you're\ninterested in this product or what else is on our planned roadmap, please get\nin contact with us using this form.\n\nRunReveal will be at BSidesSF and RSA this year in San Francisco. If you're\nburied in false positives and paying the price (figuratively and literally)\nreach out and the RunReveal founders will buy you a coffee to commiserate.\n\n### Published by:\n\n### You might also like...\n\nMar\n\n26\n\n## CVE-2024-22412 - Behind the bug, a classic caching problem in the\nClickHouse query cache\n\n6 min read\n\nMar\n\n13\n\n## Announcing RunReveal Destinations, your security data streamed to where you\nwant it.\n\n3 min read\n\nFeb\n\n27\n\n## Introducing pql, a pipelined query language that compiles to SQL (written\nin Go).\n\n5 min read\n\nDec\n\n19\n\n## Introducing RunReveal Search, the fastest way to explore logs\n\n3 min read\n\nOct\n\n31\n\n## RunReveal supports Jupyter Notebooks\n\n2 min read\n\nRunReveal \u00a9 2024\n\nPowered by Ghost\n\n", "frontpage": false}
