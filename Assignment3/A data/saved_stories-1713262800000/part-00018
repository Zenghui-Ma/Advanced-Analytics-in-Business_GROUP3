{"aid": "40047234", "title": "AI's new power of persuasion: it can change your mind", "url": "https://actu.epfl.ch/news/ai-s-new-power-of-persuasion-it-can-change-your-mi/", "domain": "epfl.ch", "votes": 1, "user": "geox", "posted_at": "2024-04-16 00:44:18", "comments": 0, "source_title": "AI's new power of persuasion: it can change your mind", "source_text": "AI's new power of persuasion: it can change your mind - EPFL\n\nWhen you access EPFL websites, we may set cookies on your devices and process\npersonal data about you in accordance with our privacy policy. You can block\ncookies by using your browser settings.\n\nOK\n\nNews\n\n  * EPFL\n  * ENAC\n  * SB\n  * STI\n  * IC\n  * SV\n  * CDM\n  * CDH\n  * All\n\nMenu\n\n# AI's new power of persuasion: it can change your mind\n\nRobot head, digital brain, neural network \u00a9 2024 iStock\n\nA new EPFL study has demonstrated the persuasive power of Large Language\nModels, finding that participants debating GPT-4 with access to their personal\ninformation were far more likely to change their opinion compared to those who\ndebated humans.\n\n\u201cOn the internet, nobody knows you\u2019re a dog\u201d. That\u2019s the caption to a famous\n1990s cartoon showing a large dog with his paw on a computer keyboard. Fast\nforward 30 years, replace \u2018dog\u2019 with \u2018AI\u2019 and this sentiment was a key\nmotivation behind a new study to quantify the persuasive power of today\u2019s\nLarge Language Models (LLMs).\n\n\u201cYou can think of all sorts of scenarios where you're interacting with a\nlanguage model although you don't know it, and this is a fear that people have\n- on the internet are you talking to a dog or a chatbot or a real human?\u201d\nasked Associate Professor Robert West, head of the Data Science Lab in the\nSchool of Computer and Communication Sciences. \u201cThe danger is superhuman like\nchatbots that create tailor-made, convincing arguments to push false or\nmisleading narratives online.\u201d\n\nAI and personalization\n\nEarly work has found that language models can generate content perceived as at\nleast on par and often more persuasive than human-written messages, however\nthere is still limited knowledge about LLMs\u2019 persuasive capabilities in direct\nconversations with humans, and how personalization \u2013 knowing a person\u2019s\ngender, age and education level - can improve their performance.\n\n\u201cWe really wanted to see how much of a difference it makes when the AI model\nknows who you are (personalization) - your age, gender, ethnicity, education\nlevel, employment status and political affiliation - and this scant amount of\ninformation is only a proxy of what more an AI model could know about you\nthrough social media, for example,\u201d West continued.\n\nHuman v AI debates\n\nIn a pre-registered study, the researchers recruited 820 people to participate\nin a controlled trial in which each participant was randomly assigned a topic\nand one of four treatment conditions: debating a human with or without\npersonal information about the participant, or debating an AI chatbot\n(OpenAI\u2019s GPT-4) with or without personal information about the participant.\n\nThis setup differed substantially from previous research in that it enabled a\ndirect comparison of the persuasive capabilities of humans and LLMs in real\nconversations, providing a framework for benchmarking how state-of-the-art\nmodels perform in online environments and the extent to which they can exploit\npersonal data.\n\nTheir pre-print, On the Conversational Persuasiveness of Large Language\nModels: A Randomized Controlled Trial, explains that the debates were\nstructured based on a simplified version of the format commonly used in\ncompetitive academic debates and participants were asked before and afterwards\nhow much they agreed with the debate proposition.\n\nThe results showed that participants who debated GPT-4 with access to their\npersonal information had 81.7% higher odds of increased agreement with their\nopponents compared to participants who debated humans. Without\npersonalization, GPT-4 still outperformed humans, but the effect was far\nlower.\n\nCambridge Analytica on steroids\n\nNot only are LLMs able to effectively exploit personal information to tailor\ntheir arguments and out-persuade humans in online conversations through\nmicrotargeting, they do so far more effectively than humans.\n\n\u201cWe were very surprised by the 82% number and if you think back to Cambridge\nAnalytica, which didn\u2019t use any of the current tech, you take Facebook likes\nand hook them up with an LLM, the Language Model can personalize its messaging\nto what it knows about you. This is Cambridge Analytica on steroids,\u201d said\nWest. \u201cIn the context of the upcoming US elections, people are concerned\nbecause that\u2019s where this kind of technology is always first battle tested.\nOne thing we know for sure is that people will be using the power of large\nlanguage models to try to swing the election.\u201d\n\nOne interesting finding of the research was that when a human was given the\nsame personal information as the AI, they didn\u2019t seem to make effective use of\nit for persuasion. West argues that this should be expected \u2013 AI models are\nconsistently better because they are almost every human on the internet put\ntogether.\n\nThe models have learnt through online patterns that a certain way of making an\nargument is more likely to lead to a persuasive outcome. They have read many\nmillions of Reddit, Twitter and Facebook threads, and been trained on books\nand papers from psychology about persuasion. It\u2019s unclear exactly how a model\nleverages all this information but West believes this is a key direction for\nfuture research.\n\n\u201cLLMs have shown signs that they can reason about themselves, so given that we\nare able to interrogate them, I can imagine that we could ask a model to\nexplain its choices and why it is saying a precise thing to a particular\nperson with particular properties. There\u2019s a lot to be explored here because\nthe models may be doing things that we don\u2019t even know about yet in terms of\npersuasiveness, cobbled together from many different parts of the knowledge\nthat they have.\u201d\n\nAuthor: Tanya Petersen\n\nSource: EPFL\n\nThis content is distributed under a Creative Commons CC BY-SA 4.0 license. You\nmay freely reproduce the text, videos and images it contains, provided that\nyou indicate the author\u2019s name and place no restrictions on the subsequent use\nof the content. If you would like to reproduce an illustration that does not\ncontain the CC BY-SA notice, you must obtain approval from the author.\n\n15.04.24\n\n## Tags\n\nartificial intelligencecommunicationDatadata scienceInternetResearchRobert\nWestsocial media\n\n## News\n\n  * All EPFL news\n  * All news\n\n## Subscription\n\nReceive an email for each new article\n\nShare on\n\nLogin\n\n  * Contact\n  * EPFL CH-1015 Lausanne\n  * +41 21 693 11 11\n\nFollow the pulses of EPFL on social networks\n\n  * Follow us on Facebook.\n  * Follow us on Instagram.\n  * Follow us on LinkedIn.\n  * Follow us on X.\n  * Follow us on Youtube.\n\nAccessibility Legal notice Privacy Policy\n\n\u00a9 2024 EPFL, all rights reserved\n\n", "frontpage": false}
