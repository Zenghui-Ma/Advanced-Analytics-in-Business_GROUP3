{"aid": "40145769", "title": "Diarizers: Fine-tune speaker diarization models", "url": "https://github.com/huggingface/diarizers", "domain": "github.com/huggingface", "votes": 1, "user": "zerojames", "posted_at": "2024-04-24 15:44:02", "comments": 0, "source_title": "GitHub - huggingface/diarizers", "source_text": "GitHub - huggingface/diarizers\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nhuggingface / diarizers Public\n\n  * Notifications\n  * Fork 2\n  * Star 39\n\n39 stars 2 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# huggingface/diarizers\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nkamilakesbiupdate readmeApr 24, 20241ebb2dd \u00b7 Apr 24, 2024Apr 24, 2024\n\n## History\n\n97 Commits  \n  \n### datasets\n\n|\n\n### datasets\n\n| minor fix readme| Apr 22, 2024  \n  \n### sanity_checks\n\n|\n\n### sanity_checks\n\n| update sanity_checks| Apr 21, 2024  \n  \n### src/diarizers\n\n|\n\n### src/diarizers\n\n| update sanity_checks| Apr 21, 2024  \n  \n### utils\n\n|\n\n### utils\n\n| prepare packaging| Apr 12, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| fix hyperparameters readme| Apr 17, 2024  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| requirements.txt| Apr 12, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| update readme| Apr 24, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| prepare packaging| Apr 12, 2024  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| relax transformers dependency| Apr 20, 2024  \n  \n### test_segmentation.py\n\n|\n\n### test_segmentation.py\n\n| minor fix readme| Apr 22, 2024  \n  \n### train_segmentation.py\n\n|\n\n### train_segmentation.py\n\n| minor fix readme| Apr 22, 2024  \n  \n## Repository files navigation\n\n# \ud83e\udd17 Diarizers\n\n\ud83e\udd17 Diarizers is a library for fine-tuning pyannote speaker diarization models\nusing the Hugging Face ecosystem. It can be used to improve performance on\nboth English and multilingual diarization datasets with simple example\nscripts, with as little as ten hours of labelled diarization data and just 5\nminutes of GPU compute time.\n\n## \ud83d\udcd6 Quick Index\n\n  * Installation\n  * Train\n  * Evaluation\n  * Inference\n  * Adding new datasets\n  * Acknowledgements\n  * Citation\n\n## Installation\n\nFirst, clone the repository and install the dependencies:\n\n    \n    \n    git clone https://github.com/huggingface/diarizers.git cd diarizers pip install -e .\n\nTo load pre-trained diarization models from the Hub, you'll first need to\naccept the terms-of-use for the following two models:\n\n  1. pyannote/segmentation-3.0\n  2. pyannote/speaker-diarization-3.1\n\nTo load the CallHome dataset from the Hub, you'll also need to accept its\nterms of use:\n\n  1. diarizers-community/callhome\n\nAnd subsequently use a Hugging Face authentication token to log in with:\n\n    \n    \n    huggingface-cli login\n\n## Train\n\nThe script train_segmentation.py can be used to pre-process a diarization\ndataset and subsequently fine-tune the pyannote segmentation model. In the\nfollowing example, we fine-tune the segmentation model on the Japanese subset\nof the CallHome dataset, a conversational dataset between native speakers:\n\n    \n    \n    python3 train_segmentation.py \\ --dataset_name=diarizers-community/callhome \\ --dataset_config_name=jpn \\ --split_on_subset=data \\ --model_name_or_path=pyannote/segmentation-3.0 \\ --output_dir=./speaker-segmentation-fine-tuned-callhome-jpn \\ --do_train \\ --do_eval \\ --learning_rate=1e-3 \\ --num_train_epochs=5 \\ --lr_scheduler_type=cosine \\ --per_device_train_batch_size=32 \\ --per_device_eval_batch_size=32 \\ --evaluation_strategy=epoch \\ --save_strategy=epoch \\ --preprocessing_num_workers=2 \\ --dataloader_num_workers=2 \\ --logging_steps=100 \\ --load_best_model_at_end \\ --push_to_hub\n\nOn a single NVIDIA RTX 24GB GPU, training takes approximately 5 minutes and\nimproves the diarization error rate (DER) from 32% to 23%, representing a 28%\nrelative improvement in performance. The final model will be pushed to the\nHugging Face Hub, for example the checkpoint diarizers-community/speaker-\nsegmentation-fine-tuned-callhome-jpn.\n\nWe encourage you to swap the CallHome Japanese dataset for a dataset in your\nlanguage of choice. The CallHome dataset provides splits for four additional\nlanguages, and there are a number of other diarization datasets available on\nthe Hugging Face Hub. We also provide instructions for adding new datasets.\n\nTo train on a different dataset, simply change the arguments:\n\n  * dataset_name: Specify a dataset from the Hub on which to fine-tune your model.\n  * dataset_config_name: If the dataset contains multiple language subsets, select the language ID of the subset you want to train on.\n\nIf the data set doesn't contain a train and a validation split, you can\nautomatically split it into train-val-test (90-10-10) by setting the argument:\n\n  * split_on_subset: Specify the subset of the dataset you want to split into train-val-set.\n\nImportant\n\nFor now, this library can only be used to fine-tune the segmentation model\nfrom the speaker diarization pipeline. Future work will aim to help optimise\nthe hyperparameters of the entire pipeline.\n\n## Evaluation\n\nThe script test_segmentation.py can be used to evaluate a fine-tuned model on\na diarization dataset. In the following example, we evaluate the fine-tuned\nmodel from the previous step on the test split of the CallHome Japanese\ndataset:\n\n    \n    \n    python3 test_segmentation.py \\ --dataset_name=diarizers-community/callhome \\ --dataset_config_name=jpn \\ --split_on_subset=data \\ --test_split_name=test \\ --model_name_or_path=diarizers-community/speaker-segmentation-fine-tuned-callhome-jpn \\ --preprocessing_num_workers=2\n\n## Inference with pyannote\n\nThe fine-tuned segmentation model can easily be loaded into the pyannote\nspeaker diarization pipeline for inference. To do so, we load the pre-trained\nspeaker diarization pipeline, and subsequently override the segmentation model\nwith our fine-tuned checkpoint:\n\n    \n    \n    from diarizers import SegmentationModel from pyannote.audio import Pipeline from datasets import load_dataset import torch device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\") # load the pre-trained pyannote pipeline pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\") pipeline.to(device) # replace the segmentation model with your fine-tuned one model = SegmentationModel().from_pretrained(\"diarizers-community/speaker-segmentation-fine-tuned-callhome-jpn\") model = model.to_pyannote_model() pipeline._segmentation.model = model.to(device) # load dataset example dataset = load_dataset(\"diarizers-community/callhome\", \"jpn\", split=\"data\") sample = dataset[0][\"audio\"] # pre-process inputs sample[\"waveform\"] = torch.from_numpy(sample.pop(\"array\")[None, :]).to(device, dtype=model.dtype) sample[\"sample_rate\"] = sample.pop(\"sampling_rate\") # perform inference diarization = pipeline(sample) # dump the diarization output to disk using RTTM format with open(\"audio.rttm\", \"w\") as rttm: diarization.write_rttm(rttm)\n\nTo apply the diarization pipeline directly to an audio file, simply call:\n\n    \n    \n    diarization = pipeline(\"audio.wav\")\n\n## Adding new datasets\n\nIn order to be compatible with our training script, the Hugging Face dataset\nshould contain the following features:\n\n  * audio: Audio feature.\n  * speakers: The list of audio speakers, with their order of appearance.\n  * timestamps_start: A list of timestamps indicating the start of each speaker segment.\n  * timestamps_end: A list of timestamps indicating the end of each speaker segment.\n\nWe added several speaker-diarization datasets to the hub in the diarizers-\ncommunity organisation. These datasets have been generated using the scripts\nin datasets/spd_datasets.py : The idea is to convert any raw speaker\ndiarization dataset containing <audio, annotation> pairs into a Hugging Face\ndataset.\n\nSee Adding a dataset for more details on how to add speaker diarization\ndatasets to the hub.\n\n## Acknowledgements\n\nThis library builds on top of pyannote library as well as several Hugging Face\nlibraries (transformers, datasets, accelerate). We would like to extend our\nwarmest thanks to their developers!\n\n## Citation\n\nIf you found this repository useful, please consider citing this work and also\nthe original pyannote paper:\n\n    \n    \n    @misc{akesbi-diarizers, author = {Kamil Akesbi and Sanchit Gandhi}, title = {\"Diarizers: A repository for fine-tuning speaker diarization models\"}, year = {2024}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\\url{https://github.com/huggingface/diarizers}} }\n    \n    \n    @inproceedings{bredin-pyannote, author={Herv\u00e9 Bredin}, title={\"pyannote.audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe\"}, year={2023}, booktitle={Proc. INTERSPEECH 2023}, }\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\nReadme\n\nActivity\n\nCustom properties\n\n### Stars\n\n39 stars\n\n### Watchers\n\n2 watching\n\n### Forks\n\n2 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 2\n\n  * kamilakesbi Kamil Akesbi\n  * sanchit-gandhi Sanchit Gandhi\n\n## Languages\n\n  * Python 98.5%\n  * Makefile 1.5%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
