{"aid": "40074454", "title": "Gemma Family Expands with Models Tailored for Developers and Researchers", "url": "https://developers.googleblog.com/2024/04/gemma-family-expands.html", "domain": "googleblog.com", "votes": 1, "user": "tosh", "posted_at": "2024-04-18 09:38:03", "comments": 0, "source_title": "Gemma Family Expands with Models Tailored for Developers and Researchers", "source_text": "Gemma Family Expands with Models Tailored for Developers and Researchers -\nGoogle for Developers\n\nBack to Google for Developers\n\nLatest Get Inspired Announcements Events Resources\n\nTags\n\n* Latest\n* Get Inspired\n* Announcements\n* Events\n* Resources\n\nBack to Google for Developers\n\n# Gemma Family Expands with Models Tailored for Developers and Researchers\n\nApril 09, 2024\n\nLink copied to clipboard\n\nPosted by Tris Warkentin \u2013 Director, Product Management and Jane Fine - Senior\nProduct Manager\n\nIn February we announced Gemma, our family of lightweight, state-of-the-art\nopen models built from the same research and technology used to create the\nGemini models. The community's incredible response \u2013 including impressive\nfine-tuned variants, Kaggle notebooks, integration into tools and services,\nrecipes for RAG using databases like MongoDB, and lots more \u2013 has been truly\ninspiring.\n\nToday, we're excited to announce our first round of additions to the Gemma\nfamily, expanding the possibilities for ML developers to innovate responsibly:\nCodeGemma for code completion and generation tasks as well as instruction\nfollowing, and RecurrentGemma, an efficiency-optimized architecture for\nresearch experimentation. Plus, we're sharing some updates to Gemma and our\nterms aimed at improvements based on invaluable feedback we've heard from the\ncommunity and our partners.\n\n## Introducing the first two Gemma variants\n\n### CodeGemma: Code completion, generation, and chat for developers and\nbusinesses\n\nHarnessing the foundation of our Gemma models, CodeGemma brings powerful yet\nlightweight coding capabilities to the community. CodeGemma models are\navailable as a 7B pretrained variant that specializes in code completion and\ncode generation tasks, a 7B instruction-tuned variant for code chat and\ninstruction-following, and a 2B pretrained variant for fast code completion\nthat fits on your local computer. CodeGemma models have several advantages:\n\n>   * Intelligent code completion and generation: Complete lines, functions,\n> and even generate entire blocks of code \u2013 whether you're working locally or\n> leveraging cloud resources.\n\n>   * Enhanced accuracy: Trained on 500 billion tokens of primarily English\n> language data from web documents, mathematics, and code, CodeGemma models\n> generate code that's not only more syntactically correct but also\n> semantically meaningful, helping reduce errors and debugging time.\n\n>   * Multi-language proficiency: Your invaluable coding assistant for Python,\n> JavaScript, Java, and other popular languages.\n\n>   * Streamlined workflows: Integrate a CodeGemma model into your development\n> environment to write less boilerplate, and focus on interesting and\n> differentiated code that matters \u2013 faster.\n\nThis table compares the performance of CodeGemma with other similar models on\nboth single and multi-line code completion tasks. Learn more in the technical\nreport.  \n---  \n  \nLearn more about CodeGemma in our report or try it in this quickstart guide.\n\n### RecurrentGemma: Efficient, faster inference at higher batch sizes for\nresearchers\n\nRecurrentGemma is a technically distinct model that leverages recurrent neural\nnetworks and local attention to improve memory efficiency. While achieving\nsimilar benchmark score performance to the Gemma 2B model, RecurrentGemma's\nunique architecture results in several advantages:\n\n>   * Reduced memory usage: Lower memory requirements allow for the generation\n> of longer samples on devices with limited memory, such as single GPUs or\n> CPUs.\n\n>   * Higher throughput: Because of its reduced memory usage, RecurrentGemma\n> can perform inference at significantly higher batch sizes, thus generating\n> substantially more tokens per second (especially when generating long\n> sequences).\n\n>   * Research innovation: RecurrentGemma showcases a non-transformer model\n> that achieves high performance, highlighting advancements in deep learning\n> research.\n\nThis chart reveals how RecurrentGemma maintains its sampling speed regardless\nof sequence length, while Transformer-based models like Gemma slow down as\nsequences get longer.  \n---  \n  \nTo understand the underlying technology, check out our paper. For practical\nexploration, try the notebook, which demonstrates how to finetune the model.\n\n## Built upon Gemma foundations, expanding capabilities\n\nGuided by the same principles of the original Gemma models, the new model\nvariants offer:\n\n>   * Open availability: Encourages innovation and collaboration with its\n> availability to everyone and flexible terms of use.\n\n>   * High-performance and efficient capabilities: Advances the capabilities\n> of open models with code-specific domain expertise and optimized design for\n> exceptionally fast completion and generation.\n\n>   * Responsible design: Our commitment to responsible AI helps ensure the\n> models deliver safe and reliable results.\n\n>   * Flexibility for diverse software and hardware:\n>     * Both CodeGemma and RecurrentGemma: Built with JAX and compatible with\n> JAX, PyTorch, , Hugging Face Transformers, and Gemma.cpp. Enable local\n> experimentation and cost-effective deployment across various hardware,\n> including laptops, desktops, NVIDIA GPUs, and Google Cloud TPUs.\n\n>     * CodeGemma: Additionally compatible with Keras, NVIDIA NeMo, TensorRT-\n> LLM, Optimum-NVIDIA, MediaPipe, and availability on Vertex AI.\n\n>     * RecurrentGemma: Support for all the aforementioned products will be\n> available in the coming weeks.\n\n## Gemma 1.1 update\n\nAlongside the new model variants, we're releasing Gemma 1.1, which includes\nperformance improvements. Additionally, we've listened to developer feedback,\nfixed bugs, and updated our terms to provide more flexibility.\n\n## Get started today\n\nThese first Gemma model variants are available in various places worldwide,\nstarting today on Kaggle, Hugging Face, and Vertex AI Model Garden. Here's how\nto get started:\n\n>   * Access the models: Visit the Gemma website, Vertex AI Model Garden,\n> Hugging Face, NVIDIA NIM APIs, or Kaggle for download instructions.\n\n>   * Explore integration options: Find guides and resources for integrating\n> the models with your favorite tools and platforms.\n\n>   * Experiment and innovate: Add a Gemma model variant to your next project\n> and explore its capabilities.\n\nWe invite you to try the CodeGemma and RecurrentGemma models and share your\nfeedback on Kaggle. Together, let's shape the future of AI-powered content\ncreation and understanding.\n\nAI Announcements Beginner Explore Gemini Generative AI Google Cloud Next '24\n\nNext post Previous post\n\nDiese Website verwendet Cookies von Google, um Dienste anzubieten und Zugriffe\nzu analysieren. Deine IP-Adresse und dein User-Agent werden zusammen mit\nMesswerten zur Leistung und Sicherheit f\u00fcr Google freigegeben. So k\u00f6nnen\nNutzungsstatistiken generiert, Missbrauchsf\u00e4lle erkannt und behoben und die\nQualit\u00e4t des Dienstes gew\u00e4hrleistet werden.Weitere InformationenOk\n\n", "frontpage": false}
