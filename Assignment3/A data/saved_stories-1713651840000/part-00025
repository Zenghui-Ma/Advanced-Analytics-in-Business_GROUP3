{"aid": "40098367", "title": "Show HN: Color Naming: Human vs. GPT-4", "url": "https://beklein.com/posts/color-naming/", "domain": "beklein.com", "votes": 3, "user": "beklein", "posted_at": "2024-04-20 16:07:44", "comments": 0, "source_title": "Color Naming: Human vs. GPT-4", "source_text": "Color Naming: Human vs. GPT-4 \u00b7 beklein\n\n\u2193Skip to main content\n\n# Color Naming: Human vs. GPT-4\n\n20 April 2024\u00b7971 words\u00b75 mins\n\nAuthor\n\nBernd Klein\n\nInterested in solving problems in robotics and AI.\n\nOne of the most interesting questions you can ask young children is, \u201cTell me\nwhat color this is?\u201d\n\nIt\u2019s quite amusing what answers you might receive as they learn to classify\ntheir visual input according to our cultural standards. I sometimes like to\nthink of our current AI models as young children\u2014but with rhetorical\nsuperpowers. They are eager to answer all our questions, regardless of knowing\nif they are right or wrong.\n\nSo, a new idea was born: Let\u2019s ask ChatGPT to tell us what color it sees and\ncompare it to human color naming in a small-scale experiment.\n\nFor this purpose, I used the GPT-4 Turbo with Vision API to run an experiment,\nshowing the model more than 1,000 images, each in a different color.\n\nI\u2019ve then compared the responses from GPT-4 with the results of the Color\nSurvey conducted in 2010 by Randall Munroe, the author of the popular web\ncomic xkcd.\n\n##\n\nResults\n\n#\n\nIn summary the model agrees with humans most of the time.\n\nThis might seem like a mundane result, but if we are to build AI systems that\nalign with human understanding, it\u2019s reassuring that we won\u2019t have\ndisagreements over color names.\n\nIn fact, this alignment is quite useful when working with documents that\ninclude images, such as PDFs in the fields of science and engineering.\n\nA common use case for me involves analyzing PDFs containing graphs, diagrams,\nand photos. Asking ChatGPT to identify all images containing a green cable and\nto determine its possible function is a useful skill for an AI model.\n(However, remember to double-check the results.)\n\nBut as always, with LLMs, there are some limitations, and the one I found is\nthe following.\n\n###\n\nThe Pink Elephant in the Room\n\n#\n\nGPT-4 failed to name any of the pinkish colors as a human would.\n\nBecause of this odd observation I\u2019ve repeated these experiments for all the\ncolors in the results graph above 10 times and never received pink as an\nanswer.\n\nFor most colors in this group, the results were a mix of magenta and sometimes\nfuchsia, with magenta always the clear winner.\n\nIn total I\u2019ve tested around 1,000 different colors, see More Results, and I\nnoted a slight aversion for the model to use pink in many other cases.\n\nMy best guess is that this behavior is somehow related to efforts to remove\nany gender-related biases in colors within large language models, but it could\nalso just be a result of the training data, training process, and/or human\nfeedback. We will probably never know for sure.\n\n###\n\nYellow vs. Green\n\n#\n\nAnother observation is that GTP-4 has some issues to name the color yellow\ncorrectly.\n\nYellow is sometimes named as chartreuse, the name of a French herbal liqueur.\nIn the full data this name comes up 17 times for different hues of yellow.\nGenerally speaking, GPT-4 drifts towards the greenish color names, such as\nlemon, lime yellow.\n\nA follow up experiment that measures the distances of the embeddings for these\ncolor images might help us to understand how GPT-4 understands colors and the\ncolor space better.\n\nLet me know if you are interested in such an article.\n\n##\n\nThe Code\n\n#\n\nIf you are interested in the details, read on to learn how to run similar\nexperiments yourself.\n\nYou can conduct your own experiments following the code snippets below.\n\nFirst we have to create the images using Pillow, a popular Python imaging\nlibrary.\n\n    \n    \n    from PIL import Image # Create a image with one specific color and size def create_image(color: str, dim_x: int, dim_y: int, image_path: str): image = Image.new(\"RGB\", (dim_x, dim_y), color) image.save(image_path)\n\nYou can specify the color as a hexadecimal color code, the size of the image\nin pixels and the name of the output file by passing in the specific function\nparameters.\n\nFor example create_image(\"#FED100\", 128, 128, \"yellow.png\") will then create a\nyellow square, like this.\n\nOnce we have all our image files, we can use the example code from the OpenAI\nDocs to encode each image file in Base64, and we change the prompt so that we\nwill get the name of the color in the image. In my experiments I\u2019ve been using\nthe following prompt that worked well for me: \u201cName the main color in the\nimage. Use one word or if needed two words to name the color. Only provide the\nname of the color as answer.\u201d\n\n    \n    \n    import base64 import json import requests # OpenAI API Key api_key = \"YOUR_OPENAI_API_KEY\" # Encode image in base64 encoded format def encode_image(image_path: str): with open(image_path, \"rb\") as image_file: return base64.b64encode(image_file.read()).decode(\"utf-8\") # Analyze image color via GPT-4-Vision API def analyze_color(hex_code: str): image_path = hex_code + \".png\" create_image(hex_code, 128, 128, image_path) base64_image = encode_image(image_path) headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"} payload = { \"model\": \"gpt-4-turbo\", \"messages\": [ { \"role\": \"user\", \"content\": [ { \"type\": \"text\", \"text\": \"Name the main color in the image. Use one word or if needed two words to name the color. Only provide the name of the color as answer.\", }, { \"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}, }, ], } ], \"max_tokens\": 300, } response = requests.post( \"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload ) result = response.json() color_name = result[\"choices\"][0][\"message\"][\"content\"] # return hex_code return color_name.lower()\n\nFor the analysis of around 1,000 images, I\u2019ve paid approximately 3\u20ac for API\nusage to OpenAI.\n\nThere are many open questions and things to explore in this space, and I would\nbe delighted to hear about your results and findings.\n\n##\n\nMore Results\n\n#\n\nIn the initial color survey, the author also published a txt file that\ncontains \u201cthe 954 most common RGB monitor colors, as defined by several\nhundred thousand participants in the xkcd color name survey\u201d.\n\nI asked GPT-4 to name all those colors from above.\n\nThe full comparison between names of these colors by humans vs. AI can be\ndownloaded here as a JSON file.\n\n\u2191\n\n\u00a9 2024 beklein.com\n\nPowered by Hugo & Blowfish\n\n", "frontpage": true}
