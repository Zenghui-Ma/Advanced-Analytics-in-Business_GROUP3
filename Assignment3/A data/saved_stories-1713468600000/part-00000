{"aid": "40075990", "title": "Optimizing WebKit and Safari for Speedometer 3.0", "url": "https://webkit.org/blog/15249/optimizing-webkit-safari-for-speedometer-3-0/", "domain": "webkit.org", "votes": 2, "user": "PaulHoule", "posted_at": "2024-04-18 13:27:58", "comments": 0, "source_title": "Optimizing WebKit & Safari for Speedometer 3.0", "source_text": "Optimizing WebKit & Safari for Speedometer 3.0 | WebKit\n\nWebKit\n\n# Optimizing WebKit & Safari for Speedometer 3.0\n\nApr 10, 2024\n\nby Alan Baradlay, Antti Koivisto, Matt Woodrow, Patrick Angle, Ryosuke Niwa,\nVitor Ribeiro Roriz, Wenson Hsieh, and Yusuke Suzuki\n\nThe introduction of Speedometer 3.0 is a major step forward in making the web\nfaster for all, and allowing Web developers to make websites and web apps that\nwere not previously possible. In this article, we explore ways the WebKit team\nmade performance optimizations in WebKit and Safari based on the Speedometer\n3.0 benchmark.\n\nIn order to make these improvements, we made an extensive use of our\nperformance testing infrastructure. It\u2019s integrated with our continuous\nintegration, and provides the capability to schedule A/B tests. This allows\nengineers to quickly test out performance optimizations and catch new\nperformance regressions.\n\n## Improving Tools\n\nProper tooling support is the key to identifying and addressing performance\nbottlenecks. We defined new internal JSON format for JavaScriptCore sampling\nprofiler output to dump and process them offline. It includes a script which\nprocesses and generates analysis of hot functions and hot byte codes for\nJavaScriptCore. We also added FlameGraph generation tool for the dumped\nsampling profiler output which visualizes performance bottlenecks. In\naddition, we added support for JITDump generation on Darwin platforms to dump\nJIT related information during execution. And we improved generated JITDump\ninformation for easy use as well. These tooling improvements allowed us to\nquickly identify bottlenecks across Speedometer 3.0.\n\n## Improving JavaScriptCore\n\n### Revising Megamorphic Inline Cache (IC)\n\nMegamorphic IC offers faster property access when one property access site\nobserves many different object types and/or property names. We observed that\nsome frameworks such as React contain a megamorphic property access. This led\nus to continuously improve JavaScriptCore\u2019s megamorphic property access\noptimizations: expanding put megamorphic IC, adding megamorphic IC for the in\noperation, and adding generic improvements for megamorphic IC.\n\n### Revising Call IC\n\nCall IC offers faster function calls by caching call targets inline. We\nredesigned Call IC and we integrated two different architectures into\ndifferent tiers of Just-In-Time (JIT) compilers. Lower level tiers use Call IC\nwithout any JIT code generation and the highest level tier uses JIT code\ngeneratiton with the fastest Call IC. There is a tradeoff between code\ngeneration time and code efficiency, and JavaScriptCore performs a balancing\nact between them to achieve the best performance across different tiers.\n\n### Optimizing JSON\n\nSpeedometer 3.0 also presented new optimization opportunities to our JSON\nimplementations as they contain more non-ASCII characters than before. We made\nour fast JSON stringifier work for unicode characters. We also analyzed\nprofile data carefully and made JSON.parse faster than ever.\n\n### Adjusting Inlining Heuristics\n\nThere are many tradeoffs when inlining functions in JavaScript. For example,\ninline functions can more aggressively increase the total bytecode size and\nmay cause memory bandwidth to become a new bottleneck. The amount of\ninstruction cache available in CPU can also influence how effective a given\ninlining strategy is. And the calculus of these tradeoffs change over time as\nwe make more improvements to JavaScriptCore such as adding new bytecode\ninstruction and changes to DFG\u2019s numerous optimization phases. We took the\nrelease of the new Speedometer 3.0 benchmark as an opportunity to adjust\ninlining heuristics based on data collected in modern Apple silicon Macs with\nthe latest JavaScriptCore.\n\n### Make JIT Code Destruction Lazy\n\nDue to complicated conditions, JavaScriptCore eagerly destroyed CodeBlock and\nJIT code when GC detects they are dead. Since these destructions are costly,\nthey should be delayed and processed while the browser is idle. We made\nchanges so that they are now destroyed lazily, during idle time in most cases.\n\n### Opportunistic Sweeping and Garbage Collection\n\nIn addition, we noticed that a significant amount of time goes into performing\ngarbage collection and incremental sweeping across all subtests in both\nSpeedometer 2.1 and 3.0. In particular, if a subtest allocated a large number\nof JavaScript objects on the heap, we would often spend a significant amount\nof time in subsequent subtests collecting these objects. This had several\neffects:\n\n  1. Increasing synchronous time intervals on many subtests due to on-demand sweeping and garbage collection when hitting heap size limits.\n  2. Increasing asynchronous time intervals on many subtests due to asynchronous garbage collection or timer-based incremental sweeping triggering immediately after the synchronous timing interval.\n  3. Increasing overall variance depending on whether timer-based incremental sweeping and garbage collection would fall in the synchronous or asynchronous timing windows of any given subtest.\n\nAt a high level, we realized that some of this work could be performed\nopportunistically in between rendering updates \u2014 that is, during idle time \u2014\ninstead of triggering in the middle of subtests. To achieve this, we\nintroduced a new mechanism in WebCore to provide hints to JavaScriptCore to\nopportunistically perform scheduled work after the previous rendering update\nhas completed until a given deadline (determined by the estimated remaining\ntime until the next rendering update). The opportunistic task scheduler also\naccounts for imminently scheduled zero delay timers or pending\nrequestAnimationFrame callbacks: if it observes either, it\u2019s less likely to\nschedule opportunistic work in order to avoid interference with imminent\nscript execution. We currently perform a couple types of opportunistically\nscheduled tasks:\n\n  * Incremental Sweeping: Prior to the opportunistic task scheduler, incremental sweeping in JavaScriptCore was automatically triggered by a periodically scheduled 100 ms timer. This had the effect of occasionally triggering incremental sweeping during asynchronous timing intervals, but also wasn\u2019t aggressive enough to prevent on-demand sweeping in the middle of script execution. Now that JavaScriptCore is knowledgable about when to opportunistically schedule tasks, it can instead perform the majority of incremental sweeping in between rendering updates while there aren\u2019t imminently scheduled timers. The process of sweeping is also granular to each marked block, which allows us to halt opportunistic sweeping early if we\u2019re about to exceed the deadline for the next estimated rendering update.\n  * Garbage Collection: By tracking the amount of time spent performing garbage collection in previous cycles, we\u2019re able to roughly estimate the amount of time needed to perform the next garbage collection based on the number of bytes visited or allocated since the last cycle. If the remaining duration for performing opportunistically scheduled tasks is longer than this estimated garbage collection duration, we immediately perform either an Eden collection or full garbage collection. Furthermore, we integrated activity-based garbage collections into this new scheme to schedule them at appropriate timing.\n\nOverall, this strategy yields a 6.5% total improvement in Speedometer 3.0*,\ndecreasing the time spent in every subtest by a significant margin, and a 6.9%\ntotal improvement in Speedometer 2.1*, significantly decreasing the time spent\nin nearly all subtests.\n\n* macOS 14.4, MacBook Air (M2, 2022)\n\n### Various Miscellaneous Optimizations for Real World Use Cases\n\nWe extensively reviewed all Speedometer 3.0 subtests and did many\noptimizations for realistic use cases. The examples include but are not\nlimited to: faster Object.assign with empty objects, improving object spread\nperformance, and so on.\n\n## Improving DOM code\n\nImproving DOM code is Speedometer\u2019s namesake, and that\u2019s exactly what we did.\nFor example, we now store the NodeType in the Node object itself instead of\nrelying on a virtual function call. We also made DOMParser use a fast parser,\nimproved its support of li elements, and made DOMParser not construct a\nredundant DocumentFragment. Together, these changes improved TodoMVC-\nJavaScript-ES5 by ~20%. We also eliminated O(n^2) behavior in the fast parser\nfor about ~0.5% overall progression in Speedometer 3.0. We also made input\nelements construct their user-agent shadow tree lazily during construction and\ncloning, the latter of which is new in Speedometer 3.0 due to web components\nand Lit tests. We devirtualized many functions and inlined more functions to\nreduce the function call overheads. We carefully reviewed performance profile\ndata and removed inefficiency in hot paths like repeated reparsing of the same\nURLs.\n\n## Improving Layout and Rendering\n\nWe landed a number of important optimizations in our layout and rendering\ncode. First off, most type checks performed on RenderObject are now done using\nan inline enum class instead of virtual function calls, this alone is\nresponsible for around ~0.7% of overall progression in Speedometer 3.0.\n\n### Improving Style Engine\n\nWe also optimized the way we compute the properties animated by Web Animations\ncode. Previously, we were enumerating every animatable properties while\nresolving transition: all. We optimized this code to only enumerate affected\nproperties. This was ~0.7% overall Speedometer 3.0 progression. Animating\nelements can now be resolved without fully recomputing their style unless\nnecessary for correctness.\n\nSpeedometer 3.0 content, like many modern web sites, uses CSS custom\nproperties extensively. We implemented significant optimizations to improve\ntheir performance. Most custom property references are now resolved via fast\ncache lookups, avoiding expensive style resolution time property parsing.\nCustom properties are now stored in a new hierarchical data structure that\nreduces memory usage as well.\n\nOne key component of WebKit styling performance is a cache (called \u201cmatched\ndeclarations cache\u201d) that maps directly from a set of CSS declarations to the\nfinal element style, avoiding repeating expensive style building steps for\nidentically styled elements. We significantly improved the hit rate of this\ncache.\n\nWe also improved styling performance of author shadow trees, allowing trees\nwith identical styles to share style data more effectively.\n\n### Improving Inline Layout\n\nWe fixed a number of performance bottlenecks in inline layout engine as well.\nEliminating complex text path in Editor-TipTap was a major ~7% overall\nimprovement. To understand this optimization, WebKit has two different code\npaths for text layout: the simple text path, which uses low level font API to\naccess raw font data, and the complex text path, which uses CoreText for\ncomplex shaping and ligatures. The simple text path is faster but it does not\ncover all the edge cases. The complex text path has full coverage but is\nslower than the simple text path.\n\nPreviously, we were taking the complex text path whenever a non-default value\nof font-feature or font-variant was used. This is because historically the\nsimple text path wouldn\u2019t support these operations. However, we noticed that\nthe only feature of these still missing in the simple text path was font-\nvariant-caps. By implementing font-variant-caps support for the simple text\npath, we allowed the simple text path to handle the benchmark content. This\nresulted in 4.5x improvement in Editor-TipTap subtest, and ~7% overall\nprogression in Speedometer 3.0.\n\nIn addition to improving the handling of text content in WebKit, we also\nworked with CoreText team to avoid unnecessary work in laying out glyphs. This\nresulted in ~0.5% overall progression in Speedometer 3.0, and these\nperformance gains will benefit not just WebKit but other frameworks and\napplications that use CoreText.\n\n### Improving SVG Layout\n\nAnother area we landed many optimizations for is SVG. Speedometer 3.0 contains\na fair bit of SVG content in test cases such as React-Stockcharts-SVG. We were\nspending a lot of time computing the bounding box for repaint by creating\nGraphicsContext, applying all styles, and actually drawing strokes in\nCoreGraphics. Here, we adopted Blink\u2019s optimization to approximate bounding\nbox and made ~6% improvement in React-Stockcharts-SVG subtest. We also\neliminated O(n^2) algorithm in SVG text layout code, which made some SVG\ncontent load a lot quicker.\n\n### Improving IOSurface Cache Hit Rate\n\nAnother optimization we did involve improving the cache hit rate of IOSurface.\nAn IOSurface is a bitmap image buffer we use to paint web contents into. Since\ncreating this object is rather expensive, we have a cache of IOSurface objects\nbased on their dimensions. We observed that the cache hit rate was rather low\n(~30%) so we increased the cache size from 64MB to 256MB on macOS and improved\nthe cache hit rate by 2.7x to ~80%, improving the overall Speedometer 3.0\nscore by ~0.7%. In practice, this means lower latency for canvas operations\nand other painting operations.\n\n### Reducing Wait Time for GPU Process\n\nPreviously, we required a synchronous IPC call from the Web Process to the GPU\nprocess to determine which of the existing buffers had been released by\nCoreAnimation and was suitable to use for the next frame. We optimized this by\nhaving the GPUP just select (or allocate) an appropriate buffer, and direct\nall incoming drawing commands to the right destination without requiring any\nresponse. We also changed the delivery of any newly allocated IOSurface\nhandles to go via a background helper thread, rather than blocking the Web\nProcess\u2019s main thread.\n\n### Improving Compositing\n\nUpdates to compositing layers are now batched, and flushed during rendering\nupdates, rather than computed during every layout. This significantly reduces\nthe cost of script-incurred layout flushes.\n\n## Improving Safari\n\nIn addition to optimizations we made in WebKit, there were a handful of\noptimizations for Safari as well.\n\n### Optimizing AutoFill Code\n\nOne area we looked at was Safari\u2019s AutoFill code. Safari uses JavaScript to\nimplement its AutoFill logic, and this execution time was showing up in the\nSpeedometer 3.0 profile. We made this code significantly faster by waiting for\nthe contents of the page to settle before performing some work for AutoFill.\nThis includes coalescing handling of newly focused fields until after the page\nhad finished loading when possible, and moving lower-priority work out of the\ncritical path of loading and presenting the page for long-loading pages. This\nwas responsible for ~13% progression in TodoMVC-React-Complex-DOM and ~1%\nprogression in numerous other tests, improving the overall Speedometer 3.0\nscore by ~0.9%.\n\n## Profile Guided Optimizations\n\nIn addition to making the above code changes, we also adjusted our profile-\nguided optimizations to take Speedometer 3.0 into account. This allowed us to\nimprove the overall Speedometer 3.0 score by 1~1.6%. It\u2019s worth noting that we\nobserved an intricate interaction between making code changes and profile-\nguided optimizations. We sometimes don\u2019t observe an immediate improvement in\nthe overall Speedometer 3.0 score when we eliminate, or reduce the runtime\ncost of a particular code path until the daily update of profile-guided\noptimizations kicks. This is because the modified or newly added code has to\nbenefit from profile-guided optimizations before it can show a measurable\ndifference. In some cases, we even observed that a performance optimization\ninitially results in a performance degradation until the profile-guided\noptimizations are updated.\n\n## Results\n\nWith all these optimizations and dozens more, we were able to improve the\noverall Speedometer 3.0 score by ~60% between Safari 17.0 and Safari 17.4.\nEven though individual progressions were often less than 1%, over time, they\nall stacked up together to make a big difference. Because some of these\noptimizations also benefited Speedometer 2.1, Safari 17.4 is also ~13% faster\nthan Safari 17.0 on Speedometer 2.1. We\u2019re thrilled to deliver these\nperformance improvements to our users allowing web developers to build\nwebsites and web apps that are more responsive and snappier than ever.\n\nNextRelease Notes for Safari Technology Preview 192Learn more\n\nPreviouslyRelease Notes for Safari Technology Preview 191Learn more\n\n", "frontpage": false}
